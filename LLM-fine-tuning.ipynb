{"cells":[{"cell_type":"markdown","metadata":{"id":"OccEUGZUr224"},"source":["# Llama 3 fine-tuning for finance prediction"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-20T19:35:30.350277Z","iopub.status.busy":"2024-08-20T19:35:30.349425Z","iopub.status.idle":"2024-08-20T19:35:51.046913Z","shell.execute_reply":"2024-08-20T19:35:51.045602Z","shell.execute_reply.started":"2024-08-20T19:35:30.350235Z"},"id":"wUI6SMqombtx","outputId":"3d2b40c8-8837-4529-e8ee-ff8ae1cf1977","scrolled":true,"trusted":true},"outputs":[],"source":["!pip install transformers bitsandbytes accelerate peft --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:35:51.049374Z","iopub.status.busy":"2024-08-20T19:35:51.049031Z","iopub.status.idle":"2024-08-20T19:36:04.027471Z","shell.execute_reply":"2024-08-20T19:36:04.026438Z","shell.execute_reply.started":"2024-08-20T19:35:51.049333Z"},"trusted":true},"outputs":[],"source":["!pip install datasets --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install finnhub-python yfinance --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:36:04.029463Z","iopub.status.busy":"2024-08-20T19:36:04.029051Z","iopub.status.idle":"2024-08-20T19:36:04.429407Z","shell.execute_reply":"2024-08-20T19:36:04.428610Z","shell.execute_reply.started":"2024-08-20T19:36:04.029424Z"},"id":"IXGcsf2dDxfG","scrolled":true,"trusted":true},"outputs":[],"source":["import os\n","import re\n","import csv\n","import math\n","import time \n","import json\n","import random\n","import pandas as pd\n","from tqdm import tqdm\n","from functools import partial\n","from datetime import datetime\n","from collections import defaultdict"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:36:04.432377Z","iopub.status.busy":"2024-08-20T19:36:04.431862Z","iopub.status.idle":"2024-08-20T19:36:05.812056Z","shell.execute_reply":"2024-08-20T19:36:05.811263Z","shell.execute_reply.started":"2024-08-20T19:36:04.432311Z"},"trusted":true},"outputs":[],"source":["import datasets\n","from datasets import Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:36:05.813518Z","iopub.status.busy":"2024-08-20T19:36:05.813086Z","iopub.status.idle":"2024-08-20T19:36:26.006742Z","shell.execute_reply":"2024-08-20T19:36:26.005710Z","shell.execute_reply.started":"2024-08-20T19:36:05.813493Z"},"id":"B0kgDCe6IIa2","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-20 19:36:13.736275: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-20 19:36:13.736420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-20 19:36:13.903872: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import torch\n","from torch.optim import AdamW\n","from transformers import (\n","    AutoTokenizer, AutoModelForCausalLM, AutoConfig, BitsAndBytesConfig,\n","    GenerationConfig, pipeline, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",")\n","\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel, PeftConfig"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:36:26.008760Z","iopub.status.busy":"2024-08-20T19:36:26.008066Z","iopub.status.idle":"2024-08-20T19:36:26.030337Z","shell.execute_reply":"2024-08-20T19:36:26.029621Z","shell.execute_reply.started":"2024-08-20T19:36:26.008728Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:36:26.031709Z","iopub.status.busy":"2024-08-20T19:36:26.031380Z","iopub.status.idle":"2024-08-20T19:36:27.673778Z","shell.execute_reply":"2024-08-20T19:36:27.672423Z","shell.execute_reply.started":"2024-08-20T19:36:26.031685Z"},"id":"mh61ETlidZXH","scrolled":true,"trusted":true},"outputs":[],"source":["os.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")"]},{"cell_type":"markdown","metadata":{"id":"tMd-yyKO9eOV"},"source":["## Collect data"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import finnhub\n","import yfinance as yf"]},{"cell_type":"markdown","metadata":{"id":"yXvES6CUnxoO"},"source":["### Get news and stocks of companies"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Z9OfTMExmRB-","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["finnhub_client = finnhub.Client(api_key=user_secrets.get_secret(\"FINNHUB_API_KEY\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"TgQRu4Z3n5ZT","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def bin_mapping(ret):\n","    up_down = 'U' if ret >= 0 else 'D'\n","    integer = math.ceil(abs(100 * ret))\n","    return up_down + (str(integer) if integer <= 5 else '5+')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"CIS6j5SlnxJ_","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def get_returns(stock_ticker, start_date, end_date):\n","    stock_data = yf.download(stock_ticker, start=start_date, end=end_date)\n","\n","    weekly_data = stock_data['Adj Close'].resample('W').ffill()\n","    weekly_returns = weekly_data.pct_change()[1:]\n","    weekly_start_prices = weekly_data[:-1]\n","    weekly_end_prices = weekly_data[1:]\n","\n","    weekly_data = pd.DataFrame({\n","        'start_date': weekly_start_prices.index,\n","        'start_price': weekly_start_prices.values,\n","        'end_date': weekly_end_prices.index,\n","        'end_price': weekly_end_prices.values,\n","        'weekly_returns': weekly_returns.values\n","    })\n","\n","    weekly_data['bin_label'] = weekly_data['weekly_returns'].map(bin_mapping)\n","\n","    return weekly_data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OXJfhwENoO7G","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def get_news(ticker, data):\n","    news_list = []\n","\n","    for _, row in data.iterrows():\n","        start_date = row['start_date'].strftime('%Y-%m-%d')\n","        end_date = row['end_date'].strftime('%Y-%m-%d')\n","        time.sleep(1) # control qpm\n","        weekly_news = finnhub_client.company_news(ticker, _from=start_date, to=end_date)\n","        weekly_news = [\n","            {\n","                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y%m%d%H%M%S'),\n","                \"headline\": n['headline'],\n","                \"summary\": n['summary'],\n","            } for n in weekly_news\n","        ]\n","        weekly_news.sort(key=lambda x: x['date'])\n","        news_list.append(json.dumps(weekly_news))\n","\n","    data['news'] = news_list\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OdTlWVR6oQRt","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def get_basics(ticker, data, start_date, always=False):\n","    basic_financials = finnhub_client.company_basic_financials(ticker, 'all')\n","\n","    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n","\n","    for metric, value_list in basic_financials['series']['quarterly'].items():\n","        for value in value_list:\n","            basic_dict[value['period']].update({metric: value['v']})\n","\n","    for k, v in basic_dict.items():\n","        v.update({'period': k})\n","        basic_list.append(v)\n","\n","    basic_list.sort(key=lambda x: x['period'])\n","\n","    for i, row in data.iterrows():\n","\n","        start_date = row['end_date'].strftime('%Y-%m-%d')\n","        last_start_date = start_date if i < 2 else data.loc[i-2, 'start_date'].strftime('%Y-%m-%d')\n","\n","        used_basic = {}\n","        for basic in basic_list[::-1]:\n","            if (always and basic['period'] < start_date) or (last_start_date <= basic['period'] < start_date):\n","                used_basic = basic\n","                break\n","        final_basics.append(json.dumps(used_basic))\n","\n","    data['basics'] = final_basics\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tho8tUOuqWwE","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def prep_data_for_ticker(ticker, data_dir, start_date, end_date):\n","\n","    _ = get_returns(ticker, start_date, end_date)\n","    data = get_news(ticker, _)\n","\n","    data = get_basics(ticker, data, start_date)\n","    data.to_csv(f\"{data_dir}/{ticker}_{start_date}_{end_date}.csv\")"]},{"cell_type":"markdown","metadata":{"id":"awyq5ySJsVe2"},"source":["### CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"7dTX-mDdqsGX","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def append_to_csv(filename, input_data, output_data):\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([input_data, output_data])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"qQbE2jwNquCQ","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def initialize_csv(filename):\n","    with open(filename, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([\"prompt\", \"answer\"])"]},{"cell_type":"markdown","metadata":{"id":"uBrLO4WCf7Ub"},"source":["### Prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"G_AEhAaLf47L","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def create_company_profile(ticker):\n","    profile = finnhub_client.company_profile2(symbol=ticker)\n","    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. \" \\\n","                      \"Incorporated and publicly traded since {ipo}, the company has established its reputation \" \\\n","                      \"as one of the key players in the market. \\n\\n{name} operates primarily in the {country}, \" \\\n","                      \"trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, \" \\\n","                      \"the company continues to innovate and drive progress within the industry.\"\n","\n","    formatted_str = company_template.format(**profile)\n","\n","    return formatted_str"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"EyDQ18rcsIR5","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def map_bin_label(bin_lb):\n","    lb = bin_lb.replace('U', 'up by ')\n","    lb = lb.replace('D', 'down by ')\n","    lb = lb.replace('1', '0-1%')\n","    lb = lb.replace('2', '1-2%')\n","    lb = lb.replace('3', '2-3%')\n","    lb = lb.replace('4', '3-4%')\n","    if lb.endswith('+'):\n","        lb = lb.replace('5+', 'more than 5%')\n","    else:\n","        lb = lb.replace('5', '4-5%')\n","\n","    return lb"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GpN0BWOwnGYa","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def sample_news(news, n=5):\n","    if not 0 <= n <= len(news):\n","        raise ValueError(f\"Bad N\")\n","    sampled_indices = random.sample(range(len(news)), n)\n","    return [news[i] for i in sampled_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"DFc7AkQTouGq","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def get_prompt_by_row(ticker, row):\n","\n","    start_date = row['start_date'].strftime('%Y-%m-%d') if isinstance(row['start_date'], datetime) else str(row['start_date'])\n","    end_date = row['end_date'].strftime('%Y-%m-%d') if isinstance(row['end_date'], datetime) else str(row['end_date'])\n","\n","    term = 'increased' if row['end_price'] > row['start_price'] else 'decreased'\n","    head = f\"From {start_date} to {end_date}, {ticker}'s stock price {term} \" \\\n","           f\"from {row['start_price']:.2f} to {row['end_price']:.2f}. News during this period are listed below:\\n\\n\"\n","\n","    news = json.loads(row[\"news\"])\n","    news = [f\"[Headline]: {n['headline']}\\n[Summary]: {n['summary']}\\n\"\n","            for n in news\n","            if n['date'][:8] <= end_date.replace('-', '')\n","            and not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n","\n","    basics = json.loads(row['basics'])\n","    if not basics:\n","        basics_str = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n","    else:\n","        basics_str = f\"Some recent basic financials of {ticker}, reported at {basics['period']}, are presented below:\\n\\n[Basic Financials]:\\n\\n\"\n","        basics_str += \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n","\n","    return head, news, basics_str"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"PvkO275nx3Ps","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def build_prompt(ticker, row, prev_rows, max_weeks, info_prompt):\n","    prompt = \"\"\n","    if prev_rows:\n","        num_prev_rows = min(random.choice(range(1, max_weeks+1)), len(prev_rows))\n","        for i in range(-num_prev_rows, 0):\n","            prompt += f\"\\n{prev_rows[i][0]}\"  # price movement (top of a period)\n","            sampled_news = sample_news(prev_rows[i][1], min(5, len(prev_rows[i][1])))\n","            if sampled_news:\n","                prompt += \"\\n\".join(sampled_news)\n","            else:\n","                prompt += \"\\nNo relative news reported.\"\n","\n","    head, news, basics = get_prompt_by_row(ticker, row)\n","    prev_rows.append((head, news, basics))\n","\n","    if len(prev_rows) > max_weeks:\n","        prev_rows.pop(0)\n","\n","    if not prompt:\n","        return \"\", prev_rows\n","\n","    prediction = map_bin_label(row['bin_label'])\n","    prompt = f\"{info_prompt}\\n{prompt}\\n{basics}\"\n","\n","    instruction_prompt = \"\\n\\nBased on all the information before {start_date}, let's first analyze the positive developments and potential concerns for {ticker}. \" \\\n","                          \"Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n","                          \"Then let's assume your prediction for next week ({start_date} to {end_date}) is {prediction}. \" \\\n","                          \"Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, \" \\\n","                          \"and thus not appearing as a foundational factor of your analysis.\"\n","\n","    prompt += instruction_prompt.format(\n","        start_date=row['start_date'],\n","        end_date=row['end_date'],\n","        ticker=ticker,\n","        prediction=prediction,\n","    )\n","\n","    return prompt.strip(), prev_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ezWWyx0UxlI_","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["def create_prompts(ticker, data_dir, start_date, end_date, max_weeks):\n","    df = pd.read_csv(f'{data_dir}/{ticker}_{start_date}_{end_date}.csv')\n","\n","    info_prompt = create_company_profile(ticker)\n","    prev_rows = []\n","    all_prompts = []\n","\n","    for _, row in df.iterrows():\n","        prompt, prev_rows = build_prompt(ticker, row, prev_rows, max_weeks, info_prompt)\n","        if prompt:\n","            all_prompts.append(prompt)\n","\n","    return all_prompts"]},{"cell_type":"markdown","metadata":{"id":"9rkPfpForYoS"},"source":["### Llama3"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-10T18:56:19.702442Z","iopub.status.busy":"2024-07-10T18:56:19.701487Z","iopub.status.idle":"2024-07-10T18:56:19.706709Z","shell.execute_reply":"2024-07-10T18:56:19.705626Z","shell.execute_reply.started":"2024-07-10T18:56:19.702406Z"},"id":"q336sgtcTdow","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-10T18:58:47.708627Z","iopub.status.busy":"2024-07-10T18:58:47.708225Z","iopub.status.idle":"2024-07-10T18:59:35.253650Z","shell.execute_reply":"2024-07-10T18:59:35.252511Z","shell.execute_reply.started":"2024-07-10T18:58:47.708591Z"},"id":"GnQmxVUaS-CA","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"1635777a-0a12-4763-9054-3ef1ccfb39ea","scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acccf441284242c593b224e9f1996d92","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5088ecbe667748c0977fdd78d7c48f29","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c94a43a587d442295815eee64a38ae1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78a1085514664f66812667becef869e5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a37e2b678d6a433d9b9b2cc98c4d12c7","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-03T17:54:35.699797Z","iopub.status.busy":"2024-07-03T17:54:35.699408Z","iopub.status.idle":"2024-07-03T17:54:35.992211Z","shell.execute_reply":"2024-07-03T17:54:35.990677Z","shell.execute_reply.started":"2024-07-03T17:54:35.699769Z"},"id":"L5l0ZOQTUbBT","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["generation_config = GenerationConfig.from_pretrained(model_id)\n","generation_config.temperature = 0.001\n","\n","llama3 = pipeline(\n","  \"text-generation\",\n","  model=model,\n","  tokenizer=tokenizer,\n","  generation_config=generation_config,\n",")"]},{"cell_type":"markdown","metadata":{"id":"fjcCIZtBgB3q"},"source":["### Llama 3 completion"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.352339Z","iopub.status.idle":"2024-07-10T18:58:44.352745Z","shell.execute_reply":"2024-07-10T18:58:44.352544Z","shell.execute_reply.started":"2024-07-10T18:58:44.352528Z"},"id":"gRrDQiUATJ9J","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["def get_completion(messages):\n","    prompt = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","\n","    outputs = llama3(prompt)\n","    return outputs\n","\n","def get_assistant_response(output):\n","    gen_text = output[0]['generated_text']\n","    assistant_text = gen_text.rsplit('<|eot_id|>', 1)[1]\n","    response = assistant_text.replace('assistant\\n\\n', \"\", 1)\n","\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.354186Z","iopub.status.idle":"2024-07-10T18:58:44.354560Z","shell.execute_reply":"2024-07-10T18:58:44.354395Z","shell.execute_reply.started":"2024-07-10T18:58:44.354379Z"},"id":"VXlCN9Ik8Zpm","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["def llama3_completion(tickers, data_dir, start_date, end_date, max_weeks=3):\n","\n","    for ticker in tqdm(tickers):\n","\n","        print(\"Processing ticker:\", ticker)\n","\n","        csv_file = f'{data_dir}/{ticker}_{start_date}_{end_date}_llama3.csv'\n","\n","        if not os.path.exists(csv_file):\n","            initialize_csv(csv_file)\n","            pre_done = 0\n","        else:\n","            df = pd.read_csv(csv_file)\n","            pre_done = len(df)\n","\n","        prompts = create_prompts(ticker, data_dir, start_date, end_date, max_weeks)\n","        system_prompt = \"You are a seasoned stock market analyst. \" \\\n","                        \"Your task is to list the positive developments and potential \" \\\n","                        \"concerns for companies based on relevant news and basic financials from the past weeks, \" \\\n","                        \"then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n","                        \"Your answer format should be as follows: \" \\\n","                        \"\\n\\n[Positive Developments]:\\n1. ...\" \\\n","                        \"\\n\\n[Potential Concerns]:\\n1. ...\" \\\n","                        \"\\n\\n[Prediction & Analysis]:\\n...\\n\"\n","\n","        for i, prompt in enumerate(prompts):\n","            if i < pre_done:\n","                continue\n","\n","            completion = get_completion(\n","                  messages=[\n","                      {\"role\": \"system\", \"content\": system_prompt},\n","                      {\"role\": \"user\", \"content\": prompt}\n","                    ]\n","            )\n","\n","            answer = get_assistant_response(completion)\n","            append_to_csv(csv_file, prompt, answer)"]},{"cell_type":"markdown","metadata":{"id":"sSnrdrI9mRAA"},"source":["## Prepare data for training"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.356316Z","iopub.status.idle":"2024-07-10T18:58:44.356731Z","shell.execute_reply":"2024-07-10T18:58:44.356526Z","shell.execute_reply.started":"2024-07-10T18:58:44.356509Z"},"id":"VmpIVCvuqHi4","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["TICKERS = [\n","    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n","    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n","    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n","\n","    ## With my account there is access only to the US tickers\n","\n","    # \"ADS.DE\", \"ADYEN.AS\", \"AD.AS\", \"AI.PA\", \"AIR.PA\", \"ALV.DE\",\n","    # \"ABI.BR\", \"ASML.AS\", \"CS.PA\", \"BAS.DE\", \"BAYN.DE\", \"BBVA.MC\",\n","    # \"SAN.MC\", \"BMW.DE\", \"BNP.PA\", \"BN.PA\", \"DAI.DE\", \"DPW.DE\", \"DTE.DE\",\n","    # \"ENEL.MI\", \"ENGI.PA\", \"EL.PA\", \"FRE.DE\", \"IBE.MC\", \"ITX.MC\", \"IFX.DE\",\n","    # \"INGA.AS\", \"ISP.MI\", \"KER.PA\", \"AD.AS\", \"PHIA.AS\", \"OR.PA\", \"LIN.DE\",\n","    # \"MC.PA\", \"MUV2.DE\", \"NOKIA.SE\", \"ORA.PA\", \"RI.PA\", \"SAF.PA\", \"SAN.PA\",\n","    # \"SAP.DE\", \"SU.PA\", \"SIE.DE\", \"GLE.PA\", \"STM.PA\", \"TEF.MC\", \"TTE.PA\",\n","    # \"UNA.AS\", \"DG.PA\", \"VOW3.DE\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2XS0PlXuodW4","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true},"outputs":[],"source":["START_DATE = \"2023-09-01\"\n","END_DATE = \"2024-06-01\"\n","\n","DATA_DIR = f\"./llama_{START_DATE}_{END_DATE}\"\n","os.makedirs(DATA_DIR, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IZFhwdGirK80","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"28919a25-6db7-410f-a012-116e11eb6d2a","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n","\n","\n","\n","\n","\n","\n","\n","[*********************100%%**********************]  1 of 1 completed\n"]}],"source":["for ticker in TICKERS:\n","    prep_data_for_ticker(ticker, DATA_DIR, START_DATE, END_DATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ELLPFLtyxEIU","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"885e546d-da8e-40d6-854f-0fdef146ee38","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Processing ticker: AXP\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 2/30 [00:00<00:08,  3.20it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: AMGN\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: AAPL\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 4/30 [00:00<00:05,  5.18it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: BA\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: CAT\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 6/30 [00:01<00:03,  6.54it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: CSCO\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: CVX\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 8/30 [00:01<00:02,  7.47it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: GS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: HD\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 10/30 [00:01<00:02,  7.44it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: HON\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: IBM\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 12/30 [00:02<00:02,  7.16it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: INTC\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: JNJ\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 14/30 [00:02<00:02,  7.56it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: KO\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: JPM\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 16/30 [00:02<00:01,  7.98it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: MCD\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: MMM\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 18/30 [00:02<00:01,  7.95it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: MRK\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: MSFT\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 20/30 [00:03<00:01,  8.01it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: NKE\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: PG\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 22/30 [00:03<00:00,  8.58it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: TRV\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: UNH\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 24/30 [00:03<00:00,  8.80it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: CRM\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: VZ\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 26/30 [00:03<00:00,  8.71it/s]"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: V\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: WBA\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","\n","\n","\n","\n","\n","\n","\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 27/30 [09:19<08:20, 166.93s/it]"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: WMT\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 28/30 [36:38<20:17, 608.63s/it]"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: DIS\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 29/30 [1:04:19<15:24, 924.34s/it]"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","Processing ticker: DOW\n","\n","\n","\n","\n","\n","\n","\n","CREATING PROMPTS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["CREATING PROMPTS END\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n","\n","\n","\n","\n","\n","\n","\n","COMPLETION IN PROCESS\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 30/30 [1:31:59<00:00, 183.97s/it] "]},{"name":"stdout","output_type":"stream","text":["COMPLETION FINISHED\n","\n","\n","\n","\n","\n","\n","\n","EXTRACTING RESPONSE\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["llama3_completion(TICKERS, DATA_DIR, START_DATE, END_DATE)"]},{"cell_type":"markdown","metadata":{"id":"q2044dqzBVz2"},"source":["## Transform for training"]},{"cell_type":"markdown","metadata":{"id":"eDfAF8C5kM6X"},"source":["### Methods"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:24:35.488357Z","iopub.status.busy":"2024-07-17T17:24:35.487671Z","iopub.status.idle":"2024-07-17T17:24:35.495336Z","shell.execute_reply":"2024-07-17T17:24:35.494304Z","shell.execute_reply.started":"2024-07-17T17:24:35.488324Z"},"id":"LxwT8bpNBY9S","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["def transform2train(tickers, data_dir, tokenizer):\n","    train_list, test_list = [], []\n","    train_size = 0.8\n","\n","    for ticker in tickers:\n","        data_dict = gen2train(ticker, data_dir, tokenizer)\n","\n","        dataset = Dataset.from_dict(data_dict)\n","        train_split = round(train_size * len(dataset))\n","\n","        train_list.append(dataset.select(range(train_split)))\n","        test_list.append(dataset.select(range(train_split, len(dataset))))\n","\n","    train_dataset = datasets.concatenate_datasets(train_list)\n","    test_dataset = datasets.concatenate_datasets(test_list)\n","\n","    dataset = datasets.DatasetDict({\n","      'train': train_dataset,\n","      'test': test_dataset\n","    })\n","\n","    return dataset"]},{"cell_type":"markdown","metadata":{"id":"F4XAYQ6VkS3r"},"source":["### Transform"]},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:27:48.628556Z","iopub.status.busy":"2024-07-17T17:27:48.627707Z","iopub.status.idle":"2024-07-17T17:27:48.638653Z","shell.execute_reply":"2024-07-17T17:27:48.637802Z","shell.execute_reply.started":"2024-07-17T17:27:48.628523Z"},"id":"nan6PQiRBYjG","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["def gen2train(ticker, data_dir, tokenizer):\n","    csv_file = f'{data_dir}/{ticker}.csv'\n","    df = pd.read_csv(csv_file)\n","    prompts, answers, periods, labels = [], [], [], []\n","\n","    for i, row in df.iterrows():\n","        prompt, answer = row['prompt'], row['answer']\n","        res = re.search(r\"Then let's assume your prediction for next week \\((.*)\\) is ((:?up|down) by .*%).\", prompt)\n","        period, label = res.group(1), res.group(2)\n","        prompt = re.sub(\n","            r\"Then let's assume your prediction for next week \\((.*)\\) is (up|down) by ((:?.*)%). Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\",\n","            f\"Then make your prediction of the {ticker} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\",\n","            prompt\n","        )\n","        answer = re.sub(\n","            r\"\\[Prediction & Analysis\\]:\\s*\",\n","            f\"[Prediction & Analysis]:\\nPrediction: {label.capitalize()}\\nAnalysis: \",\n","            answer\n","        )\n","\n","        system_prompt = \"You are a seasoned stock market analyst. \" \\\n","                        \"Your task is to list the positive developments and potential \" \\\n","                        \"concerns for companies based on relevant news and basic financials from the past weeks, \" \\\n","                        \"then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n","                        \"Your answer format should be as follows: \" \\\n","                        \"\\n\\n[Positive Developments]:\" \\\n","                        \"\\n1. ...\" \\\n","                        \"\\n\\n[Potential Concerns]:\" \\\n","                        \"\\n1. ...\" \\\n","                        \"\\n\\n[Prediction & Analysis]:\" \\\n","                        \"\\nPrediction: ...\" \\\n","                        \"\\nAnalysis: ...\\n\"\n","\n","        messages=[\n","          {\"role\": \"system\", \"content\": system_prompt},\n","          {\"role\": \"user\", \"content\": prompt}\n","        ]\n","        train_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","\n","        prompts.append(train_prompt)\n","        answers.append(answer)\n","        periods.append(period)\n","        labels.append(label)\n","\n","    return {\n","        \"prompt\": prompts,\n","        \"answer\": answers,\n","        \"period\": periods,\n","        \"label\": labels,\n","    }"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:25:48.074448Z","iopub.status.busy":"2024-07-17T17:25:48.073560Z","iopub.status.idle":"2024-07-17T17:25:48.080689Z","shell.execute_reply":"2024-07-17T17:25:48.079752Z","shell.execute_reply.started":"2024-07-17T17:25:48.074407Z"},"id":"4PnscvX4Bcxq","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["TICKERS = [\n","    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n","    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n","    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n","]"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:31:44.581982Z","iopub.status.busy":"2024-07-17T17:31:44.581617Z","iopub.status.idle":"2024-07-17T17:31:44.586784Z","shell.execute_reply":"2024-07-17T17:31:44.585899Z","shell.execute_reply.started":"2024-07-17T17:31:44.581955Z"},"id":"qq_VUq39BdXQ","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["DATA_DIR = \"/kaggle/input/llama-2023-09-01-2024-06-01\""]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:27:29.116668Z","iopub.status.busy":"2024-07-17T17:27:29.116299Z","iopub.status.idle":"2024-07-17T17:27:30.731769Z","shell.execute_reply":"2024-07-17T17:27:30.730924Z","shell.execute_reply.started":"2024-07-17T17:27:29.116640Z"},"id":"gRoV431sTGyD","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"27f443e7-e87c-480b-c796-423a96f72dc5","scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5e6dd3ec94f41b1b863991da31d798a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21691a2013f84dd08e774e38a73324cb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68af2a03c2614af0b2d11cc6663db758","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\"\n","finance_tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\n","\n","# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:31:46.358424Z","iopub.status.busy":"2024-07-17T17:31:46.357781Z","iopub.status.idle":"2024-07-17T17:31:47.157827Z","shell.execute_reply":"2024-07-17T17:31:47.157037Z","shell.execute_reply.started":"2024-07-17T17:31:46.358394Z"},"id":"8hHp7Gm7jxJy","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"]}],"source":["llama3_dataset = transform2train(TICKERS, DATA_DIR, finance_tokenizer)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:31:52.460662Z","iopub.status.busy":"2024-07-17T17:31:52.460296Z","iopub.status.idle":"2024-07-17T17:31:52.470589Z","shell.execute_reply":"2024-07-17T17:31:52.469657Z","shell.execute_reply.started":"2024-07-17T17:31:52.460634Z"},"id":"7yonKOPXko9e","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"10362916-a75d-4b83-868b-31447dd7dd50","scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["{'prompt': \"<|im_start|>system\\nYou are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. Your answer format should be as follows: \\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]:\\nPrediction: ...\\nAnalysis: ...\\n<|im_end|>\\n<|im_start|>user\\n[Company Introduction]:\\n\\nAmerican Express Co is a leading entity in the Financial Services sector. Incorporated and publicly traded since 1977-05-18, the company has established its reputation as one of the key players in the market. \\n\\nAmerican Express Co operates primarily in the US, trading under the ticker AXP on the NEW YORK STOCK EXCHANGE, INC.. As a dominant force in the Financial Services space, the company continues to innovate and drive progress within the industry.\\n\\nFrom 2023-09-03 to 2023-09-10, AXP's stock price decreased from 157.97 to 155.80. News during this period are listed below:\\n\\n[Headline]: September Rally? 3 Financial Stocks to Buy Before Liftoff\\n[Summary]: A September rally may not be in the cards for financial stocks, as the stock market is off to a lackluster start during this historically very poor month for equities. To make matters worse, Wall Street is upset by slight increases in interest rates and oil prices that we’ve seen so far in September. However, I believe that by Thanksgiving financial stocks will attain liftoff. That’s because I agree with Citizens Financial (NYSE:CFG) CEO Bruce Van Saun who told Bloomberg TV on Sept. 7 that The F\\n\\n[Headline]: Warren Buffett’s Biggest Bets: The 7 Stocks Dominating His Portfolio\\n[Summary]: Since taking over the reins of Berkshire Hathaway (NYSE:BRK-A, NYSE:BRK-B) as CEO in 1965, Warren Buffett has overseen compounded gains of 20% a year. That’s more than double the returns of the S&P 500. Not every year was a winner. At numerous points over the past 58 years, Buffett lost to the popular benchmark index. Sometimes by a wide margin. But Buffett’s strategy of buying excellent companies at fair prices and then holding them long-term continues to pay off. We’re talking about an aggrega\\n\\n[Headline]: American Express (AXP) Dips More Than Broader Markets: What You Should Know\\n[Summary]: American Express (AXP) closed the most recent trading day at $156.78, moving -0.77% from the previous trading session.\\n\\n[Headline]: American Express Company (AXP) Is a Trending Stock: Facts to Know Before Betting on It\\n[Summary]: American Express (AXP) has received quite a bit of attention from Zacks.com users lately. Therefore, it is wise to be aware of the facts that can impact the stock's prospects.\\n\\n[Headline]: U.S. Wide-Moat Stocks On Sale - The September 2023 Heat Map\\n[Summary]: Our 3-step process focuses on wide-moat stocks (as per Morningstarâ\\x80\\x99s rating). Find out the heat map of the most investable candidates.\\n\\n[Basic Financials]:\\n\\nNo basic financial reported.\\n\\nBased on all the information before 2023-09-10, let's first analyze the positive developments and potential concerns for AXP. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. Then make your prediction of the AXP stock price movement for next week (2023-09-10 to 2023-09-17). Provide a summary analysis to support your prediction.<|im_end|>\\n<|im_start|>assistant\\n\",\n"," 'answer': \"[Positive Developments]:\\n1. American Express (AXP) is mentioned as one of the financial stocks that could potentially experience a September rally, as per a recent article.\\n2. Warren Buffett's investment in AXP is highlighted, indicating the company's potential for long-term growth and stability.\\n3. AXP's recent trading session saw a slight decrease in stock price, which could be seen as a buying opportunity for investors.\\n4. The company's wide-moat stock status, as per Morningstar's rating, suggests its potential for long-term growth and stability.\\n\\n[Potential Concerns]:\\n1. The recent decrease in AXP's stock price could be a sign of market uncertainty and potential volatility.\\n2. The slight increase in interest rates and oil prices could have a negative impact on the company's financial performance.\\n3. The lackluster start to the month of September for the stock market could continue to affect AXP's stock price.\\n4. The company's recent trading session saw a slight decrease in stock price, which could be a sign of market uncertainty and potential volatility.\\n\\n[Prediction & Analysis]:\\nPrediction: Up by 4-5%\\nAnalysis: Based on the positive developments, I believe that AXP's stock price has the potential to increase by 4-5% in the upcoming week (2023-09-10 to 2023-09-17). This prediction is supported by the company's wide-moat stock status, Warren Buffett's investment, and the potential for a September rally. Additionally, the recent decrease in AXP's stock price could be seen as a buying opportunity for investors, which could drive the stock price up in the upcoming week. However, the potential concerns, such as market uncertainty and the slight increase in interest rates and oil prices, could also impact the company's financial performance and stock price. Overall, I believe that AXP's stock price has the potential to increase in the upcoming week, but it is important to monitor the company's financial performance and market trends to confirm this prediction.\",\n"," 'period': '2023-09-10 to 2023-09-17',\n"," 'label': 'up by 4-5%'}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["llama3_dataset['train'][0]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["455ef0362bcd4bb984b4154822164249","4aecd68f2e294d4c8c549c7cba4af701","144e6101bb27400280288b98d713e918","47acbbfe8fad419881c1e2698f9c2a34","93fd7ad358e543ac8e5aa6d9cb298aab","c0ce274386e04ddf8070d64db608730c","0b9428da99ba46ffaf4b862e07207ede","e2c45ca2da95461f943198b2a8b93d46","81f7d44dd0dc45689b708459df10c761","d4572c769c98415f914bb5b184abd745","0cbbffeee1774506b48eef11496c9b73","5a49aecc4f8945b9892c275b5a1626a3","2a163537d1e740a28413efde552b0300","a36975338ea24f9dae5c355627248dd2","f14ba5b13f9a402e8c3809b6c4c07020","f15ba01c1c664f119d1f46a683356ef4","ed4273e578634ea3a534e2f09d031fb1","79b84a811d1c4d4ba3af804ca8dfa315","402a3bcf10cb4ac4b4b831cc30fed454","29751286d1eb47ad81d39eed31b1abac","cb1b2f2bf1e34dcc9568034fc37db6a9","a42763c249d64234ba0eb05462efd3f1"]},"collapsed":true,"execution":{"iopub.execute_input":"2024-07-17T17:34:00.863831Z","iopub.status.busy":"2024-07-17T17:34:00.863435Z","iopub.status.idle":"2024-07-17T17:34:00.939703Z","shell.execute_reply":"2024-07-17T17:34:00.938800Z","shell.execute_reply.started":"2024-07-17T17:34:00.863804Z"},"id":"gZRDFRIJkllb","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"5300ef3b-277d-45a0-e00f-c6a40fed65f1","scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44196e7a4d864cfd9b6bab077d2b7c68","version_major":2,"version_minor":0},"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/900 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa15c6db71f04a31baba1e9694fafad0","version_major":2,"version_minor":0},"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["llama3_dataset.save_to_disk('./fin-prediction-2023-09-01_2024-06-01-llama3')"]},{"cell_type":"markdown","metadata":{"id":"JxV8KPCzmNYw"},"source":["## Fine-tuning"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T15:51:01.350902Z","iopub.status.busy":"2024-08-13T15:51:01.350214Z","iopub.status.idle":"2024-08-13T15:51:01.484503Z","shell.execute_reply":"2024-08-13T15:51:01.483572Z","shell.execute_reply.started":"2024-08-13T15:51:01.350868Z"},"id":"e6Sao3ipVI5d","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["os.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"WANDB_API_KEY\")\n","os.environ['WANDB_PROJECT'] = 'llama3-fin-pred'"]},{"cell_type":"markdown","metadata":{},"source":["### Finance Llama 3 8B"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T01:26:20.173046Z","iopub.status.busy":"2024-08-17T01:26:20.172663Z","iopub.status.idle":"2024-08-17T01:26:20.177151Z","shell.execute_reply":"2024-08-17T01:26:20.176263Z","shell.execute_reply.started":"2024-08-17T01:26:20.173018Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\""]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-17T01:26:29.348216Z","iopub.status.busy":"2024-08-17T01:26:29.347538Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a281bf6acdc448dbaead4e7b0b320cf","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80524b023bb144b5867ec72a0902ddbf","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e893b22e5592415ba370990ca1fd3ac7","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1ca0a88480945c08efc031bae5585fa","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41c566efa75e40d6908779bbb0af8975","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a65b5c71e1474ccb8726b776e0c0bc74","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08df6e574489404abb05aaac13fbe9dd","version_major":2,"version_minor":0},"text/plain":["model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b530008c51a94bbbadd00d100140def4","version_major":2,"version_minor":0},"text/plain":["model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e5c1cbc8d2c4327bdcb1f17ce89bdc6","version_major":2,"version_minor":0},"text/plain":["model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8852eb8db5244c7d9ccad4f41be65fc9","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bnb_config = BitsAndBytesConfig(\n","#     load_in_4bit=True,\n","#     bnb_4bit_quant_type=\"nf4\",\n","#     bnb_4bit_compute_dtype=torch.float16,\n","#     bnb_4bit_use_double_quant=True,\n","    load_in_8bit=True,\n",")\n","model = AutoModelForCausalLM.from_pretrained(finance_llama3_8b, quantization_config=bnb_config, device_map=\"auto\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["a60776900afb41c588673f7a76a4f7f9","afc408fe52114d80beb590fb9e4ac9aa","9e510b2f45884ab39c543846c0a851d4"]},"collapsed":true,"execution":{"iopub.execute_input":"2024-08-17T01:15:09.984884Z","iopub.status.busy":"2024-08-17T01:15:09.984286Z","iopub.status.idle":"2024-08-17T01:15:11.294807Z","shell.execute_reply":"2024-08-17T01:15:11.293837Z","shell.execute_reply.started":"2024-08-17T01:15:09.984851Z"},"id":"V8PFfJMTzEQ4","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"4823c013-44db-49c2-e4ad-6da0d37d28a4","scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e7ba2c4499442839749f80a0ea29822","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c26e5b2fc9d74da5a1152de36d334910","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d138b6a9988f4f0ca84d4cf85f2a870c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\n","# tokenizer.pad_token = tokenizer.eos_token\n","# tokenizer.padding_side = \"right\""]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T03:32:24.197508Z","iopub.status.busy":"2024-08-13T03:32:24.197204Z","iopub.status.idle":"2024-08-13T03:32:24.205017Z","shell.execute_reply":"2024-08-13T03:32:24.204100Z","shell.execute_reply.started":"2024-08-13T03:32:24.197481Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["{'model.embed_tokens': 0,\n"," 'model.layers.0': 0,\n"," 'model.layers.1': 0,\n"," 'model.layers.2': 0,\n"," 'model.layers.3': 0,\n"," 'model.layers.4': 0,\n"," 'model.layers.5': 0,\n"," 'model.layers.6': 0,\n"," 'model.layers.7': 0,\n"," 'model.layers.8': 1,\n"," 'model.layers.9': 1,\n"," 'model.layers.10': 1,\n"," 'model.layers.11': 1,\n"," 'model.layers.12': 1,\n"," 'model.layers.13': 1,\n"," 'model.layers.14': 1,\n"," 'model.layers.15': 1,\n"," 'model.layers.16': 1,\n"," 'model.layers.17': 1,\n"," 'model.layers.18': 1,\n"," 'model.layers.19': 1,\n"," 'model.layers.20': 1,\n"," 'model.layers.21': 1,\n"," 'model.layers.22': 1,\n"," 'model.layers.23': 1,\n"," 'model.layers.24': 1,\n"," 'model.layers.25': 1,\n"," 'model.layers.26': 1,\n"," 'model.layers.27': 1,\n"," 'model.layers.28': 1,\n"," 'model.layers.29': 1,\n"," 'model.layers.30': 1,\n"," 'model.layers.31': 1,\n"," 'model.norm': 1,\n"," 'lm_head': 1}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model.hf_device_map"]},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:02:30.351308Z","iopub.status.busy":"2024-08-13T16:02:30.350925Z","iopub.status.idle":"2024-08-13T16:02:30.428474Z","shell.execute_reply":"2024-08-13T16:02:30.427573Z","shell.execute_reply.started":"2024-08-13T16:02:30.351272Z"},"id":"YOiVA425fNIt","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["# model = prepare_model_for_kbit_training(model)"]},{"cell_type":"markdown","metadata":{"id":"jXQMMODRnVXl"},"source":["### Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:13:46.673344Z","iopub.status.busy":"2024-08-13T16:13:46.673067Z","iopub.status.idle":"2024-08-13T16:13:46.680741Z","shell.execute_reply":"2024-08-13T16:13:46.679744Z","shell.execute_reply.started":"2024-08-13T16:13:46.673319Z"},"id":"iT8CKDlrzzVk","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["def tokenize(tokenizer, feature):\n","    prompt = feature['prompt']\n","    answer = feature['answer']\n","\n","    prompt_ids = tokenizer.encode(prompt, add_special_tokens=True, truncation=True, max_length=4096)\n","    answer_ids = tokenizer.encode(answer, add_special_tokens=False, truncation=True, max_length=4096)\n","\n","    input_ids = prompt_ids + answer_ids\n","    too_big = len(input_ids) >= 8192\n","\n","    if input_ids[-1] != tokenizer.eos_token_id and not too_big:\n","        input_ids.append(tokenizer.eos_token_id)\n","\n","    label_ids = [tokenizer.pad_token_id] * len(prompt_ids) + input_ids[len(prompt_ids):]\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"labels\": label_ids,\n","        \"is_too_big\": too_big\n","    }"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:13:46.682376Z","iopub.status.busy":"2024-08-13T16:13:46.682018Z","iopub.status.idle":"2024-08-13T16:13:46.734206Z","shell.execute_reply":"2024-08-13T16:13:46.733496Z","shell.execute_reply.started":"2024-08-13T16:13:46.682342Z"},"id":"4RdmrMpVnWX8","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["dataset_name = \"/kaggle/working/fin-prediction-2023-09-01-2024-06-01-llama3\"\n","dataset = datasets.load_from_disk(dataset_name)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["5b5fe12a6dd242fbb1f678c24f8889d2","7c03165ba1e44f1fb6a0f5e9a1de7130","cc70d5494aa2428fb4535b2ce377ec2d","9ecd6cfe1f5e4dd38daeb66f80c3193b","0e25c3657c7a482d99ab14e24094700f","bd61c21d4cda47f283752d1f36928ef3","5a028a4a33044b339002e40457536735","9387d7e0e98b4534849529e008858964","0db68bea29e644bcab2a579fb87bf271","71927857a7e44dcdad2e0df79462ed6c","eec4724bdc904708aa87119b9c187861","ba61a21d0ef047b89400ebed07ab1f30","94bd9f1753be45fb91201bbce2b81567","047dcce93d5048b6b647f1cb3c8902e5","d7c51f161f5f4779b7d724eb1caf56c1","f203c7d51d0b4760a8df3d20b12159ff","9e6fbfcf4602470783234944fe00a80d","75dbd4b48d4b40a9aa73c389ca4b431c","b4219fd1c6c142ea8cbbe41c66a6fd7e","52317ad1f4fb4470b0b221bcdb5d1b84","ce76e0ba88844a9ab693d7daffae81b4","244a20287aec48af8a42757150c23504","5376f9587933402ba422859e999492ed","ed331e46cc1a463f828c2dfba96d9296","2e4b2e72ab3b4dcd83d5382c6c217c9b","3f409f0118d243b8a86f470c69f372e9","9a9593098dca4472b120719e5b80739c","a09ecb5428ff4c9894784d75fbd1ac4e","b223de2deb454a46ab183c8472db4f27","901c6fefb887434f9b9015de5fa8c0c3","a4d0e2f164044634b62f57b8cf25929d","6abd119862244705bd86594c5e438e1b","08854c2134364248a3233434b551c0ab","ac949691abbb4c9c9b79d1928ae15420","7cb91b31a79744d4937c374f0fb029fb","a43c8944390e47ffb28dad160ffed250","e76296a04b104dd0b724d72dd23b960f","c1dead594a0c4ee487f19d3f2879a266","bda0f0cca6f642668518e37b9b7c3977","2e8eaa8ba6334c11864dfc333cf35697","1ebb62bbbbe44f7c9be5fef39333be0d","31eab09e78384a40afd70b9d0296a4bc","4dfc0effb5d648d29e04ecd28e8c57d4","bcccba20051f4916ab98bd18f9219681","8f908931441f4b279484424b15aae9ab","03f9706a8a02498da8bd3c07850d26c5"]},"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:13:46.735523Z","iopub.status.busy":"2024-08-13T16:13:46.735239Z","iopub.status.idle":"2024-08-13T16:13:47.163120Z","shell.execute_reply":"2024-08-13T16:13:47.162166Z","shell.execute_reply.started":"2024-08-13T16:13:46.735498Z"},"id":"B-3QnV5Ryk1Q","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"e0b98822-9e65-4ad2-a0dd-a0b24581828d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["original dataset length:  900\n","\n","filtered dataset length:  900\n"]}],"source":["tokenized_dataset = dataset.map(partial(tokenize, tokenizer))\n","print('original dataset length: ', len(dataset['train']))\n","tokenized_dataset = tokenized_dataset.filter(lambda x: not x['is_too_big'])\n","print('filtered dataset length: ', len(dataset['train']))\n","tokenized_dataset = tokenized_dataset.remove_columns(\n","    ['prompt', 'answer', 'label', 'period', 'is_too_big']\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T15:56:00.069741Z","iopub.status.busy":"2024-08-13T15:56:00.069094Z","iopub.status.idle":"2024-08-13T15:56:00.116641Z","shell.execute_reply":"2024-08-13T15:56:00.115786Z","shell.execute_reply.started":"2024-08-13T15:56:00.069705Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [128000,\n","  27,\n","  91,\n","  318,\n","  5011,\n","  91,\n","  29,\n","  9125,\n","  198,\n","  2675,\n","  527,\n","  264,\n","  52614,\n","  5708,\n","  3157,\n","  18738,\n","  13,\n","  4718,\n","  3465,\n","  374,\n","  311,\n","  1160,\n","  279,\n","  6928,\n","  26006,\n","  323,\n","  4754,\n","  10742,\n","  369,\n","  5220,\n","  3196,\n","  389,\n","  9959,\n","  3754,\n","  323,\n","  6913,\n","  6020,\n","  82,\n","  505,\n","  279,\n","  3347,\n","  5672,\n","  11,\n","  1243,\n","  3493,\n","  459,\n","  6492,\n","  323,\n","  20212,\n","  369,\n","  279,\n","  5220,\n","  6,\n","  5708,\n","  3430,\n","  7351,\n","  369,\n","  279,\n","  14827,\n","  2046,\n","  13,\n","  4718,\n","  4320,\n","  3645,\n","  1288,\n","  387,\n","  439,\n","  11263,\n","  25,\n","  4815,\n","  58,\n","  36590,\n","  8000,\n","  1392,\n","  10556,\n","  16,\n","  13,\n","  5585,\n","  43447,\n","  354,\n","  2335,\n","  52347,\n","  82,\n","  10556,\n","  16,\n","  13,\n","  5585,\n","  43447,\n","  1171,\n","  2538,\n","  612,\n","  18825,\n","  10556,\n","  89379,\n","  25,\n","  12515,\n","  27671,\n","  25,\n","  12515,\n","  27,\n","  91,\n","  318,\n","  6345,\n","  91,\n","  397,\n","  27,\n","  91,\n","  318,\n","  5011,\n","  91,\n","  29,\n","  882,\n","  198,\n","  58,\n","  14831,\n","  29438,\n","  69662,\n","  29518,\n","  17855,\n","  3623,\n","  374,\n","  264,\n","  6522,\n","  5502,\n","  304,\n","  279,\n","  17961,\n","  8471,\n","  10706,\n","  13,\n","  67795,\n","  323,\n","  17880,\n","  31207,\n","  2533,\n","  220,\n","  4468,\n","  22,\n","  12,\n","  2304,\n","  12,\n","  972,\n","  11,\n","  279,\n","  2883,\n","  706,\n","  9749,\n","  1202,\n","  17444,\n","  439,\n","  832,\n","  315,\n","  279,\n","  1401,\n","  4311,\n","  304,\n","  279,\n","  3157,\n","  13,\n","  4815,\n","  29518,\n","  17855,\n","  3623,\n","  27149,\n","  15871,\n","  304,\n","  279,\n","  2326,\n","  11,\n","  11380,\n","  1234,\n","  279,\n","  48087,\n","  362,\n","  28475,\n","  389,\n","  279,\n","  16560,\n","  47404,\n","  83751,\n","  4154,\n","  41973,\n","  11,\n","  18610,\n","  497,\n","  1666,\n","  264,\n","  25462,\n","  5457,\n","  304,\n","  279,\n","  17961,\n","  8471,\n","  3634,\n","  11,\n","  279,\n","  2883,\n","  9731,\n","  311,\n","  92064,\n","  323,\n","  6678,\n","  5208,\n","  2949,\n","  279,\n","  5064,\n","  382,\n","  3915,\n","  220,\n","  2366,\n","  18,\n","  12,\n","  2545,\n","  12,\n","  2839,\n","  311,\n","  220,\n","  2366,\n","  18,\n","  12,\n","  2545,\n","  12,\n","  605,\n","  11,\n","  362,\n","  28475,\n","  596,\n","  5708,\n","  3430,\n","  25983,\n","  505,\n","  220,\n","  10895,\n","  13,\n","  3534,\n","  311,\n","  220,\n","  9992,\n","  13,\n","  1490,\n","  13,\n","  5513,\n","  2391,\n","  420,\n","  4261,\n","  527,\n","  10212,\n","  3770,\n","  1473,\n","  58,\n","  12626,\n","  1074,\n","  5787,\n","  6250,\n","  59800,\n","  30,\n","  220,\n","  18,\n","  17961,\n","  80336,\n","  311,\n","  11544,\n","  13538,\n","  65863,\n","  998,\n","  544,\n","  198,\n","  58,\n","  19791,\n","  5787,\n","  362,\n","  6250,\n","  19768,\n","  1253,\n","  539,\n","  387,\n","  304,\n","  279,\n","  7563,\n","  369,\n","  6020,\n","  23301,\n","  11,\n","  439,\n","  279,\n","  5708,\n","  3157,\n","  374,\n","  1022,\n","  311,\n","  264,\n","  6996,\n","  75,\n","  5100,\n","  1212,\n","  2391,\n","  420,\n","  35901,\n","  1633,\n","  8009,\n","  2305,\n","  369,\n","  3312,\n","  1385,\n","  13,\n","  2057,\n","  1304,\n","  13146,\n","  11201,\n","  11,\n","  9935,\n","  6825,\n","  374,\n","  23268,\n","  555,\n","  8275,\n","  12992,\n","  304,\n","  2802,\n","  7969,\n","  323,\n","  5707,\n","  7729,\n","  430,\n","  584,\n","  4070,\n","  3970,\n","  779,\n","  3117,\n","  304,\n","  6250,\n","  13,\n","  4452,\n","  11,\n","  358,\n","  4510,\n","  430,\n","  555,\n","  37250,\n","  6020,\n","  23301,\n","  690,\n","  36861,\n","  10345,\n","  998,\n","  544,\n","  13,\n","  3011,\n","  753,\n","  1606,\n","  358,\n","  7655,\n","  449,\n","  40996,\n","  17961,\n","  320,\n","  68445,\n","  25,\n","  30175,\n","  8,\n","  12432,\n","  24785,\n","  13000,\n","  16233,\n","  359,\n","  889,\n","  3309,\n","  37653,\n","  6007,\n","  389,\n","  5488,\n","  13,\n","  220,\n","  22,\n","  430,\n","  578,\n","  435,\n","  271,\n","  58,\n","  12626,\n","  1074,\n","  5787,\n","  26713,\n","  86552,\n","  753,\n","  86621,\n","  426,\n","  1441,\n","  25,\n","  578,\n","  220,\n","  22,\n","  80336,\n","  23286,\n","  1113,\n","  5414,\n","  47292,\n","  198,\n","  58,\n","  19791,\n","  5787,\n","  8876,\n","  4737,\n","  927,\n","  279,\n","  90518,\n","  315,\n","  91375,\n","  91668,\n","  14075,\n","  320,\n","  68445,\n","  25,\n","  13396,\n","  42,\n","  6830,\n","  11,\n","  12551,\n","  937,\n","  25,\n","  13396,\n","  42,\n","  7826,\n","  8,\n","  439,\n","  12432,\n","  304,\n","  220,\n","  5162,\n","  20,\n","  11,\n","  26713,\n","  86552,\n","  706,\n","  20270,\n","  268,\n","  88424,\n","  20192,\n","  315,\n","  220,\n","  508,\n","  4,\n","  264,\n","  1060,\n","  13,\n","  3011,\n","  753,\n","  810,\n","  1109,\n","  2033,\n","  279,\n","  4780,\n","  315,\n","  279,\n","  328,\n","  43945,\n","  220,\n","  2636,\n","  13,\n","  2876,\n","  1475,\n","  1060,\n","  574,\n","  264,\n","  13946,\n","  13,\n","  2468,\n","  12387,\n","  3585,\n","  927,\n","  279,\n","  3347,\n","  220,\n","  2970,\n","  1667,\n","  11,\n","  86552,\n","  5675,\n","  311,\n","  279,\n","  5526,\n","  29531,\n","  1963,\n","  13,\n","  18156,\n","  555,\n","  264,\n","  7029,\n","  4850,\n","  13,\n","  2030,\n","  86552,\n","  753,\n","  8446,\n","  315,\n","  12096,\n","  9250,\n","  5220,\n","  520,\n","  6762,\n","  7729,\n","  323,\n","  1243,\n","  10168,\n","  1124,\n","  1317,\n","  9860,\n","  9731,\n","  311,\n","  2343,\n","  1022,\n","  13,\n","  1226,\n","  3207,\n","  7556,\n","  922,\n","  459,\n","  26263,\n","  64,\n","  271,\n","  58,\n","  12626,\n","  1074,\n","  5787,\n","  3778,\n","  17855,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  423,\n","  3153,\n","  4497,\n","  34776,\n","  6031,\n","  1013,\n","  47910,\n","  25,\n","  3639,\n","  1472,\n","  12540,\n","  14521,\n","  198,\n","  58,\n","  19791,\n","  5787,\n","  3778,\n","  17855,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  8036,\n","  279,\n","  1455,\n","  3293,\n","  11380,\n","  1938,\n","  520,\n","  400,\n","  10132,\n","  13,\n","  2495,\n","  11,\n","  7366,\n","  482,\n","  15,\n","  13,\n","  2813,\n","  4,\n","  505,\n","  279,\n","  3766,\n","  11380,\n","  3882,\n","  382,\n","  58,\n","  12626,\n","  1074,\n","  5787,\n","  3778,\n","  17855,\n","  8351,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  2209,\n","  264,\n","  31753,\n","  287,\n","  12937,\n","  25,\n","  46083,\n","  311,\n","  14521,\n","  13538,\n","  85085,\n","  389,\n","  1102,\n","  198,\n","  58,\n","  19791,\n","  5787,\n","  3778,\n","  17855,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  706,\n","  4036,\n","  5115,\n","  264,\n","  2766,\n","  315,\n","  6666,\n","  505,\n","  1901,\n","  7977,\n","  916,\n","  3932,\n","  31445,\n","  13,\n","  15636,\n","  11,\n","  433,\n","  374,\n","  24219,\n","  311,\n","  387,\n","  8010,\n","  315,\n","  279,\n","  13363,\n","  430,\n","  649,\n","  5536,\n","  279,\n","  5708,\n","  596,\n","  27949,\n","  382,\n","  58,\n","  12626,\n","  1074,\n","  5787,\n","  549,\n","  815,\n","  13,\n","  33845,\n","  5364,\n","  78,\n","  266,\n","  80336,\n","  1952,\n","  13618,\n","  482,\n","  578,\n","  6250,\n","  220,\n","  2366,\n","  18,\n","  27162,\n","  5135,\n","  198,\n","  58,\n","  19791,\n","  5787,\n","  5751,\n","  220,\n","  18,\n","  30308,\n","  1920,\n","  24400,\n","  389,\n","  7029,\n","  1474,\n","  78,\n","  266,\n","  23301,\n","  320,\n","  300,\n","  824,\n","  29084,\n","  12134,\n","  9011,\n","  75809,\n","  82,\n","  10959,\n","  570,\n","  7531,\n","  704,\n","  279,\n","  8798,\n","  2472,\n","  315,\n","  279,\n","  1455,\n","  2793,\n","  481,\n","  11426,\n","  382,\n","  58,\n","  16323,\n","  17961,\n","  82,\n","  69662,\n","  2822,\n","  6913,\n","  6020,\n","  5068,\n","  382,\n","  29815,\n","  389,\n","  682,\n","  279,\n","  2038,\n","  1603,\n","  220,\n","  2366,\n","  18,\n","  12,\n","  2545,\n","  12,\n","  605,\n","  11,\n","  1095,\n","  596,\n","  1176,\n","  24564,\n","  279,\n","  6928,\n","  26006,\n","  323,\n","  4754,\n","  10742,\n","  369,\n","  362,\n","  28475,\n","  13,\n","  15936,\n","  709,\n","  449,\n","  220,\n","  17,\n","  12,\n","  19,\n","  1455,\n","  3062,\n","  9547,\n","  15947,\n","  323,\n","  2567,\n","  1124,\n","  64694,\n","  13,\n","  7648,\n","  9547,\n","  1288,\n","  387,\n","  68695,\n","  505,\n","  2883,\n","  5552,\n","  3754,\n","  13,\n","  5112,\n","  1304,\n","  701,\n","  20212,\n","  315,\n","  279,\n","  362,\n","  28475,\n","  5708,\n","  3430,\n","  7351,\n","  369,\n","  1828,\n","  2046,\n","  320,\n","  2366,\n","  18,\n","  12,\n","  2545,\n","  12,\n","  605,\n","  311,\n","  220,\n","  2366,\n","  18,\n","  12,\n","  2545,\n","  12,\n","  1114,\n","  570,\n","  40665,\n","  264,\n","  12399,\n","  6492,\n","  311,\n","  1862,\n","  701,\n","  20212,\n","  16134,\n","  91,\n","  318,\n","  6345,\n","  91,\n","  397,\n","  27,\n","  91,\n","  318,\n","  5011,\n","  91,\n","  29,\n","  78191,\n","  198,\n","  58,\n","  36590,\n","  8000,\n","  1392,\n","  10556,\n","  16,\n","  13,\n","  3778,\n","  17855,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  374,\n","  9932,\n","  439,\n","  832,\n","  315,\n","  279,\n","  6020,\n","  23301,\n","  430,\n","  1436,\n","  13893,\n","  3217,\n","  264,\n","  6250,\n","  19768,\n","  11,\n","  439,\n","  824,\n","  264,\n","  3293,\n","  4652,\n","  627,\n","  17,\n","  13,\n","  26713,\n","  86552,\n","  596,\n","  9341,\n","  304,\n","  362,\n","  28475,\n","  374,\n","  27463,\n","  11,\n","  19392,\n","  279,\n","  2883,\n","  596,\n","  4754,\n","  369,\n","  1317,\n","  9860,\n","  6650,\n","  323,\n","  20334,\n","  627,\n","  18,\n","  13,\n","  362,\n","  28475,\n","  596,\n","  3293,\n","  11380,\n","  3882,\n","  5602,\n","  264,\n","  8275,\n","  18979,\n","  304,\n","  5708,\n","  3430,\n","  11,\n","  902,\n","  1436,\n","  387,\n","  3970,\n","  439,\n","  264,\n","  12096,\n","  6776,\n","  369,\n","  15167,\n","  627,\n","  19,\n","  13,\n","  578,\n","  2883,\n","  596,\n","  7029,\n","  1474,\n","  78,\n","  266,\n","  5708,\n","  2704,\n","  11,\n","  439,\n","  824,\n","  29084,\n","  12134,\n","  596,\n","  10959,\n","  11,\n","  13533,\n","  1202,\n","  4754,\n","  369,\n","  1317,\n","  9860,\n","  6650,\n","  323,\n","  20334,\n","  382,\n","  43447,\n","  354,\n","  2335,\n","  52347,\n","  82,\n","  10556,\n","  16,\n","  13,\n","  578,\n","  3293,\n","  18979,\n","  304,\n","  362,\n","  28475,\n","  596,\n","  5708,\n","  3430,\n","  1436,\n","  387,\n","  264,\n","  1879,\n","  315,\n","  3157,\n","  27924,\n","  323,\n","  4754,\n","  53838,\n","  627,\n","  17,\n","  13,\n","  578,\n","  8275,\n","  5376,\n","  304,\n","  2802,\n","  7969,\n","  323,\n","  5707,\n","  7729,\n","  1436,\n","  617,\n","  264,\n","  8389,\n","  5536,\n","  389,\n","  279,\n","  2883,\n","  596,\n","  6020,\n","  5178,\n","  627,\n","  18,\n","  13,\n","  578,\n","  6996,\n","  75,\n","  5100,\n","  1212,\n","  311,\n","  279,\n","  2305,\n","  315,\n","  6250,\n","  369,\n","  279,\n","  5708,\n","  ...],\n"," 'labels': [128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  128001,\n","  58,\n","  36590,\n","  8000,\n","  1392,\n","  10556,\n","  16,\n","  13,\n","  3778,\n","  17855,\n","  320,\n","  3027,\n","  47,\n","  8,\n","  374,\n","  9932,\n","  439,\n","  832,\n","  315,\n","  279,\n","  6020,\n","  23301,\n","  430,\n","  1436,\n","  13893,\n","  3217,\n","  264,\n","  6250,\n","  19768,\n","  11,\n","  439,\n","  824,\n","  264,\n","  3293,\n","  4652,\n","  627,\n","  17,\n","  13,\n","  26713,\n","  86552,\n","  596,\n","  9341,\n","  304,\n","  362,\n","  28475,\n","  374,\n","  27463,\n","  11,\n","  19392,\n","  279,\n","  2883,\n","  596,\n","  4754,\n","  369,\n","  1317,\n","  9860,\n","  6650,\n","  323,\n","  20334,\n","  627,\n","  18,\n","  13,\n","  362,\n","  28475,\n","  596,\n","  3293,\n","  11380,\n","  3882,\n","  5602,\n","  264,\n","  8275,\n","  18979,\n","  304,\n","  5708,\n","  3430,\n","  11,\n","  902,\n","  1436,\n","  387,\n","  3970,\n","  439,\n","  264,\n","  12096,\n","  6776,\n","  369,\n","  15167,\n","  627,\n","  19,\n","  13,\n","  578,\n","  2883,\n","  596,\n","  7029,\n","  1474,\n","  78,\n","  266,\n","  5708,\n","  2704,\n","  11,\n","  439,\n","  824,\n","  29084,\n","  12134,\n","  596,\n","  10959,\n","  11,\n","  13533,\n","  1202,\n","  4754,\n","  369,\n","  1317,\n","  9860,\n","  6650,\n","  323,\n","  20334,\n","  382,\n","  43447,\n","  354,\n","  2335,\n","  52347,\n","  82,\n","  10556,\n","  16,\n","  13,\n","  578,\n","  3293,\n","  18979,\n","  304,\n","  362,\n","  28475,\n","  596,\n","  5708,\n","  3430,\n","  1436,\n","  387,\n","  264,\n","  1879,\n","  315,\n","  3157,\n","  27924,\n","  323,\n","  4754,\n","  53838,\n","  627,\n","  17,\n","  13,\n","  578,\n","  8275,\n","  5376,\n","  304,\n","  2802,\n","  7969,\n","  323,\n","  5707,\n","  7729,\n","  1436,\n","  617,\n","  264,\n","  8389,\n","  5536,\n","  389,\n","  279,\n","  2883,\n","  596,\n","  6020,\n","  5178,\n","  627,\n","  18,\n","  13,\n","  578,\n","  6996,\n","  75,\n","  5100,\n","  1212,\n","  311,\n","  279,\n","  2305,\n","  315,\n","  6250,\n","  369,\n","  279,\n","  5708,\n","  ...]}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset['train'][0]"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T15:56:00.118015Z","iopub.status.busy":"2024-08-13T15:56:00.117758Z","iopub.status.idle":"2024-08-13T15:56:00.157303Z","shell.execute_reply":"2024-08-13T15:56:00.156430Z","shell.execute_reply.started":"2024-08-13T15:56:00.117993Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["\"<|begin_of_text|><|im_start|>system\\nYou are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. Your answer format should be as follows: \\n\\n[Positive Developments]:\\n1....\\n\\n[Potential Concerns]:\\n1....\\n\\n[Prediction & Analysis]:\\nPrediction:...\\nAnalysis:...\\n<|im_end|>\\n<|im_start|>user\\n[Company Introduction]:\\n\\nAmerican Express Co is a leading entity in the Financial Services sector. Incorporated and publicly traded since 1977-05-18, the company has established its reputation as one of the key players in the market. \\n\\nAmerican Express Co operates primarily in the US, trading under the ticker AXP on the NEW YORK STOCK EXCHANGE, INC.. As a dominant force in the Financial Services space, the company continues to innovate and drive progress within the industry.\\n\\nFrom 2023-09-03 to 2023-09-10, AXP's stock price decreased from 157.97 to 155.80. News during this period are listed below:\\n\\n[Headline]: September Rally? 3 Financial Stocks to Buy Before Liftoff\\n[Summary]: A September rally may not be in the cards for financial stocks, as the stock market is off to a lackluster start during this historically very poor month for equities. To make matters worse, Wall Street is upset by slight increases in interest rates and oil prices that we’ve seen so far in September. However, I believe that by Thanksgiving financial stocks will attain liftoff. That’s because I agree with Citizens Financial (NYSE:CFG) CEO Bruce Van Saun who told Bloomberg TV on Sept. 7 that The F\\n\\n[Headline]: Warren Buffett’s Biggest Bets: The 7 Stocks Dominating His Portfolio\\n[Summary]: Since taking over the reins of Berkshire Hathaway (NYSE:BRK-A, NYSE:BRK-B) as CEO in 1965, Warren Buffett has overseen compounded gains of 20% a year. That’s more than double the returns of the S&P 500. Not every year was a winner. At numerous points over the past 58 years, Buffett lost to the popular benchmark index. Sometimes by a wide margin. But Buffett’s strategy of buying excellent companies at fair prices and then holding them long-term continues to pay off. We’re talking about an aggrega\\n\\n[Headline]: American Express (AXP) Dips More Than Broader Markets: What You Should Know\\n[Summary]: American Express (AXP) closed the most recent trading day at $156.78, moving -0.77% from the previous trading session.\\n\\n[Headline]: American Express Company (AXP) Is a Trending Stock: Facts to Know Before Betting on It\\n[Summary]: American Express (AXP) has received quite a bit of attention from Zacks.com users lately. Therefore, it is wise to be aware of the facts that can impact the stock's prospects.\\n\\n[Headline]: U.S. Wide-Moat Stocks On Sale - The September 2023 Heat Map\\n[Summary]: Our 3-step process focuses on wide-moat stocks (as per Morningstarâ\\x80\\x99s rating). Find out the heat map of the most investable candidates.\\n\\n[Basic Financials]:\\n\\nNo basic financial reported.\\n\\nBased on all the information before 2023-09-10, let's first analyze the positive developments and potential concerns for AXP. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. Then make your prediction of the AXP stock price movement for next week (2023-09-10 to 2023-09-17). Provide a summary analysis to support your prediction.<|im_end|>\\n<|im_start|>assistant\\n[Positive Developments]:\\n1. American Express (AXP) is mentioned as one of the financial stocks that could potentially experience a September rally, as per a recent article.\\n2. Warren Buffett's investment in AXP is highlighted, indicating the company's potential for long-term growth and stability.\\n3. AXP's recent trading session saw a slight decrease in stock price, which could be seen as a buying opportunity for investors.\\n4. The company's wide-moat stock status, as per Morningstar's rating, suggests its potential for long-term growth and stability.\\n\\n[Potential Concerns]:\\n1. The recent decrease in AXP's stock price could be a sign of market uncertainty and potential volatility.\\n2. The slight increase in interest rates and oil prices could have a negative impact on the company's financial performance.\\n3. The lackluster start to the month of September for the stock market could continue to affect AXP's stock price.\\n4. The company's recent trading session saw a slight decrease in stock price, which could be a sign of market uncertainty and potential volatility.\\n\\n[Prediction & Analysis]:\\nPrediction: Up by 4-5%\\nAnalysis: Based on the positive developments, I believe that AXP's stock price has the potential to increase by 4-5% in the upcoming week (2023-09-10 to 2023-09-17). This prediction is supported by the company's wide-moat stock status, Warren Buffett's investment, and the potential for a September rally. Additionally, the recent decrease in AXP's stock price could be seen as a buying opportunity for investors, which could drive the stock price up in the upcoming week. However, the potential concerns, such as market uncertainty and the slight increase in interest rates and oil prices, could also impact the company's financial performance and stock price. Overall, I believe that AXP's stock price has the potential to increase in the upcoming week, but it is important to monitor the company's financial performance and market trends to confirm this prediction.<|end_of_text|>\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(tokenized_dataset['train'][0]['input_ids'])"]},{"cell_type":"markdown","metadata":{"id":"rTvWHUu1kkPz"},"source":["### Params"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:13:47.165221Z","iopub.status.busy":"2024-08-13T16:13:47.164472Z","iopub.status.idle":"2024-08-13T16:13:48.028460Z","shell.execute_reply":"2024-08-13T16:13:48.027489Z","shell.execute_reply.started":"2024-08-13T16:13:47.165181Z"},"id":"7H-_DeEpklSG","jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'],\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model.gradient_checkpointing_enable()\n","model.enable_input_require_grads()\n","model.is_parallelizable = True\n","model.model_parallel = True\n","model.model.config.use_cache = False\n","\n","peft_model = get_peft_model(model, lora_config)"]},{"cell_type":"code","execution_count":28,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:02:41.765672Z","iopub.status.busy":"2024-08-13T16:02:41.765354Z","iopub.status.idle":"2024-08-13T16:02:41.802633Z","shell.execute_reply":"2024-08-13T16:02:41.801555Z","shell.execute_reply.started":"2024-08-13T16:02:41.765647Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=1024, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=4096, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=14336, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-20): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-30): Dropout(p=0.1, inplace=False)\n","                  (checkpoint-40): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  (checkpoint-20): Linear(in_features=14336, out_features=16, bias=False)\n","                  (checkpoint-30): Linear(in_features=14336, out_features=16, bias=False)\n","                  (checkpoint-40): Linear(in_features=14336, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-20): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-30): Linear(in_features=16, out_features=4096, bias=False)\n","                  (checkpoint-40): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm()\n","            (post_attention_layernorm): LlamaRMSNorm()\n","          )\n","        )\n","        (norm): LlamaRMSNorm()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["peft_model"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:13:57.914400Z","iopub.status.busy":"2024-08-13T16:13:57.914027Z","iopub.status.idle":"2024-08-13T16:13:57.989108Z","shell.execute_reply":"2024-08-13T16:13:57.988214Z","shell.execute_reply.started":"2024-08-13T16:13:57.914365Z"},"id":"D6xuWZ7emFDy","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"aafba994-8392-4ef8-f320-5cfdc7addfe8","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n","\n","Using auto half precision backend\n"]}],"source":["# current_time = datetime.now().strftime('%Y%m%d-%H-%M')\n","current_time = \"20240813-03-33\"\n","\n","optimizer = AdamW(\n","    peft_model.parameters(),\n","    lr=3e-5,\n","    betas=(0.9, 0.97),\n","    eps=1e-8,\n","    weight_decay=0.005\n",")\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"./results_{current_time}\",\n","    num_train_epochs=4,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    log_level='info',\n","    gradient_accumulation_steps=32,\n","    eval_strategy='steps',\n","    save_strategy=\"steps\",\n","    fp16=True,\n","    logging_steps=1,\n","    save_total_limit=3,\n","    save_steps=10,\n","    eval_steps=10,\n","    remove_unused_columns=False,\n","    report_to='wandb',\n","    run_name=\"llama3_fin_pred_run\",\n","    max_grad_norm=0.3,\n","    warmup_ratio=0.03,\n",")\n","\n","trainer = Trainer(\n","    model=peft_model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset['train'],\n","    eval_dataset=tokenized_dataset['test'],\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, padding=True,\n","      return_tensors=\"pt\"\n","    ),\n","    optimizers=(optimizer, None),  # (optimizer, scheduler)\n",")\n","\n","trainer.is_model_parallel = True\n","\n","peft_model.gradient_checkpointing_enable()\n","peft_model.enable_input_require_grads()"]},{"cell_type":"markdown","metadata":{"id":"2h7gViVvbMcr"},"source":["### Train"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T16:14:04.574378Z","iopub.status.busy":"2024-08-13T16:14:04.573539Z","iopub.status.idle":"2024-08-13T21:23:54.579439Z","shell.execute_reply":"2024-08-13T21:23:54.578207Z","shell.execute_reply.started":"2024-08-13T16:14:04.574343Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading model from /kaggle/working/results_20240813-03-33/checkpoint-40.\n","\n","***** Running training *****\n","\n","  Num examples = 900\n","\n","  Num Epochs = 4\n","\n","  Instantaneous batch size per device = 1\n","\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","\n","  Gradient Accumulation steps = 32\n","\n","  Total optimization steps = 112\n","\n","  Number of trainable parameters = 41,943,040\n","\n","  Continuing training from checkpoint, will skip to saved global_step\n","\n","  Continuing training from epoch 1\n","\n","  Continuing training from global step 40\n","\n","  Will skip the first 1 epochs then the first 384 batches in the first epoch.\n","\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240813_162332-lkugbi3z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface/runs/lkugbi3z' target=\"_blank\">llama3_fin_pred_run</a></strong> to <a href='https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface' target=\"_blank\">https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface/runs/lkugbi3z' target=\"_blank\">https://wandb.ai/serhii-fedosov-kharkiv-national-universoty-of-radio-elec/huggingface/runs/lkugbi3z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [112/112 4:56:23, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.135700</td>\n","      <td>0.130672</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.115300</td>\n","      <td>0.118240</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.110700</td>\n","      <td>0.110976</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.108200</td>\n","      <td>0.106154</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.098000</td>\n","      <td>0.103041</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.093300</td>\n","      <td>0.101208</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.093300</td>\n","      <td>0.100461</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-50\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-50/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-50/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-20] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-60\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-60/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-60/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-30] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-70\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-70/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-70/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-40] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-80\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-80/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-80/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-50] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-90\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-90/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-90/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-60] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-100\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-100/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-100/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-70] due to args.save_total_limit\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-110\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-110/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-110/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-80] due to args.save_total_limit\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-112\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-112/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-112/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-90] due to args.save_total_limit\n","\n","\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\n","\n","\n","Saving model checkpoint to ./results_20240813-03-33/trainer_model\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/trainer_model/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/trainer_model/special_tokens_map.json\n","\n","Configuration saved in ./results_20240813-03-33/pretrained/config.json\n","\n","Configuration saved in ./results_20240813-03-33/pretrained/generation_config.json\n","\n","The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./results_20240813-03-33/pretrained/model.safetensors.index.json.\n"]}],"source":["trainer.train(\"/kaggle/working/results_20240813-03-33/checkpoint-40\")\n","\n","trainer.save_model(f\"{training_args.output_dir}/trainer_model\")\n","model.save_pretrained(f\"{training_args.output_dir}/pretrained\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"collapsed":true,"execution":{"iopub.execute_input":"2024-08-13T03:33:40.195755Z","iopub.status.busy":"2024-08-13T03:33:40.195076Z","iopub.status.idle":"2024-08-13T07:46:37.487772Z","shell.execute_reply":"2024-08-13T07:46:37.485996Z","shell.execute_reply.started":"2024-08-13T03:33:40.195723Z"},"id":"_9vZEAQ4dEBi","jupyter":{"outputs_hidden":true,"source_hidden":true},"outputId":"ae6e5dd1-a141-47f1-ca3d-21dd80cabba1","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","\n","  Num examples = 900\n","\n","  Num Epochs = 4\n","\n","  Instantaneous batch size per device = 1\n","\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","\n","  Gradient Accumulation steps = 32\n","\n","  Total optimization steps = 112\n","\n","  Number of trainable parameters = 41,943,040\n","\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maskador\u001b[0m (\u001b[33maskador-Kharkiv National University of Radio Electronics\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240813_033343-4m6mt4nv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/4m6mt4nv' target=\"_blank\">llama3_fin_pred_run</a></strong> to <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred' target=\"_blank\">https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/4m6mt4nv' target=\"_blank\">https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/4m6mt4nv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 48/112 4:04:14 < 5:39:49, 0.00 it/s, Epoch 1.67/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>7.703100</td>\n","      <td>6.983650</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.001000</td>\n","      <td>1.631318</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.400800</td>\n","      <td>0.348252</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.163000</td>\n","      <td>0.160674</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-10\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-10/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-10/special_tokens_map.json\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-20\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-20/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-20/special_tokens_map.json\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-30\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-30/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-30/special_tokens_map.json\n","\n","\n","\n","***** Running Evaluation *****\n","\n","  Num examples = 240\n","\n","  Batch size = 1\n","\n","Saving model checkpoint to ./results_20240813-03-33/checkpoint-40\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/b573f2ae317bca8e137321c8d8dca2919dfc37ef/config.json\n","\n","Model config LlamaConfig {\n","\n","  \"architectures\": [\n","\n","    \"LlamaForCausalLM\"\n","\n","  ],\n","\n","  \"attention_bias\": false,\n","\n","  \"attention_dropout\": 0.0,\n","\n","  \"bos_token_id\": 128000,\n","\n","  \"eos_token_id\": 128001,\n","\n","  \"hidden_act\": \"silu\",\n","\n","  \"hidden_size\": 4096,\n","\n","  \"initializer_range\": 0.02,\n","\n","  \"intermediate_size\": 14336,\n","\n","  \"max_position_embeddings\": 8192,\n","\n","  \"mlp_bias\": false,\n","\n","  \"model_type\": \"llama\",\n","\n","  \"num_attention_heads\": 32,\n","\n","  \"num_hidden_layers\": 32,\n","\n","  \"num_key_value_heads\": 8,\n","\n","  \"pretraining_tp\": 1,\n","\n","  \"rms_norm_eps\": 1e-05,\n","\n","  \"rope_scaling\": null,\n","\n","  \"rope_theta\": 500000.0,\n","\n","  \"tie_word_embeddings\": false,\n","\n","  \"torch_dtype\": \"float16\",\n","\n","  \"transformers_version\": \"4.42.3\",\n","\n","  \"use_cache\": true,\n","\n","  \"vocab_size\": 128256\n","\n","}\n","\n","\n","\n","tokenizer config file saved in ./results_20240813-03-33/checkpoint-40/tokenizer_config.json\n","\n","Special tokens file saved in ./results_20240813-03-33/checkpoint-40/special_tokens_map.json\n","\n","Deleting older checkpoint [results_20240813-03-33/checkpoint-10] due to args.save_total_limit\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacty of 14.74 GiB of which 1.28 GiB is free. Process 2392 has 13.46 GiB memory in use. Of the allocated memory 10.13 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_args\u001b[38;5;241m.\u001b[39moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/trainer_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_args\u001b[38;5;241m.\u001b[39moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3324\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3322\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3324\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2147\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:288\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    287\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:288\u001b[0m, in \u001b[0;36mCheckpointFunction.backward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone of output has requires_grad=True,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this checkpoint() is not necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[0;32m--> 288\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    290\u001b[0m     inp\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m detached_inputs\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m+\u001b[39m grads\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacty of 14.74 GiB of which 1.28 GiB is free. Process 2392 has 13.46 GiB memory in use. Of the allocated memory 10.13 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["trainer.train()\n","\n","trainer.save_model(f\"{training_args.output_dir}/trainer_model\")\n","model.save_pretrained(f\"{training_args.output_dir}/pretrained\")"]},{"cell_type":"markdown","metadata":{"id":"_sz4zAEHveGB"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:37:49.851881Z","iopub.status.busy":"2024-08-20T19:37:49.850841Z","iopub.status.idle":"2024-08-20T19:37:49.869574Z","shell.execute_reply":"2024-08-20T19:37:49.868684Z","shell.execute_reply.started":"2024-08-20T19:37:49.851850Z"},"id":"7M6bFouWv3Q-","trusted":true},"outputs":[],"source":["dataset_name = \"./fin-prediction-2023-09-01-2024-06-01-llama3\"\n","dataset = datasets.load_from_disk(dataset_name)\n","eval_dataset = dataset['test'].shuffle(seed=333).select(range(20))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:37:50.559134Z","iopub.status.busy":"2024-08-20T19:37:50.558471Z","iopub.status.idle":"2024-08-20T19:37:50.567238Z","shell.execute_reply":"2024-08-20T19:37:50.566397Z","shell.execute_reply.started":"2024-08-20T19:37:50.559103Z"},"trusted":true},"outputs":[],"source":["def change_prompt_instruct_to_prcnt(feature):\n","    prompt = feature['prompt']\n","    feature['prompt'] = prompt.replace(\"Prediction: ...\", \"Prediction: Up|Down by X-Y%\")\n","    return feature\n","\n","better_prompt_dataset = eval_dataset.map(change_prompt_instruct_to_prcnt)"]},{"cell_type":"markdown","metadata":{},"source":["### Models"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:37:52.045885Z","iopub.status.busy":"2024-08-20T19:37:52.044991Z","iopub.status.idle":"2024-08-20T19:37:52.050149Z","shell.execute_reply":"2024-08-20T19:37:52.049237Z","shell.execute_reply.started":"2024-08-20T19:37:52.045851Z"},"trusted":true},"outputs":[],"source":["finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\"\n","# finance_peft_adapter_path = \"/kaggle/input/fin-prediction-llama3/transformers/peft-adapter/3\"\n","finance_peft_adapter_path = \"/kaggle/input/fine-tuned-fin-pred-llama3-model/transformers/peft-adapter/1\"\n","# finance_peft_adapter_path2 = \"/kaggle/input/fine-tuned-fin-pred-llama3-model/transformers/peft-adapter/2\"\n","base_llama3_8b = \"meta-llama/Meta-Llama-3-8B-Instruct\""]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:48:28.950143Z","iopub.status.busy":"2024-08-20T19:48:28.949787Z","iopub.status.idle":"2024-08-20T19:48:32.197988Z","shell.execute_reply":"2024-08-20T19:48:32.196999Z","shell.execute_reply.started":"2024-08-20T19:48:28.950115Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a6e44f66ed44b2e9942e4c4128420c5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d30fa2078ac4c909780e372471c9873","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcf0cd16d9b442f08b66c1ddf43cbe5a","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23abba51f8e04d10ac0ded575bac0e2d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248f899e497d4564ad455118008e0ecd","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24522d611d8c4b55ae66ad4b1dd4a989","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["finance_tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\n","base_tokenizer = AutoTokenizer.from_pretrained(base_llama3_8b)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:37:53.292757Z","iopub.status.busy":"2024-08-20T19:37:53.291948Z","iopub.status.idle":"2024-08-20T19:37:53.298493Z","shell.execute_reply":"2024-08-20T19:37:53.297548Z","shell.execute_reply.started":"2024-08-20T19:37:53.292724Z"},"trusted":true},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Base"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T01:15:22.143875Z","iopub.status.busy":"2024-08-20T01:15:22.143614Z","iopub.status.idle":"2024-08-20T01:17:54.065005Z","shell.execute_reply":"2024-08-20T01:17:54.064201Z","shell.execute_reply.started":"2024-08-20T01:15:22.143852Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e635f0a00bb247a99a8607368c132d0b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5622fcd8b6eb40c4b7ffe7693790b312","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f20b8a2518584a19b739ed775056b86f","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4978e41ef3f54a9ba4917d48cf3bd51f","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e55409e5cc0642e3b88269718ffbb078","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1f2804ce1d24029872bc25ab815bb75","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bde033e16c3441ca0aaaf54e8fb921e","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e49a5ad4c9104647b88f6083859c3251","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fbb7ef9923147e8b27aad7a435c88d7","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["base_model = AutoModelForCausalLM.from_pretrained(base_llama3_8b, quantization_config=bnb_config, device_map='cuda:1', low_cpu_mem_usage=True)\n","base_model = base_model.eval()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T22:15:59.082541Z","iopub.status.busy":"2024-08-19T22:15:59.082235Z","iopub.status.idle":"2024-08-19T22:15:59.087698Z","shell.execute_reply":"2024-08-19T22:15:59.086605Z","shell.execute_reply.started":"2024-08-19T22:15:59.082515Z"},"trusted":true},"outputs":[],"source":["base_model_pipeline = pipeline(\n","    \"text-generation\",\n","    model=base_model,\n","    tokenizer=base_tokenizer,\n","    eos_token_id=base_tokenizer.eos_token_id,\n","    do_sample=True,\n","    return_full_text=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuned"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:37:56.094929Z","iopub.status.busy":"2024-08-20T19:37:56.094557Z","iopub.status.idle":"2024-08-20T19:43:27.333383Z","shell.execute_reply":"2024-08-20T19:43:27.332550Z","shell.execute_reply.started":"2024-08-20T19:37:56.094903Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93d49e54312341148d88835cf99d1e81","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b54f4dc6046a48928fbf9094e71af787","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b74d43e8a6d14b4ebf08491762ed3033","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26f204dfc71f42af9cc9a536fe3fad90","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfc98060be344192adf0005f1da250a6","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c960a3a7109047298880d74022bedc3c","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d9c64e65515489bb0928868900f8bd8","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a13682a6a0640129a909957a812d645","version_major":2,"version_minor":0},"text/plain":["model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6634dc6a88d440487234060ce348033","version_major":2,"version_minor":0},"text/plain":["model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33d80a7c7cf249cea1bf3be9025b3233","version_major":2,"version_minor":0},"text/plain":["model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"481b51a3213e438195cc2db27ec24418","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb07a79d700a413aa4dee1d0a73e1912","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["finance_model = AutoModelForCausalLM.from_pretrained(\n","    finance_llama3_8b, \n","    return_dict=True, \n","    quantization_config=bnb_config, \n","    low_cpu_mem_usage=True,\n","    device_map=\"cuda:0\"\n",")\n","PeftModel.from_pretrained(finance_model, finance_peft_adapter_path)\n","finetuned_model = finance_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# finance_finetuned_model = PeftModel.from_pretrained(finance_llama3_8b_model, finance_peft_adapter_path)\n","# finance_finetuned_model = finance_finetuned_model.merge_and_unload()\n","# finance_finetuned_model = finance_finetuned_model.eval()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T22:51:02.494782Z","iopub.status.busy":"2024-08-19T22:51:02.493873Z","iopub.status.idle":"2024-08-19T22:51:02.499784Z","shell.execute_reply":"2024-08-19T22:51:02.498960Z","shell.execute_reply.started":"2024-08-19T22:51:02.494741Z"},"trusted":true},"outputs":[],"source":["finetuned_pipeline = pipeline(\n","    \"text-generation\",\n","    model=finetuned_model,\n","    tokenizer=finance_tokenizer,\n","    eos_token_id=finance_tokenizer.eos_token_id,\n","    do_sample=True,\n","#     return_full_text=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Running completions for evaluation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:43:27.335282Z","iopub.status.busy":"2024-08-20T19:43:27.334985Z","iopub.status.idle":"2024-08-20T19:43:27.340312Z","shell.execute_reply":"2024-08-20T19:43:27.339226Z","shell.execute_reply.started":"2024-08-20T19:43:27.335255Z"},"trusted":true},"outputs":[],"source":["def decode(tokenizer, output):\n","    return tokenizer.decode(output[0]).split(\"|>assistant\\n\", 1)[1].split('<|e')[0]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T01:23:42.958639Z","iopub.status.busy":"2024-08-20T01:23:42.958285Z","iopub.status.idle":"2024-08-20T01:51:01.354903Z","shell.execute_reply":"2024-08-20T01:51:01.353978Z","shell.execute_reply.started":"2024-08-20T01:23:42.958603Z"},"scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04207d6f3d1243f384a83715beb16890","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]}],"source":["from tqdm.notebook import tqdm\n","completions = {'base': [], 'finetuned': []}\n","\n","for i, row in tqdm(enumerate(better_prompt_dataset)):\n","    base_inputs = base_tokenizer(\n","        row['prompt'], return_tensors='pt',\n","        add_special_tokens=True\n","    ).to(base_model.device)\n","    \n","    base_res = base_model.generate(\n","        **base_inputs, \n","        do_sample=True,\n","        eos_token_id=base_tokenizer.eos_token_id\n","    )\n","    completions['base'].append(decode(base_tokenizer, base_res))\n","    \n","    \n","    finetuned_inputs = finance_tokenizer(\n","        row['prompt'], return_tensors='pt',\n","        add_special_tokens=True\n","    ).to(finetuned_model.device)\n","    \n","    finetuned_res = finetuned_model.generate(\n","        **finetuned_inputs, \n","        do_sample=True,\n","        eos_token_id=finance_tokenizer.eos_token_id\n","    )\n","    \n","    completions['finetuned'].append(decode(finance_tokenizer, finetuned_res))"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:33:29.315845Z","iopub.status.busy":"2024-08-20T20:33:29.315470Z","iopub.status.idle":"2024-08-20T20:33:29.322301Z","shell.execute_reply":"2024-08-20T20:33:29.321329Z","shell.execute_reply.started":"2024-08-20T20:33:29.315814Z"},"trusted":true},"outputs":[],"source":["with open(\"./completions.json\", 'w') as f:\n","    json.dump(completions, f, ensure_ascii=False, indent=4)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:30:53.953516Z","iopub.status.busy":"2024-08-20T20:30:53.953141Z","iopub.status.idle":"2024-08-20T20:30:53.963974Z","shell.execute_reply":"2024-08-20T20:30:53.963004Z","shell.execute_reply.started":"2024-08-20T20:30:53.953483Z"},"trusted":true},"outputs":[],"source":["completions = []\n","with open(\"/kaggle/working/completions.json\", 'r') as f:\n","    completions = json.load(f)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:30:26.612445Z","iopub.status.busy":"2024-08-20T20:30:26.612064Z","iopub.status.idle":"2024-08-20T20:30:26.619371Z","shell.execute_reply":"2024-08-20T20:30:26.618398Z","shell.execute_reply.started":"2024-08-20T20:30:26.612412Z"},"trusted":true},"outputs":[],"source":["answers = []\n","for row in better_prompt_dataset:\n","    answers.append(row['answer'])"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:29:59.322475Z","iopub.status.busy":"2024-08-20T20:29:59.322005Z","iopub.status.idle":"2024-08-20T20:29:59.337040Z","shell.execute_reply":"2024-08-20T20:29:59.336007Z","shell.execute_reply.started":"2024-08-20T20:29:59.322439Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","\n","def parse_answer(answer):\n","    \n","    match_res = re.search(r\"(?:\\[|\\*\\*)?Positive Developments(?:\\]:|:\\*\\*)?\\s*(.*?)(?:\\n+|\\s+)*(?:\\[|\\*\\*)?Potential Concerns(?:\\]:|:\\*\\*)?\\s*(.*?)(?:\\n+|\\s+)*(?:\\[|\\*\\*)?Prediction\\s*(?:&|and)\\s*Analysis(?:\\]:|:\\*\\*)?\\s*(.*)\\s*\", answer, flags=re.DOTALL)\n","    if not match_res:\n","        return None\n","    \n","    positive, concerns, predict = match_res.group(1), match_res.group(2), match_res.group(3)\n","        \n","\n","    match_predictions = re.match(r'^Prediction:\\s*(.*)\\s*Analysis:\\s*(.*)\\s*$', predict, flags=re.DOTALL)\n","    if not match_predictions:\n","        match_predictions = re.search(r'((?:increase|decrease|up|down|decline)\\s+by\\s+(?:\\d(?:-\\d)?%))', predict, flags=re.DOTALL)\n","        if not match_predictions:\n","            return None\n","        prediction = match_predictions.group(1)\n","        analysis = prediction\n","    else:\n","        prediction, analysis = match_predictions.group(1), match_predictions.group(2)\n","\n","    \n","    if re.search(r'up|increase', prediction.lower()):\n","        prediction_bin = 1\n","    elif re.search(r'down|decrease|decline', prediction.lower()):\n","        prediction_bin = -1\n","    else:\n","        prediction_bin = 0\n","        \n","\n","    match_res = re.search(r'(\\d)-(\\d)%', prediction)\n","    if not match_res:\n","        match_res = re.search(r'(?:more than )?(\\d)+?%', prediction)    \n","        \n","    prediction_margin = prediction_bin * (int(match_res.group(1)) + 0.5) if match_res else 0.\n","        \n","    return {\n","        \"positive_developments\": positive,\n","        \"potential_concerns\": concerns,\n","        \"prediction\": prediction_margin,\n","        \"prediction_binary\": prediction_bin,\n","        \"analysis\": analysis\n","    }\n","\n","\n","def evaluate(completions, answers):\n","    completions_dict = defaultdict(list)\n","    answers_dict = defaultdict(list)\n","    \n","    for completion, answer in zip(completions, answers):\n","        completion_dict = parse_answer(completion)\n","        answer_dict = parse_answer(answer)\n","        \n","        if completion_dict and answer_dict:\n","            print(f\"Completion:\\t{completion_dict['prediction']}\\t| Answer:\\t{answer_dict['prediction']}\")\n","            for k in completion_dict.keys():\n","                completions_dict[k].append(completion_dict[k])\n","                answers_dict[k].append(answer_dict[k])\n","                \n","    if not completions_dict['prediction']:\n","        return {}\n","    \n","    bin_acc = accuracy_score(completions_dict['prediction_binary'], answers_dict['prediction_binary'])\n","    mse = mean_squared_error(completions_dict['prediction'], answers_dict['prediction'])\n","    return {\n","        \"valid_count\": len(completions_dict['prediction']),\n","        \"bin_acc\": bin_acc,\n","        \"mse\": mse\n","    }"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T19:32:22.926553Z","iopub.status.busy":"2024-08-20T19:32:22.925982Z","iopub.status.idle":"2024-08-20T19:32:22.977854Z","shell.execute_reply":"2024-08-20T19:32:22.976244Z","shell.execute_reply.started":"2024-08-20T19:32:22.926491Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Completion:\t5.5\t| Answer:\t-5.5\n","Completion:\t2.5\t| Answer:\t1.5\n","Completion:\t5.5\t| Answer:\t-0.5\n","Completion:\t1.5\t| Answer:\t-0.5\n","Completion:\t1.5\t| Answer:\t-1.5\n","Completion:\t2.5\t| Answer:\t-0.5\n","Completion:\t2.5\t| Answer:\t-3.5\n","Completion:\t5.5\t| Answer:\t1.5\n","Completion:\t5.5\t| Answer:\t1.5\n","Completion:\t2.5\t| Answer:\t1.5\n","Completion:\t-5.5\t| Answer:\t-5.5\n","Completion:\t2.5\t| Answer:\t4.5\n","Completion:\t-5.5\t| Answer:\t3.5\n","Completion:\t1.5\t| Answer:\t-3.5\n","Completion:\t1.5\t| Answer:\t0.5\n","Completion:\t1.5\t| Answer:\t0.5\n","Completion:\t2.5\t| Answer:\t-5.5\n","Completion:\t2.5\t| Answer:\t-0.5\n","Completion:\t2.5\t| Answer:\t-4.5\n","Completion:\t5.5\t| Answer:\t-0.5\n","Base model evaluation {'valid_count': 20, 'bin_acc': 0.4, 'mse': 25.95}\n"]}],"source":["basemodel_result = evaluate(completions['base'], answers)\n","print(\"Base model evaluation\", basemodel_result)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:31:16.169826Z","iopub.status.busy":"2024-08-20T20:31:16.169068Z","iopub.status.idle":"2024-08-20T20:31:16.199247Z","shell.execute_reply":"2024-08-20T20:31:16.198079Z","shell.execute_reply.started":"2024-08-20T20:31:16.169792Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Completion:\t-5.5\t| Answer:\t-5.5\n","Completion:\t1.5\t| Answer:\t1.5\n","Completion:\t2.5\t| Answer:\t-0.5\n","Completion:\t-1.5\t| Answer:\t-0.5\n","Completion:\t-0.5\t| Answer:\t-1.5\n","Completion:\t-0.5\t| Answer:\t-0.5\n","Completion:\t-2.5\t| Answer:\t-3.5\n","Completion:\t2.5\t| Answer:\t1.5\n","Completion:\t1.5\t| Answer:\t1.5\n","Completion:\t2.5\t| Answer:\t1.5\n","Completion:\t-3.5\t| Answer:\t-5.5\n","Completion:\t-1.5\t| Answer:\t4.5\n","Completion:\t-2.5\t| Answer:\t3.5\n","Completion:\t1.5\t| Answer:\t-3.5\n","Completion:\t1.5\t| Answer:\t0.5\n","Completion:\t1.5\t| Answer:\t0.5\n","Completion:\t1.5\t| Answer:\t-5.5\n","Completion:\t1.5\t| Answer:\t-0.5\n","Completion:\t-1.5\t| Answer:\t-4.5\n","Completion:\t2.5\t| Answer:\t-0.5\n","Finetuned model evaluation {'valid_count': 20, 'bin_acc': 0.65, 'mse': 9.4}\n"]}],"source":["finetuned_result = evaluate(completions['finetuned'], answers)\n","print(\"Finetuned model evaluation\", finetuned_result)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:36:00.779553Z","iopub.status.busy":"2024-08-20T20:36:00.778415Z","iopub.status.idle":"2024-08-20T20:36:00.822877Z","shell.execute_reply":"2024-08-20T20:36:00.822118Z","shell.execute_reply.started":"2024-08-20T20:36:00.779510Z"},"trusted":true},"outputs":[],"source":["completions_base_parsed = [parse_answer(c) for c in completions['base']]\n","completions_finetuned_parsed = [parse_answer(c) for c in completions['finetuned']]\n","answers_parsed = [parse_answer(c) for c in answers]"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:36:11.028750Z","iopub.status.busy":"2024-08-20T20:36:11.028335Z","iopub.status.idle":"2024-08-20T20:36:11.035917Z","shell.execute_reply":"2024-08-20T20:36:11.034957Z","shell.execute_reply.started":"2024-08-20T20:36:11.028720Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions:  5.5 -5.5 | Base == Answer False\n","Predictions:  2.5  1.5 | Base == Answer False\n","Predictions:  5.5 -0.5 | Base == Answer False\n","Predictions:  1.5 -0.5 | Base == Answer False\n","Predictions:  1.5 -1.5 | Base == Answer False\n","Predictions:  2.5 -0.5 | Base == Answer False\n","Predictions:  2.5 -3.5 | Base == Answer False\n","Predictions:  5.5  1.5 | Base == Answer False\n","Predictions:  5.5  1.5 | Base == Answer False\n","Predictions:  2.5  1.5 | Base == Answer False\n","Predictions: -5.5 -5.5 | Base == Answer True\n","Predictions:  2.5  4.5 | Base == Answer False\n","Predictions: -5.5  3.5 | Base == Answer False\n","Predictions:  1.5 -3.5 | Base == Answer False\n","Predictions:  1.5  0.5 | Base == Answer False\n","Predictions:  1.5  0.5 | Base == Answer False\n","Predictions:  2.5 -5.5 | Base == Answer False\n","Predictions:  2.5 -0.5 | Base == Answer False\n","Predictions:  2.5 -4.5 | Base == Answer False\n","Predictions:  5.5 -0.5 | Base == Answer False\n"]}],"source":["for base, answer in zip(completions_base_parsed, answers_parsed):\n","    if not base:\n","        print(\"No Base\")\n","        continue\n","    space_base = \" \" if base['prediction'] > 0 else \"\"\n","    space_answer = \" \" if answer['prediction'] > 0 else \"\"\n","    is_eq = answer['prediction'] == base['prediction']\n","    print(f\"Predictions: {space_base}{base['prediction']} {space_answer}{answer['prediction']} | Base == Answer {is_eq}\")"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:36:27.801031Z","iopub.status.busy":"2024-08-20T20:36:27.800356Z","iopub.status.idle":"2024-08-20T20:36:27.807558Z","shell.execute_reply":"2024-08-20T20:36:27.806524Z","shell.execute_reply.started":"2024-08-20T20:36:27.800998Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions: -5.5 -5.5 | Finetuned == Answer True\n","Predictions:  1.5  1.5 | Finetuned == Answer True\n","Predictions: -0.5  2.5 | Finetuned == Answer False\n","Predictions: -0.5 -1.5 | Finetuned == Answer False\n","Predictions: -1.5 -0.5 | Finetuned == Answer False\n","Predictions: -0.5 -0.5 | Finetuned == Answer True\n","Predictions: -3.5 -2.5 | Finetuned == Answer False\n","Predictions:  1.5  2.5 | Finetuned == Answer False\n","Predictions:  1.5  1.5 | Finetuned == Answer True\n","Predictions:  1.5  2.5 | Finetuned == Answer False\n","Predictions: -5.5 -3.5 | Finetuned == Answer False\n","Predictions:  4.5 -1.5 | Finetuned == Answer False\n","Predictions:  3.5 -2.5 | Finetuned == Answer False\n","Predictions: -3.5  1.5 | Finetuned == Answer False\n","Predictions:  0.5  1.5 | Finetuned == Answer False\n","Predictions:  0.5  1.5 | Finetuned == Answer False\n","Predictions: -5.5  1.5 | Finetuned == Answer False\n","Predictions: -0.5  1.5 | Finetuned == Answer False\n","Predictions: -4.5 -1.5 | Finetuned == Answer False\n","Predictions: -0.5  2.5 | Finetuned == Answer False\n"]}],"source":["for finetuned, answer in zip(completions_finetuned_parsed, answers_parsed):\n","    if not finetuned:\n","        print(\"No Finetuned\")\n","        continue\n","    space_answer = \" \" if answer['prediction'] > 0 else \"\"\n","    space_finetuned = \" \" if finetuned['prediction'] > 0 else \"\"\n","    is_eq = finetuned['prediction'] == answer['prediction']\n","    print(f\"Predictions: {space_answer}{answer['prediction']} {space_finetuned}{finetuned['prediction']} | Finetuned == Answer {is_eq}\")"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:37:07.624433Z","iopub.status.busy":"2024-08-20T20:37:07.624036Z","iopub.status.idle":"2024-08-20T20:37:07.631677Z","shell.execute_reply":"2024-08-20T20:37:07.630781Z","shell.execute_reply.started":"2024-08-20T20:37:07.624399Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions:  5.5 -5.5 | Base == Finetuned False\n","Predictions:  2.5  1.5 | Base == Finetuned False\n","Predictions:  5.5  2.5 | Base == Finetuned False\n","Predictions:  1.5 -1.5 | Base == Finetuned False\n","Predictions:  1.5 -0.5 | Base == Finetuned False\n","Predictions:  2.5 -0.5 | Base == Finetuned False\n","Predictions:  2.5 -2.5 | Base == Finetuned False\n","Predictions:  5.5  2.5 | Base == Finetuned False\n","Predictions:  5.5  1.5 | Base == Finetuned False\n","Predictions:  2.5  2.5 | Base == Finetuned True\n","Predictions: -5.5 -3.5 | Base == Finetuned False\n","Predictions:  2.5 -1.5 | Base == Finetuned False\n","Predictions: -5.5 -2.5 | Base == Finetuned False\n","Predictions:  1.5  1.5 | Base == Finetuned True\n","Predictions:  1.5  1.5 | Base == Finetuned True\n","Predictions:  1.5  1.5 | Base == Finetuned True\n","Predictions:  2.5  1.5 | Base == Finetuned False\n","Predictions:  2.5  1.5 | Base == Finetuned False\n","Predictions:  2.5 -1.5 | Base == Finetuned False\n","Predictions:  5.5  2.5 | Base == Finetuned False\n"]}],"source":["for base, finetuned in zip(completions_base_parsed, completions_finetuned_parsed):\n","    if not base:\n","        print(\"No Base\")\n","        continue\n","    if not finetuned:\n","        print(\"No Finetuned\")\n","        continue\n","    space_base = \" \" if base['prediction'] > 0 else \"\"\n","    space_finetuned = \" \" if finetuned['prediction'] > 0 else \"\"\n","    is_eq = finetuned['prediction'] == base['prediction']\n","    print(f\"Predictions: {space_base}{base['prediction']} {space_finetuned}{finetuned['prediction']} | Base == Finetuned {is_eq}\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["yXvES6CUnxoO","5rD-9tKrq8E2","awyq5ySJsVe2","uBrLO4WCf7Ub","9rkPfpForYoS","fjcCIZtBgB3q","sSnrdrI9mRAA","q2044dqzBVz2","36281plhTPsW","eDfAF8C5kM6X"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5405938,"sourceId":8977924,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":89261,"modelInstanceId":79891,"sourceId":95268,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":89261,"modelInstanceId":79891,"sourceId":95397,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"047dcce93d5048b6b647f1cb3c8902e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4219fd1c6c142ea8cbbe41c66a6fd7e","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52317ad1f4fb4470b0b221bcdb5d1b84","value":240}},"08854c2134364248a3233434b551c0ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b9428da99ba46ffaf4b862e07207ede":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cbbffeee1774506b48eef11496c9b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0db68bea29e644bcab2a579fb87bf271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e25c3657c7a482d99ab14e24094700f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144e6101bb27400280288b98d713e918":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2c45ca2da95461f943198b2a8b93d46","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81f7d44dd0dc45689b708459df10c761","value":900}},"1ebb62bbbbe44f7c9be5fef39333be0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244a20287aec48af8a42757150c23504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29751286d1eb47ad81d39eed31b1abac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a163537d1e740a28413efde552b0300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed4273e578634ea3a534e2f09d031fb1","placeholder":"​","style":"IPY_MODEL_79b84a811d1c4d4ba3af804ca8dfa315","value":"Saving the dataset (1/1 shards): 100%"}},"2ca0642af68c46639439f1c2d2a3949e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e4b2e72ab3b4dcd83d5382c6c217c9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_901c6fefb887434f9b9015de5fa8c0c3","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4d0e2f164044634b62f57b8cf25929d","value":900}},"2e8eaa8ba6334c11864dfc333cf35697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31eab09e78384a40afd70b9d0296a4bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3864b6ee5bfe43f59f62652259b4784e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f409f0118d243b8a86f470c69f372e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6abd119862244705bd86594c5e438e1b","placeholder":"​","style":"IPY_MODEL_08854c2134364248a3233434b551c0ab","value":" 900/900 [00:01&lt;00:00, 710.54 examples/s]"}},"402a3bcf10cb4ac4b4b831cc30fed454":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"455ef0362bcd4bb984b4154822164249":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4aecd68f2e294d4c8c549c7cba4af701","IPY_MODEL_144e6101bb27400280288b98d713e918","IPY_MODEL_47acbbfe8fad419881c1e2698f9c2a34"],"layout":"IPY_MODEL_93fd7ad358e543ac8e5aa6d9cb298aab"}},"47acbbfe8fad419881c1e2698f9c2a34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4572c769c98415f914bb5b184abd745","placeholder":"​","style":"IPY_MODEL_0cbbffeee1774506b48eef11496c9b73","value":" 900/900 [00:00&lt;00:00, 5990.90 examples/s]"}},"4aecd68f2e294d4c8c549c7cba4af701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0ce274386e04ddf8070d64db608730c","placeholder":"​","style":"IPY_MODEL_0b9428da99ba46ffaf4b862e07207ede","value":"Saving the dataset (1/1 shards): 100%"}},"4dfc0effb5d648d29e04ecd28e8c57d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fc7092531be46a79e2d3a6f77d38f24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52317ad1f4fb4470b0b221bcdb5d1b84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5376f9587933402ba422859e999492ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed331e46cc1a463f828c2dfba96d9296","IPY_MODEL_2e4b2e72ab3b4dcd83d5382c6c217c9b","IPY_MODEL_3f409f0118d243b8a86f470c69f372e9"],"layout":"IPY_MODEL_9a9593098dca4472b120719e5b80739c"}},"5a028a4a33044b339002e40457536735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a49aecc4f8945b9892c275b5a1626a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a163537d1e740a28413efde552b0300","IPY_MODEL_a36975338ea24f9dae5c355627248dd2","IPY_MODEL_f14ba5b13f9a402e8c3809b6c4c07020"],"layout":"IPY_MODEL_f15ba01c1c664f119d1f46a683356ef4"}},"5b5fe12a6dd242fbb1f678c24f8889d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c03165ba1e44f1fb6a0f5e9a1de7130","IPY_MODEL_cc70d5494aa2428fb4535b2ce377ec2d","IPY_MODEL_9ecd6cfe1f5e4dd38daeb66f80c3193b"],"layout":"IPY_MODEL_0e25c3657c7a482d99ab14e24094700f"}},"648cebe8d0364d80be1067334d09b766":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc7092531be46a79e2d3a6f77d38f24","placeholder":"​","style":"IPY_MODEL_86f7cb3a195a4d869c647105a4ab0eee","value":" 4/4 [01:20&lt;00:00, 17.40s/it]"}},"664f48c594944f5d831b536c7ee0e19f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebf33f9a05f6456ca3677182fc74c80c","IPY_MODEL_c773105c13444009a5c1b612522db511","IPY_MODEL_648cebe8d0364d80be1067334d09b766"],"layout":"IPY_MODEL_9fbdfe76b8cb40c38b3220656e94245f"}},"6abd119862244705bd86594c5e438e1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71927857a7e44dcdad2e0df79462ed6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75dbd4b48d4b40a9aa73c389ca4b431c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79b84a811d1c4d4ba3af804ca8dfa315":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c03165ba1e44f1fb6a0f5e9a1de7130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd61c21d4cda47f283752d1f36928ef3","placeholder":"​","style":"IPY_MODEL_5a028a4a33044b339002e40457536735","value":"Map: 100%"}},"7cb91b31a79744d4937c374f0fb029fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bda0f0cca6f642668518e37b9b7c3977","placeholder":"​","style":"IPY_MODEL_2e8eaa8ba6334c11864dfc333cf35697","value":"Filter: 100%"}},"81f7d44dd0dc45689b708459df10c761":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86f7cb3a195a4d869c647105a4ab0eee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"901c6fefb887434f9b9015de5fa8c0c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9387d7e0e98b4534849529e008858964":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93fd7ad358e543ac8e5aa6d9cb298aab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94bd9f1753be45fb91201bbce2b81567":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6fbfcf4602470783234944fe00a80d","placeholder":"​","style":"IPY_MODEL_75dbd4b48d4b40a9aa73c389ca4b431c","value":"Map: 100%"}},"9a9593098dca4472b120719e5b80739c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e6fbfcf4602470783234944fe00a80d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ecd6cfe1f5e4dd38daeb66f80c3193b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71927857a7e44dcdad2e0df79462ed6c","placeholder":"​","style":"IPY_MODEL_eec4724bdc904708aa87119b9c187861","value":" 900/900 [00:08&lt;00:00, 25.95 examples/s]"}},"9fbdfe76b8cb40c38b3220656e94245f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a09ecb5428ff4c9894784d75fbd1ac4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a36975338ea24f9dae5c355627248dd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_402a3bcf10cb4ac4b4b831cc30fed454","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29751286d1eb47ad81d39eed31b1abac","value":240}},"a42763c249d64234ba0eb05462efd3f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a43c8944390e47ffb28dad160ffed250":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ebb62bbbbe44f7c9be5fef39333be0d","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31eab09e78384a40afd70b9d0296a4bc","value":240}},"a4d0e2f164044634b62f57b8cf25929d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac949691abbb4c9c9b79d1928ae15420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cb91b31a79744d4937c374f0fb029fb","IPY_MODEL_a43c8944390e47ffb28dad160ffed250","IPY_MODEL_e76296a04b104dd0b724d72dd23b960f"],"layout":"IPY_MODEL_c1dead594a0c4ee487f19d3f2879a266"}},"b223de2deb454a46ab183c8472db4f27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4219fd1c6c142ea8cbbe41c66a6fd7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba61a21d0ef047b89400ebed07ab1f30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94bd9f1753be45fb91201bbce2b81567","IPY_MODEL_047dcce93d5048b6b647f1cb3c8902e5","IPY_MODEL_d7c51f161f5f4779b7d724eb1caf56c1"],"layout":"IPY_MODEL_f203c7d51d0b4760a8df3d20b12159ff"}},"bcccba20051f4916ab98bd18f9219681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd61c21d4cda47f283752d1f36928ef3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bda0f0cca6f642668518e37b9b7c3977":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0ce274386e04ddf8070d64db608730c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1dead594a0c4ee487f19d3f2879a266":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c773105c13444009a5c1b612522db511":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff22bb776ed44cba97eba3eea25362ac","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ca0642af68c46639439f1c2d2a3949e","value":4}},"cb1b2f2bf1e34dcc9568034fc37db6a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc70d5494aa2428fb4535b2ce377ec2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9387d7e0e98b4534849529e008858964","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0db68bea29e644bcab2a579fb87bf271","value":900}},"ce2af65398c741aaa5ccb4144576638c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce76e0ba88844a9ab693d7daffae81b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4572c769c98415f914bb5b184abd745":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c51f161f5f4779b7d724eb1caf56c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce76e0ba88844a9ab693d7daffae81b4","placeholder":"​","style":"IPY_MODEL_244a20287aec48af8a42757150c23504","value":" 240/240 [00:01&lt;00:00, 152.13 examples/s]"}},"e2c45ca2da95461f943198b2a8b93d46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e76296a04b104dd0b724d72dd23b960f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dfc0effb5d648d29e04ecd28e8c57d4","placeholder":"​","style":"IPY_MODEL_bcccba20051f4916ab98bd18f9219681","value":" 240/240 [00:00&lt;00:00, 607.49 examples/s]"}},"ebf33f9a05f6456ca3677182fc74c80c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3864b6ee5bfe43f59f62652259b4784e","placeholder":"​","style":"IPY_MODEL_ce2af65398c741aaa5ccb4144576638c","value":"Loading checkpoint shards: 100%"}},"ed331e46cc1a463f828c2dfba96d9296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a09ecb5428ff4c9894784d75fbd1ac4e","placeholder":"​","style":"IPY_MODEL_b223de2deb454a46ab183c8472db4f27","value":"Filter: 100%"}},"ed4273e578634ea3a534e2f09d031fb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec4724bdc904708aa87119b9c187861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f14ba5b13f9a402e8c3809b6c4c07020":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb1b2f2bf1e34dcc9568034fc37db6a9","placeholder":"​","style":"IPY_MODEL_a42763c249d64234ba0eb05462efd3f1","value":" 240/240 [00:00&lt;00:00, 2247.82 examples/s]"}},"f15ba01c1c664f119d1f46a683356ef4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f203c7d51d0b4760a8df3d20b12159ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff22bb776ed44cba97eba3eea25362ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}
