{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["yXvES6CUnxoO","5rD-9tKrq8E2","awyq5ySJsVe2","uBrLO4WCf7Ub","9rkPfpForYoS","fjcCIZtBgB3q","sSnrdrI9mRAA","q2044dqzBVz2","36281plhTPsW","eDfAF8C5kM6X"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8979545,"sourceType":"datasetVersion","datasetId":5407035},{"sourceId":8992727,"sourceType":"datasetVersion","datasetId":5416555},{"sourceId":79156,"sourceType":"modelInstanceVersion","modelInstanceId":66501,"modelId":91463}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"047dcce93d5048b6b647f1cb3c8902e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4219fd1c6c142ea8cbbe41c66a6fd7e","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52317ad1f4fb4470b0b221bcdb5d1b84","value":240}},"08854c2134364248a3233434b551c0ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b9428da99ba46ffaf4b862e07207ede":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cbbffeee1774506b48eef11496c9b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0db68bea29e644bcab2a579fb87bf271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e25c3657c7a482d99ab14e24094700f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144e6101bb27400280288b98d713e918":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2c45ca2da95461f943198b2a8b93d46","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81f7d44dd0dc45689b708459df10c761","value":900}},"1ebb62bbbbe44f7c9be5fef39333be0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244a20287aec48af8a42757150c23504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29751286d1eb47ad81d39eed31b1abac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a163537d1e740a28413efde552b0300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed4273e578634ea3a534e2f09d031fb1","placeholder":"​","style":"IPY_MODEL_79b84a811d1c4d4ba3af804ca8dfa315","value":"Saving the dataset (1/1 shards): 100%"}},"2ca0642af68c46639439f1c2d2a3949e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e4b2e72ab3b4dcd83d5382c6c217c9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_901c6fefb887434f9b9015de5fa8c0c3","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4d0e2f164044634b62f57b8cf25929d","value":900}},"2e8eaa8ba6334c11864dfc333cf35697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31eab09e78384a40afd70b9d0296a4bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3864b6ee5bfe43f59f62652259b4784e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f409f0118d243b8a86f470c69f372e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6abd119862244705bd86594c5e438e1b","placeholder":"​","style":"IPY_MODEL_08854c2134364248a3233434b551c0ab","value":" 900/900 [00:01&lt;00:00, 710.54 examples/s]"}},"402a3bcf10cb4ac4b4b831cc30fed454":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"455ef0362bcd4bb984b4154822164249":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4aecd68f2e294d4c8c549c7cba4af701","IPY_MODEL_144e6101bb27400280288b98d713e918","IPY_MODEL_47acbbfe8fad419881c1e2698f9c2a34"],"layout":"IPY_MODEL_93fd7ad358e543ac8e5aa6d9cb298aab"}},"47acbbfe8fad419881c1e2698f9c2a34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4572c769c98415f914bb5b184abd745","placeholder":"​","style":"IPY_MODEL_0cbbffeee1774506b48eef11496c9b73","value":" 900/900 [00:00&lt;00:00, 5990.90 examples/s]"}},"4aecd68f2e294d4c8c549c7cba4af701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0ce274386e04ddf8070d64db608730c","placeholder":"​","style":"IPY_MODEL_0b9428da99ba46ffaf4b862e07207ede","value":"Saving the dataset (1/1 shards): 100%"}},"4dfc0effb5d648d29e04ecd28e8c57d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fc7092531be46a79e2d3a6f77d38f24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52317ad1f4fb4470b0b221bcdb5d1b84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5376f9587933402ba422859e999492ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed331e46cc1a463f828c2dfba96d9296","IPY_MODEL_2e4b2e72ab3b4dcd83d5382c6c217c9b","IPY_MODEL_3f409f0118d243b8a86f470c69f372e9"],"layout":"IPY_MODEL_9a9593098dca4472b120719e5b80739c"}},"5a028a4a33044b339002e40457536735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a49aecc4f8945b9892c275b5a1626a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a163537d1e740a28413efde552b0300","IPY_MODEL_a36975338ea24f9dae5c355627248dd2","IPY_MODEL_f14ba5b13f9a402e8c3809b6c4c07020"],"layout":"IPY_MODEL_f15ba01c1c664f119d1f46a683356ef4"}},"5b5fe12a6dd242fbb1f678c24f8889d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c03165ba1e44f1fb6a0f5e9a1de7130","IPY_MODEL_cc70d5494aa2428fb4535b2ce377ec2d","IPY_MODEL_9ecd6cfe1f5e4dd38daeb66f80c3193b"],"layout":"IPY_MODEL_0e25c3657c7a482d99ab14e24094700f"}},"648cebe8d0364d80be1067334d09b766":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc7092531be46a79e2d3a6f77d38f24","placeholder":"​","style":"IPY_MODEL_86f7cb3a195a4d869c647105a4ab0eee","value":" 4/4 [01:20&lt;00:00, 17.40s/it]"}},"664f48c594944f5d831b536c7ee0e19f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebf33f9a05f6456ca3677182fc74c80c","IPY_MODEL_c773105c13444009a5c1b612522db511","IPY_MODEL_648cebe8d0364d80be1067334d09b766"],"layout":"IPY_MODEL_9fbdfe76b8cb40c38b3220656e94245f"}},"6abd119862244705bd86594c5e438e1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71927857a7e44dcdad2e0df79462ed6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75dbd4b48d4b40a9aa73c389ca4b431c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79b84a811d1c4d4ba3af804ca8dfa315":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c03165ba1e44f1fb6a0f5e9a1de7130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd61c21d4cda47f283752d1f36928ef3","placeholder":"​","style":"IPY_MODEL_5a028a4a33044b339002e40457536735","value":"Map: 100%"}},"7cb91b31a79744d4937c374f0fb029fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bda0f0cca6f642668518e37b9b7c3977","placeholder":"​","style":"IPY_MODEL_2e8eaa8ba6334c11864dfc333cf35697","value":"Filter: 100%"}},"81f7d44dd0dc45689b708459df10c761":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86f7cb3a195a4d869c647105a4ab0eee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"901c6fefb887434f9b9015de5fa8c0c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9387d7e0e98b4534849529e008858964":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93fd7ad358e543ac8e5aa6d9cb298aab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94bd9f1753be45fb91201bbce2b81567":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6fbfcf4602470783234944fe00a80d","placeholder":"​","style":"IPY_MODEL_75dbd4b48d4b40a9aa73c389ca4b431c","value":"Map: 100%"}},"9a9593098dca4472b120719e5b80739c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e6fbfcf4602470783234944fe00a80d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ecd6cfe1f5e4dd38daeb66f80c3193b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71927857a7e44dcdad2e0df79462ed6c","placeholder":"​","style":"IPY_MODEL_eec4724bdc904708aa87119b9c187861","value":" 900/900 [00:08&lt;00:00, 25.95 examples/s]"}},"9fbdfe76b8cb40c38b3220656e94245f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a09ecb5428ff4c9894784d75fbd1ac4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a36975338ea24f9dae5c355627248dd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_402a3bcf10cb4ac4b4b831cc30fed454","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29751286d1eb47ad81d39eed31b1abac","value":240}},"a42763c249d64234ba0eb05462efd3f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a43c8944390e47ffb28dad160ffed250":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ebb62bbbbe44f7c9be5fef39333be0d","max":240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31eab09e78384a40afd70b9d0296a4bc","value":240}},"a4d0e2f164044634b62f57b8cf25929d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac949691abbb4c9c9b79d1928ae15420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cb91b31a79744d4937c374f0fb029fb","IPY_MODEL_a43c8944390e47ffb28dad160ffed250","IPY_MODEL_e76296a04b104dd0b724d72dd23b960f"],"layout":"IPY_MODEL_c1dead594a0c4ee487f19d3f2879a266"}},"b223de2deb454a46ab183c8472db4f27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4219fd1c6c142ea8cbbe41c66a6fd7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba61a21d0ef047b89400ebed07ab1f30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94bd9f1753be45fb91201bbce2b81567","IPY_MODEL_047dcce93d5048b6b647f1cb3c8902e5","IPY_MODEL_d7c51f161f5f4779b7d724eb1caf56c1"],"layout":"IPY_MODEL_f203c7d51d0b4760a8df3d20b12159ff"}},"bcccba20051f4916ab98bd18f9219681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd61c21d4cda47f283752d1f36928ef3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bda0f0cca6f642668518e37b9b7c3977":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0ce274386e04ddf8070d64db608730c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1dead594a0c4ee487f19d3f2879a266":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c773105c13444009a5c1b612522db511":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff22bb776ed44cba97eba3eea25362ac","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ca0642af68c46639439f1c2d2a3949e","value":4}},"cb1b2f2bf1e34dcc9568034fc37db6a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc70d5494aa2428fb4535b2ce377ec2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9387d7e0e98b4534849529e008858964","max":900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0db68bea29e644bcab2a579fb87bf271","value":900}},"ce2af65398c741aaa5ccb4144576638c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce76e0ba88844a9ab693d7daffae81b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4572c769c98415f914bb5b184abd745":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c51f161f5f4779b7d724eb1caf56c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce76e0ba88844a9ab693d7daffae81b4","placeholder":"​","style":"IPY_MODEL_244a20287aec48af8a42757150c23504","value":" 240/240 [00:01&lt;00:00, 152.13 examples/s]"}},"e2c45ca2da95461f943198b2a8b93d46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e76296a04b104dd0b724d72dd23b960f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dfc0effb5d648d29e04ecd28e8c57d4","placeholder":"​","style":"IPY_MODEL_bcccba20051f4916ab98bd18f9219681","value":" 240/240 [00:00&lt;00:00, 607.49 examples/s]"}},"ebf33f9a05f6456ca3677182fc74c80c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3864b6ee5bfe43f59f62652259b4784e","placeholder":"​","style":"IPY_MODEL_ce2af65398c741aaa5ccb4144576638c","value":"Loading checkpoint shards: 100%"}},"ed331e46cc1a463f828c2dfba96d9296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a09ecb5428ff4c9894784d75fbd1ac4e","placeholder":"​","style":"IPY_MODEL_b223de2deb454a46ab183c8472db4f27","value":"Filter: 100%"}},"ed4273e578634ea3a534e2f09d031fb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec4724bdc904708aa87119b9c187861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f14ba5b13f9a402e8c3809b6c4c07020":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb1b2f2bf1e34dcc9568034fc37db6a9","placeholder":"​","style":"IPY_MODEL_a42763c249d64234ba0eb05462efd3f1","value":" 240/240 [00:00&lt;00:00, 2247.82 examples/s]"}},"f15ba01c1c664f119d1f46a683356ef4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f203c7d51d0b4760a8df3d20b12159ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff22bb776ed44cba97eba3eea25362ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Llama 3 fine-tuning for finance prediction","metadata":{"id":"OccEUGZUr224"}},{"cell_type":"code","source":"!pip install finnhub-python yfinance transformers bitsandbytes accelerate datasets peft wandb --quiet","metadata":{"id":"wUI6SMqombtx","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d2b40c8-8837-4529-e8ee-ff8ae1cf1977","execution":{"iopub.status.busy":"2024-07-20T03:26:36.981589Z","iopub.execute_input":"2024-07-20T03:26:36.982263Z","iopub.status.idle":"2024-07-20T03:27:18.022523Z","shell.execute_reply.started":"2024-07-20T03:26:36.982228Z","shell.execute_reply":"2024-07-20T03:27:18.021239Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Collect data","metadata":{"id":"tMd-yyKO9eOV"}},{"cell_type":"markdown","source":"### Libraries\n","metadata":{"id":"L4oHEsLjpZYL"}},{"cell_type":"code","source":"import os\nimport re\nimport csv\nimport math\nimport time\nimport json\nimport random\nimport pandas as pd\nfrom tqdm import tqdm\nfrom functools import partial\nfrom datetime import datetime\nfrom collections import defaultdict","metadata":{"id":"IXGcsf2dDxfG","scrolled":true,"execution":{"iopub.status.busy":"2024-07-20T03:27:18.024952Z","iopub.execute_input":"2024-07-20T03:27:18.025643Z","iopub.status.idle":"2024-07-20T03:27:18.439431Z","shell.execute_reply.started":"2024-07-20T03:27:18.025603Z","shell.execute_reply":"2024-07-20T03:27:18.438467Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import finnhub\nimport yfinance as yf\n\nimport datasets\nfrom datasets import Dataset\n\nimport wandb\nimport torch\nimport transformers\nfrom torch.optim import AdamW\nfrom transformers import (\n    AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n    GenerationConfig, pipeline, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n)\n\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel","metadata":{"id":"B0kgDCe6IIa2","scrolled":true,"execution":{"iopub.status.busy":"2024-07-20T03:27:18.440725Z","iopub.execute_input":"2024-07-20T03:27:18.441532Z","iopub.status.idle":"2024-07-20T03:27:36.633265Z","shell.execute_reply.started":"2024-07-20T03:27:18.441497Z","shell.execute_reply":"2024-07-20T03:27:36.632441Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-07-20 03:27:25.522100: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-20 03:27:25.522211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-20 03:27:25.656327: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:27:36.636183Z","iopub.execute_input":"2024-07-20T03:27:36.637133Z","iopub.status.idle":"2024-07-20T03:27:36.652244Z","shell.execute_reply.started":"2024-07-20T03:27:36.637093Z","shell.execute_reply":"2024-07-20T03:27:36.651381Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"os.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"id":"mh61ETlidZXH","scrolled":true,"execution":{"iopub.status.busy":"2024-07-19T16:48:55.183335Z","iopub.execute_input":"2024-07-19T16:48:55.183679Z","iopub.status.idle":"2024-07-19T16:48:55.362508Z","shell.execute_reply.started":"2024-07-19T16:48:55.183653Z","shell.execute_reply":"2024-07-19T16:48:55.361568Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Get news and stocks of companies","metadata":{"id":"yXvES6CUnxoO"}},{"cell_type":"code","source":"finnhub_client = finnhub.Client(api_key=user_secrets.get_secret(\"FINNHUB_API_KEY\"))","metadata":{"id":"Z9OfTMExmRB-","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bin_mapping(ret):\n    up_down = 'U' if ret >= 0 else 'D'\n    integer = math.ceil(abs(100 * ret))\n    return up_down + (str(integer) if integer <= 5 else '5+')","metadata":{"id":"TgQRu4Z3n5ZT","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_returns(stock_ticker, start_date, end_date):\n    stock_data = yf.download(stock_ticker, start=start_date, end=end_date)\n\n    weekly_data = stock_data['Adj Close'].resample('W').ffill()\n    weekly_returns = weekly_data.pct_change()[1:]\n    weekly_start_prices = weekly_data[:-1]\n    weekly_end_prices = weekly_data[1:]\n\n    weekly_data = pd.DataFrame({\n        'start_date': weekly_start_prices.index,\n        'start_price': weekly_start_prices.values,\n        'end_date': weekly_end_prices.index,\n        'end_price': weekly_end_prices.values,\n        'weekly_returns': weekly_returns.values\n    })\n\n    weekly_data['bin_label'] = weekly_data['weekly_returns'].map(bin_mapping)\n\n    return weekly_data","metadata":{"id":"CIS6j5SlnxJ_","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_news(ticker, data):\n    news_list = []\n\n    for _, row in data.iterrows():\n        start_date = row['start_date'].strftime('%Y-%m-%d')\n        end_date = row['end_date'].strftime('%Y-%m-%d')\n        time.sleep(1) # control qpm\n        weekly_news = finnhub_client.company_news(ticker, _from=start_date, to=end_date)\n        weekly_news = [\n            {\n                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y%m%d%H%M%S'),\n                \"headline\": n['headline'],\n                \"summary\": n['summary'],\n            } for n in weekly_news\n        ]\n        weekly_news.sort(key=lambda x: x['date'])\n        news_list.append(json.dumps(weekly_news))\n\n    data['news'] = news_list\n\n    return data","metadata":{"id":"OXJfhwENoO7G","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_basics(ticker, data, start_date, always=False):\n    basic_financials = finnhub_client.company_basic_financials(ticker, 'all')\n\n    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n\n    for metric, value_list in basic_financials['series']['quarterly'].items():\n        for value in value_list:\n            basic_dict[value['period']].update({metric: value['v']})\n\n    for k, v in basic_dict.items():\n        v.update({'period': k})\n        basic_list.append(v)\n\n    basic_list.sort(key=lambda x: x['period'])\n\n    for i, row in data.iterrows():\n\n        start_date = row['end_date'].strftime('%Y-%m-%d')\n        last_start_date = start_date if i < 2 else data.loc[i-2, 'start_date'].strftime('%Y-%m-%d')\n\n        used_basic = {}\n        for basic in basic_list[::-1]:\n            if (always and basic['period'] < start_date) or (last_start_date <= basic['period'] < start_date):\n                used_basic = basic\n                break\n        final_basics.append(json.dumps(used_basic))\n\n    data['basics'] = final_basics\n\n    return data","metadata":{"id":"OdTlWVR6oQRt","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prep_data_for_ticker(ticker, data_dir, start_date, end_date):\n\n    _ = get_returns(ticker, start_date, end_date)\n    data = get_news(ticker, _)\n\n    data = get_basics(ticker, data, start_date)\n    data.to_csv(f\"{data_dir}/{ticker}_{start_date}_{end_date}.csv\")","metadata":{"id":"tho8tUOuqWwE","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CSV","metadata":{"id":"awyq5ySJsVe2"}},{"cell_type":"code","source":"def append_to_csv(filename, input_data, output_data):\n    with open(filename, mode='a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([input_data, output_data])","metadata":{"id":"7dTX-mDdqsGX","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_csv(filename):\n    with open(filename, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"prompt\", \"answer\"])","metadata":{"id":"qQbE2jwNquCQ","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prompts","metadata":{"id":"uBrLO4WCf7Ub"}},{"cell_type":"code","source":"def create_company_profile(ticker):\n    profile = finnhub_client.company_profile2(symbol=ticker)\n    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. \" \\\n                      \"Incorporated and publicly traded since {ipo}, the company has established its reputation \" \\\n                      \"as one of the key players in the market. \\n\\n{name} operates primarily in the {country}, \" \\\n                      \"trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, \" \\\n                      \"the company continues to innovate and drive progress within the industry.\"\n\n    formatted_str = company_template.format(**profile)\n\n    return formatted_str","metadata":{"id":"G_AEhAaLf47L","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_bin_label(bin_lb):\n    lb = bin_lb.replace('U', 'up by ')\n    lb = lb.replace('D', 'down by ')\n    lb = lb.replace('1', '0-1%')\n    lb = lb.replace('2', '1-2%')\n    lb = lb.replace('3', '2-3%')\n    lb = lb.replace('4', '3-4%')\n    if lb.endswith('+'):\n        lb = lb.replace('5+', 'more than 5%')\n    else:\n        lb = lb.replace('5', '4-5%')\n\n    return lb","metadata":{"id":"EyDQ18rcsIR5","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_news(news, n=5):\n    if not 0 <= n <= len(news):\n        raise ValueError(f\"Bad N\")\n    sampled_indices = random.sample(range(len(news)), n)\n    return [news[i] for i in sampled_indices]","metadata":{"id":"GpN0BWOwnGYa","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prompt_by_row(ticker, row):\n\n    start_date = row['start_date'].strftime('%Y-%m-%d') if isinstance(row['start_date'], datetime) else str(row['start_date'])\n    end_date = row['end_date'].strftime('%Y-%m-%d') if isinstance(row['end_date'], datetime) else str(row['end_date'])\n\n    term = 'increased' if row['end_price'] > row['start_price'] else 'decreased'\n    head = f\"From {start_date} to {end_date}, {ticker}'s stock price {term} \" \\\n           f\"from {row['start_price']:.2f} to {row['end_price']:.2f}. News during this period are listed below:\\n\\n\"\n\n    news = json.loads(row[\"news\"])\n    news = [f\"[Headline]: {n['headline']}\\n[Summary]: {n['summary']}\\n\"\n            for n in news\n            if n['date'][:8] <= end_date.replace('-', '')\n            and not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n\n    basics = json.loads(row['basics'])\n    if not basics:\n        basics_str = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n    else:\n        basics_str = f\"Some recent basic financials of {ticker}, reported at {basics['period']}, are presented below:\\n\\n[Basic Financials]:\\n\\n\"\n        basics_str += \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n\n    return head, news, basics_str","metadata":{"id":"DFc7AkQTouGq","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_prompt(ticker, row, prev_rows, max_weeks, info_prompt):\n    prompt = \"\"\n    if prev_rows:\n        num_prev_rows = min(random.choice(range(1, max_weeks+1)), len(prev_rows))\n        for i in range(-num_prev_rows, 0):\n            prompt += f\"\\n{prev_rows[i][0]}\"  # Add Price Movement (Head)\n            sampled_news = sample_news(prev_rows[i][1], min(5, len(prev_rows[i][1])))\n            if sampled_news:\n                prompt += \"\\n\".join(sampled_news)\n            else:\n                prompt += \"\\nNo relative news reported.\"\n\n    head, news, basics = get_prompt_by_row(ticker, row)\n    prev_rows.append((head, news, basics))\n\n    if len(prev_rows) > max_weeks:\n        prev_rows.pop(0)\n\n    if not prompt:\n        return \"\"\n\n    prediction = map_bin_label(row['bin_label'])\n    prompt = f\"{info_prompt}\\n{prompt}\\n{basics}\"\n\n    instruction_prompt = \"\\n\\nBased on all the information before {start_date}, let's first analyze the positive developments and potential concerns for {ticker}. \" \\\n                          \"Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n                          \"Then let's assume your prediction for next week ({start_date} to {end_date}) is {prediction}. \" \\\n                          \"Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, \" \\\n                          \"and thus not appearing as a foundational factor of your analysis.\"\n\n    prompt += instruction_prompt.format(\n        start_date=row['start_date'],\n        end_date=row['end_date'],\n        ticker=ticker,\n        prediction=prediction,\n    )\n\n    return prompt.strip()","metadata":{"id":"PvkO275nx3Ps","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_prompts(ticker, data_dir, start_date, end_date, max_weeks):\n    df = pd.read_csv(f'{data_dir}/{ticker}_{start_date}_{end_date}.csv')\n\n    info_prompt = create_company_profile(ticker)\n    prev_rows = []\n    all_prompts = []\n\n    for _, row in df.iterrows():\n        prompt = build_prompt(ticker, row, prev_rows, max_weeks, info_prompt)\n        if prompt:\n            all_prompts.append(prompt)\n\n    return all_prompts","metadata":{"id":"ezWWyx0UxlI_","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Llama3","metadata":{"id":"9rkPfpForYoS"}},{"cell_type":"code","source":"model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"","metadata":{"id":"q336sgtcTdow","scrolled":true,"execution":{"iopub.status.busy":"2024-07-10T18:56:19.701487Z","iopub.execute_input":"2024-07-10T18:56:19.702442Z","iopub.status.idle":"2024-07-10T18:56:19.706709Z","shell.execute_reply.started":"2024-07-10T18:56:19.702406Z","shell.execute_reply":"2024-07-10T18:56:19.705626Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"id":"GnQmxVUaS-CA","scrolled":true,"outputId":"1635777a-0a12-4763-9054-3ef1ccfb39ea","execution":{"iopub.status.busy":"2024-07-10T18:58:47.708225Z","iopub.execute_input":"2024-07-10T18:58:47.708627Z","iopub.status.idle":"2024-07-10T18:59:35.253650Z","shell.execute_reply.started":"2024-07-10T18:58:47.708591Z","shell.execute_reply":"2024-07-10T18:59:35.252511Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acccf441284242c593b224e9f1996d92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5088ecbe667748c0977fdd78d7c48f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c94a43a587d442295815eee64a38ae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a1085514664f66812667becef869e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a37e2b678d6a433d9b9b2cc98c4d12c7"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"generation_config = GenerationConfig.from_pretrained(model_id)\ngeneration_config.temperature = 0.001\n\nllama3 = pipeline(\n  \"text-generation\",\n  model=model,\n  tokenizer=tokenizer,\n  generation_config=generation_config,\n)","metadata":{"execution":{"iopub.execute_input":"2024-07-03T17:54:35.699797Z","iopub.status.busy":"2024-07-03T17:54:35.699408Z","iopub.status.idle":"2024-07-03T17:54:35.992211Z","shell.execute_reply":"2024-07-03T17:54:35.990677Z","shell.execute_reply.started":"2024-07-03T17:54:35.699769Z"},"id":"L5l0ZOQTUbBT","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Llama 3 completion","metadata":{"id":"fjcCIZtBgB3q"}},{"cell_type":"code","source":"def get_completion(messages):\n    prompt = tokenizer.apply_chat_template(\n      messages,\n      tokenize=False\n    )\n\n    outputs = llama3(prompt)\n    return outputs\n\ndef get_assistant_response(output):\n    gen_text = output[0]['generated_text']\n    assistant_text = gen_text.rsplit('<|eot_id|>', 1)[1]\n    response = assistant_text.replace('assistant\\n\\n', \"\", 1)\n\n    return response","metadata":{"id":"gRrDQiUATJ9J","scrolled":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.352339Z","iopub.status.idle":"2024-07-10T18:58:44.352745Z","shell.execute_reply.started":"2024-07-10T18:58:44.352528Z","shell.execute_reply":"2024-07-10T18:58:44.352544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def llama3_completion(tickers, data_dir, start_date, end_date, max_weeks=3):\n\n    for ticker in tqdm(tickers):\n\n        print(\"Processing ticker:\", ticker)\n\n        csv_file = f'{data_dir}/{ticker}_{start_date}_{end_date}_llama3.csv'\n\n        if not os.path.exists(csv_file):\n            initialize_csv(csv_file)\n            pre_done = 0\n        else:\n            df = pd.read_csv(csv_file)\n            pre_done = len(df)\n\n        prompts = create_prompts(ticker, data_dir, start_date, end_date, max_weeks)\n        system_prompt = \"You are a seasoned stock market analyst. \" \\\n                        \"Your task is to list the positive developments and potential \" \\\n                        \"concerns for companies based on relevant news and basic financials from the past weeks, \" \\\n                        \"then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n                        \"Your answer format should be as follows: \" \\\n                        \"\\n\\n[Positive Developments]:\\n1. ...\" \\\n                        \"\\n\\n[Potential Concerns]:\\n1. ...\" \\\n                        \"\\n\\n[Prediction & Analysis]:\\n...\\n\"\n\n        for i, prompt in enumerate(prompts):\n            if i < pre_done:\n                continue\n\n            completion = get_completion(\n                  messages=[\n                      {\"role\": \"system\", \"content\": system_prompt},\n                      {\"role\": \"user\", \"content\": prompt}\n                    ]\n            )\n\n            answer = get_assistant_response(completion)\n            append_to_csv(csv_file, prompt, answer)","metadata":{"id":"VXlCN9Ik8Zpm","scrolled":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.354186Z","iopub.status.idle":"2024-07-10T18:58:44.354560Z","shell.execute_reply.started":"2024-07-10T18:58:44.354379Z","shell.execute_reply":"2024-07-10T18:58:44.354395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare data for training","metadata":{"id":"sSnrdrI9mRAA"}},{"cell_type":"code","source":"TICKERS = [\n    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n\n    ## With my account there is access only to the US tickers\n\n    # \"ADS.DE\", \"ADYEN.AS\", \"AD.AS\", \"AI.PA\", \"AIR.PA\", \"ALV.DE\",\n    # \"ABI.BR\", \"ASML.AS\", \"CS.PA\", \"BAS.DE\", \"BAYN.DE\", \"BBVA.MC\",\n    # \"SAN.MC\", \"BMW.DE\", \"BNP.PA\", \"BN.PA\", \"DAI.DE\", \"DPW.DE\", \"DTE.DE\",\n    # \"ENEL.MI\", \"ENGI.PA\", \"EL.PA\", \"FRE.DE\", \"IBE.MC\", \"ITX.MC\", \"IFX.DE\",\n    # \"INGA.AS\", \"ISP.MI\", \"KER.PA\", \"AD.AS\", \"PHIA.AS\", \"OR.PA\", \"LIN.DE\",\n    # \"MC.PA\", \"MUV2.DE\", \"NOKIA.SE\", \"ORA.PA\", \"RI.PA\", \"SAF.PA\", \"SAN.PA\",\n    # \"SAP.DE\", \"SU.PA\", \"SIE.DE\", \"GLE.PA\", \"STM.PA\", \"TEF.MC\", \"TTE.PA\",\n    # \"UNA.AS\", \"DG.PA\", \"VOW3.DE\"\n]","metadata":{"id":"VmpIVCvuqHi4","scrolled":true,"execution":{"iopub.status.busy":"2024-07-10T18:58:44.356316Z","iopub.status.idle":"2024-07-10T18:58:44.356731Z","shell.execute_reply.started":"2024-07-10T18:58:44.356509Z","shell.execute_reply":"2024-07-10T18:58:44.356526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"START_DATE = \"2023-09-01\"\nEND_DATE = \"2024-06-01\"\n\nDATA_DIR = f\"./llama_{START_DATE}_{END_DATE}\"\nos.makedirs(DATA_DIR, exist_ok=True)","metadata":{"id":"2XS0PlXuodW4","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ticker in TICKERS:\n    prep_data_for_ticker(ticker, DATA_DIR, START_DATE, END_DATE)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZFhwdGirK80","outputId":"28919a25-6db7-410f-a012-116e11eb6d2a","scrolled":true},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n[*********************100%%**********************]  1 of 1 completed\n"}]},{"cell_type":"code","source":"llama3_completion(TICKERS, DATA_DIR, START_DATE, END_DATE)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELLPFLtyxEIU","outputId":"885e546d-da8e-40d6-854f-0fdef146ee38","scrolled":true},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"  0%|          | 0/30 [00:00<?, ?it/s]"},{"name":"stdout","output_type":"stream","text":"Processing ticker: AXP\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":"  7%|▋         | 2/30 [00:00<00:08,  3.20it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: AMGN\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: AAPL\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 13%|█▎        | 4/30 [00:00<00:05,  5.18it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: BA\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: CAT\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 20%|██        | 6/30 [00:01<00:03,  6.54it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: CSCO\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: CVX\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 27%|██▋       | 8/30 [00:01<00:02,  7.47it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: GS\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: HD\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 33%|███▎      | 10/30 [00:01<00:02,  7.44it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: HON\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: IBM\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 40%|████      | 12/30 [00:02<00:02,  7.16it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: INTC\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: JNJ\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 47%|████▋     | 14/30 [00:02<00:02,  7.56it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: KO\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: JPM\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 53%|█████▎    | 16/30 [00:02<00:01,  7.98it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: MCD\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: MMM\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 60%|██████    | 18/30 [00:02<00:01,  7.95it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: MRK\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: MSFT\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 67%|██████▋   | 20/30 [00:03<00:01,  8.01it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: NKE\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: PG\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 73%|███████▎  | 22/30 [00:03<00:00,  8.58it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: TRV\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: UNH\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 80%|████████  | 24/30 [00:03<00:00,  8.80it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: CRM\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: VZ\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":" 87%|████████▋ | 26/30 [00:03<00:00,  8.71it/s]"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nProcessing ticker: V\n\n\n\nCREATING PROMPTS\n\n\n\nCREATING PROMPTS END\n\n\n\nProcessing ticker: WBA\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n\n\n\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":" 90%|█████████ | 27/30 [09:19<08:20, 166.93s/it]"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nProcessing ticker: WMT\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":" 93%|█████████▎| 28/30 [36:38<20:17, 608.63s/it]"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nProcessing ticker: DIS\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":" 97%|█████████▋| 29/30 [1:04:19<15:24, 924.34s/it]"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nProcessing ticker: DOW\n\n\n\nCREATING PROMPTS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"CREATING PROMPTS END\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n\n\n\nCOMPLETION IN PROCESS\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 30/30 [1:31:59<00:00, 183.97s/it] "},{"name":"stdout","output_type":"stream","text":"COMPLETION FINISHED\n\n\n\nEXTRACTING RESPONSE\n"},{"name":"stderr","output_type":"stream","text":"\n"}]},{"cell_type":"markdown","source":"## Transform for training","metadata":{"id":"q2044dqzBVz2"}},{"cell_type":"markdown","source":"### Methods","metadata":{"id":"eDfAF8C5kM6X"}},{"cell_type":"code","source":"def gen2train(ticker, data_dir, tokenizer):\n    csv_file = f'{data_dir}/{ticker}.csv'\n    df = pd.read_csv(csv_file)\n    prompts, answers, periods, labels = [], [], [], []\n\n    for i, row in df.iterrows():\n        prompt, answer = row['prompt'], row['answer']\n        res = re.search(r\"Then let's assume your prediction for next week \\((.*)\\) is ((:?up|down) by .*%).\", prompt)\n        period, label = res.group(1), res.group(2)\n        prompt = re.sub(\n            r\"Then let's assume your prediction for next week \\((.*)\\) is (up|down) by ((:?.*)%). Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\",\n            f\"Then make your prediction of the {ticker} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\",\n            prompt\n        )\n        answer = re.sub(\n            r\"\\[Prediction & Analysis\\]:\\s*\",\n            f\"[Prediction & Analysis]:\\nPrediction: {label.capitalize()}\\nAnalysis: \",\n            answer\n        )\n\n        system_prompt = \"You are a seasoned stock market analyst. \" \\\n                        \"Your task is to list the positive developments and potential \" \\\n                        \"concerns for companies based on relevant news and basic financials from the past weeks, \" \\\n                        \"then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n                        \"Your answer format should be as follows: \" \\\n                        \"\\n\\n[Positive Developments]:\" \\\n                        \"\\n1. ...\" \\\n                        \"\\n\\n[Potential Concerns]:\" \\\n                        \"\\n1. ...\" \\\n                        \"\\n\\n[Prediction & Analysis]:\" \\\n                        \"\\nPrediction: ...\" \\\n                        \"\\nAnalysis: ...\\n\"\n\n        messages=[\n          {\"role\": \"system\", \"content\": system_prompt},\n          {\"role\": \"user\", \"content\": prompt}\n        ]\n        train_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\n        prompts.append(train_prompt)\n        answers.append(answer)\n        periods.append(period)\n        labels.append(label)\n\n    return {\n        \"prompt\": prompts,\n        \"answer\": answers,\n        \"period\": periods,\n        \"label\": labels,\n    }","metadata":{"id":"nan6PQiRBYjG","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:27:48.627707Z","iopub.execute_input":"2024-07-17T17:27:48.628556Z","iopub.status.idle":"2024-07-17T17:27:48.638653Z","shell.execute_reply.started":"2024-07-17T17:27:48.628523Z","shell.execute_reply":"2024-07-17T17:27:48.637802Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def transform2train(tickers, data_dir, tokenizer):\n    train_list, test_list = [], []\n    train_size = 0.8\n\n    for ticker in tickers:\n        data_dict = gen2train(ticker, data_dir, tokenizer)\n\n        dataset = Dataset.from_dict(data_dict)\n        train_split = round(train_size * len(dataset))\n\n        train_list.append(dataset.select(range(train_split)))\n        test_list.append(dataset.select(range(train_split, len(dataset))))\n\n    train_dataset = datasets.concatenate_datasets(train_list)\n    test_dataset = datasets.concatenate_datasets(test_list)\n\n    dataset = datasets.DatasetDict({\n      'train': train_dataset,\n      'test': test_dataset\n    })\n\n    return dataset","metadata":{"id":"LxwT8bpNBY9S","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:24:35.487671Z","iopub.execute_input":"2024-07-17T17:24:35.488357Z","iopub.status.idle":"2024-07-17T17:24:35.495336Z","shell.execute_reply.started":"2024-07-17T17:24:35.488324Z","shell.execute_reply":"2024-07-17T17:24:35.494304Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Transform","metadata":{"id":"F4XAYQ6VkS3r"}},{"cell_type":"code","source":"TICKERS = [\n    \"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n]","metadata":{"id":"4PnscvX4Bcxq","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:25:48.073560Z","iopub.execute_input":"2024-07-17T17:25:48.074448Z","iopub.status.idle":"2024-07-17T17:25:48.080689Z","shell.execute_reply.started":"2024-07-17T17:25:48.074407Z","shell.execute_reply":"2024-07-17T17:25:48.079752Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/llama-2023-09-01-2024-06-01\"","metadata":{"id":"qq_VUq39BdXQ","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:31:44.581617Z","iopub.execute_input":"2024-07-17T17:31:44.581982Z","iopub.status.idle":"2024-07-17T17:31:44.586784Z","shell.execute_reply.started":"2024-07-17T17:31:44.581955Z","shell.execute_reply":"2024-07-17T17:31:44.585899Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\"\nfinance_tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\n\n# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n# tokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRoV431sTGyD","outputId":"27f443e7-e87c-480b-c796-423a96f72dc5","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:27:29.116299Z","iopub.execute_input":"2024-07-17T17:27:29.116668Z","iopub.status.idle":"2024-07-17T17:27:30.731769Z","shell.execute_reply.started":"2024-07-17T17:27:29.116640Z","shell.execute_reply":"2024-07-17T17:27:30.730924Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e6dd3ec94f41b1b863991da31d798a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21691a2013f84dd08e774e38a73324cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68af2a03c2614af0b2d11cc6663db758"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"llama3_dataset = transform2train(TICKERS, DATA_DIR, finance_tokenizer)","metadata":{"id":"8hHp7Gm7jxJy","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:31:46.357781Z","iopub.execute_input":"2024-07-17T17:31:46.358424Z","iopub.status.idle":"2024-07-17T17:31:47.157827Z","shell.execute_reply.started":"2024-07-17T17:31:46.358394Z","shell.execute_reply":"2024-07-17T17:31:47.157037Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n","output_type":"stream"}]},{"cell_type":"code","source":"llama3_dataset['train'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yonKOPXko9e","outputId":"10362916-a75d-4b83-868b-31447dd7dd50","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:31:52.460296Z","iopub.execute_input":"2024-07-17T17:31:52.460662Z","iopub.status.idle":"2024-07-17T17:31:52.470589Z","shell.execute_reply.started":"2024-07-17T17:31:52.460634Z","shell.execute_reply":"2024-07-17T17:31:52.469657Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'prompt': \"<|im_start|>system\\nYou are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. Your answer format should be as follows: \\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]:\\nPrediction: ...\\nAnalysis: ...\\n<|im_end|>\\n<|im_start|>user\\n[Company Introduction]:\\n\\nAmerican Express Co is a leading entity in the Financial Services sector. Incorporated and publicly traded since 1977-05-18, the company has established its reputation as one of the key players in the market. \\n\\nAmerican Express Co operates primarily in the US, trading under the ticker AXP on the NEW YORK STOCK EXCHANGE, INC.. As a dominant force in the Financial Services space, the company continues to innovate and drive progress within the industry.\\n\\nFrom 2023-09-03 to 2023-09-10, AXP's stock price decreased from 157.97 to 155.80. News during this period are listed below:\\n\\n[Headline]: September Rally? 3 Financial Stocks to Buy Before Liftoff\\n[Summary]: A September rally may not be in the cards for financial stocks, as the stock market is off to a lackluster start during this historically very poor month for equities. To make matters worse, Wall Street is upset by slight increases in interest rates and oil prices that we’ve seen so far in September. However, I believe that by Thanksgiving financial stocks will attain liftoff. That’s because I agree with Citizens Financial (NYSE:CFG) CEO Bruce Van Saun who told Bloomberg TV on Sept. 7 that The F\\n\\n[Headline]: Warren Buffett’s Biggest Bets: The 7 Stocks Dominating His Portfolio\\n[Summary]: Since taking over the reins of Berkshire Hathaway (NYSE:BRK-A, NYSE:BRK-B) as CEO in 1965, Warren Buffett has overseen compounded gains of 20% a year. That’s more than double the returns of the S&P 500. Not every year was a winner. At numerous points over the past 58 years, Buffett lost to the popular benchmark index. Sometimes by a wide margin. But Buffett’s strategy of buying excellent companies at fair prices and then holding them long-term continues to pay off. We’re talking about an aggrega\\n\\n[Headline]: American Express (AXP) Dips More Than Broader Markets: What You Should Know\\n[Summary]: American Express (AXP) closed the most recent trading day at $156.78, moving -0.77% from the previous trading session.\\n\\n[Headline]: American Express Company (AXP) Is a Trending Stock: Facts to Know Before Betting on It\\n[Summary]: American Express (AXP) has received quite a bit of attention from Zacks.com users lately. Therefore, it is wise to be aware of the facts that can impact the stock's prospects.\\n\\n[Headline]: U.S. Wide-Moat Stocks On Sale - The September 2023 Heat Map\\n[Summary]: Our 3-step process focuses on wide-moat stocks (as per Morningstarâ\\x80\\x99s rating). Find out the heat map of the most investable candidates.\\n\\n[Basic Financials]:\\n\\nNo basic financial reported.\\n\\nBased on all the information before 2023-09-10, let's first analyze the positive developments and potential concerns for AXP. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. Then make your prediction of the AXP stock price movement for next week (2023-09-10 to 2023-09-17). Provide a summary analysis to support your prediction.<|im_end|>\\n<|im_start|>assistant\\n\",\n 'answer': \"[Positive Developments]:\\n1. American Express (AXP) is mentioned as one of the financial stocks that could potentially experience a September rally, as per a recent article.\\n2. Warren Buffett's investment in AXP is highlighted, indicating the company's potential for long-term growth and stability.\\n3. AXP's recent trading session saw a slight decrease in stock price, which could be seen as a buying opportunity for investors.\\n4. The company's wide-moat stock status, as per Morningstar's rating, suggests its potential for long-term growth and stability.\\n\\n[Potential Concerns]:\\n1. The recent decrease in AXP's stock price could be a sign of market uncertainty and potential volatility.\\n2. The slight increase in interest rates and oil prices could have a negative impact on the company's financial performance.\\n3. The lackluster start to the month of September for the stock market could continue to affect AXP's stock price.\\n4. The company's recent trading session saw a slight decrease in stock price, which could be a sign of market uncertainty and potential volatility.\\n\\n[Prediction & Analysis]:\\nPrediction: Up by 4-5%\\nAnalysis: Based on the positive developments, I believe that AXP's stock price has the potential to increase by 4-5% in the upcoming week (2023-09-10 to 2023-09-17). This prediction is supported by the company's wide-moat stock status, Warren Buffett's investment, and the potential for a September rally. Additionally, the recent decrease in AXP's stock price could be seen as a buying opportunity for investors, which could drive the stock price up in the upcoming week. However, the potential concerns, such as market uncertainty and the slight increase in interest rates and oil prices, could also impact the company's financial performance and stock price. Overall, I believe that AXP's stock price has the potential to increase in the upcoming week, but it is important to monitor the company's financial performance and market trends to confirm this prediction.\",\n 'period': '2023-09-10 to 2023-09-17',\n 'label': 'up by 4-5%'}"},"metadata":{}}]},{"cell_type":"code","source":"llama3_dataset.save_to_disk('./fin-prediction-2023-09-01_2024-06-01-llama3')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["455ef0362bcd4bb984b4154822164249","4aecd68f2e294d4c8c549c7cba4af701","144e6101bb27400280288b98d713e918","47acbbfe8fad419881c1e2698f9c2a34","93fd7ad358e543ac8e5aa6d9cb298aab","c0ce274386e04ddf8070d64db608730c","0b9428da99ba46ffaf4b862e07207ede","e2c45ca2da95461f943198b2a8b93d46","81f7d44dd0dc45689b708459df10c761","d4572c769c98415f914bb5b184abd745","0cbbffeee1774506b48eef11496c9b73","5a49aecc4f8945b9892c275b5a1626a3","2a163537d1e740a28413efde552b0300","a36975338ea24f9dae5c355627248dd2","f14ba5b13f9a402e8c3809b6c4c07020","f15ba01c1c664f119d1f46a683356ef4","ed4273e578634ea3a534e2f09d031fb1","79b84a811d1c4d4ba3af804ca8dfa315","402a3bcf10cb4ac4b4b831cc30fed454","29751286d1eb47ad81d39eed31b1abac","cb1b2f2bf1e34dcc9568034fc37db6a9","a42763c249d64234ba0eb05462efd3f1"]},"id":"gZRDFRIJkllb","outputId":"5300ef3b-277d-45a0-e00f-c6a40fed65f1","scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T17:34:00.863435Z","iopub.execute_input":"2024-07-17T17:34:00.863831Z","iopub.status.idle":"2024-07-17T17:34:00.939703Z","shell.execute_reply.started":"2024-07-17T17:34:00.863804Z","shell.execute_reply":"2024-07-17T17:34:00.938800Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44196e7a4d864cfd9b6bab077d2b7c68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa15c6db71f04a31baba1e9694fafad0"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Fine-tuning","metadata":{"id":"JxV8KPCzmNYw"}},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ['WANDB_PROJECT'] = 'llama3-fin-pred'","metadata":{"id":"e6Sao3ipVI5d","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:28:29.196200Z","iopub.execute_input":"2024-07-18T16:28:29.196556Z","iopub.status.idle":"2024-07-18T16:28:29.327265Z","shell.execute_reply.started":"2024-07-18T16:28:29.196522Z","shell.execute_reply":"2024-07-18T16:28:29.326269Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Finance Llama 3 8B","metadata":{}},{"cell_type":"code","source":"finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\"","metadata":{"execution":{"iopub.status.busy":"2024-07-18T16:28:29.328517Z","iopub.execute_input":"2024-07-18T16:28:29.328887Z","iopub.status.idle":"2024-07-18T16:28:29.333835Z","shell.execute_reply.started":"2024-07-18T16:28:29.328855Z","shell.execute_reply":"2024-07-18T16:28:29.332883Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\nmodel = AutoModelForCausalLM.from_pretrained(finance_llama3_8b, quantization_config=bnb_config, device_map=\"auto\", attn_implementation=\"eager\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T16:28:29.335010Z","iopub.execute_input":"2024-07-18T16:28:29.335334Z","iopub.status.idle":"2024-07-18T16:33:16.053432Z","shell.execute_reply.started":"2024-07-18T16:28:29.335305Z","shell.execute_reply":"2024-07-18T16:33:16.052418Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805dfaec5dab44da9d441943c7dc8c3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1a54c18fda4670b761576b8de90b97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b732de1a4844baf842d667a92b61e22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826b686aa32a46a28af46b3a3355e5fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0666d36e3efa4edb85802bfb7a592cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad95022571b450d97ad4f90fb0a433b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d61870f2d6dc4e81957c4c0df71cfbac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8305288732dc480ba46ff9237ee37e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abdafc35e7c64e9e84b5f948e7b5152e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c582ab0e634c12bfaef441ac92f3a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"058bce55cd4440f0a673ac261387d394"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c3d7bd61aa84f3f80f115547ee9944a"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["a60776900afb41c588673f7a76a4f7f9","afc408fe52114d80beb590fb9e4ac9aa","9e510b2f45884ab39c543846c0a851d4"]},"id":"V8PFfJMTzEQ4","outputId":"4823c013-44db-49c2-e4ad-6da0d37d28a4","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:33:16.054721Z","iopub.execute_input":"2024-07-18T16:33:16.055049Z","iopub.status.idle":"2024-07-18T16:33:17.798947Z","shell.execute_reply.started":"2024-07-18T16:33:16.055016Z","shell.execute_reply":"2024-07-18T16:33:17.798040Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf5c976b45a842ee845e917f7e6480e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784b174811e5470587c7d26dff1cbd3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c4d3c33fad4fec9245791430670d5f"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:08:40.560410Z","iopub.execute_input":"2024-07-17T18:08:40.561424Z","iopub.status.idle":"2024-07-17T18:08:40.568879Z","shell.execute_reply.started":"2024-07-17T18:08:40.561391Z","shell.execute_reply":"2024-07-17T18:08:40.567835Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'model.embed_tokens': 0,\n 'model.layers.0': 0,\n 'model.layers.1': 0,\n 'model.layers.2': 0,\n 'model.layers.3': 0,\n 'model.layers.4': 0,\n 'model.layers.5': 0,\n 'model.layers.6': 0,\n 'model.layers.7': 0,\n 'model.layers.8': 1,\n 'model.layers.9': 1,\n 'model.layers.10': 1,\n 'model.layers.11': 1,\n 'model.layers.12': 1,\n 'model.layers.13': 1,\n 'model.layers.14': 1,\n 'model.layers.15': 1,\n 'model.layers.16': 1,\n 'model.layers.17': 1,\n 'model.layers.18': 1,\n 'model.layers.19': 1,\n 'model.layers.20': 1,\n 'model.layers.21': 1,\n 'model.layers.22': 1,\n 'model.layers.23': 1,\n 'model.layers.24': 1,\n 'model.layers.25': 1,\n 'model.layers.26': 1,\n 'model.layers.27': 1,\n 'model.layers.28': 1,\n 'model.layers.29': 1,\n 'model.layers.30': 1,\n 'model.layers.31': 1,\n 'model.norm': 1,\n 'lm_head': 1}"},"metadata":{}}]},{"cell_type":"code","source":"# model = prepare_model_for_kbit_training(model)","metadata":{"id":"YOiVA425fNIt","scrolled":true,"execution":{"iopub.status.busy":"2024-07-10T23:53:43.982141Z","iopub.execute_input":"2024-07-10T23:53:43.982389Z","iopub.status.idle":"2024-07-10T23:53:44.009881Z","shell.execute_reply.started":"2024-07-10T23:53:43.982366Z","shell.execute_reply":"2024-07-10T23:53:44.009031Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{"id":"jXQMMODRnVXl"}},{"cell_type":"code","source":"def tokenize(tokenizer, feature):\n    prompt = feature['prompt'].strip()\n    answer = feature['answer'].strip()\n\n    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False, truncation=True, max_length=4096)\n    answer_ids = tokenizer.encode(answer, add_special_tokens=False, truncation=True, max_length=4096)\n\n    input_ids = prompt_ids + answer_ids\n    too_big = len(input_ids) >= 8192\n\n    if input_ids[-1] != tokenizer.eos_token_id and not too_big:\n        input_ids.append(tokenizer.eos_token_id)\n\n    label_ids = [tokenizer.pad_token_id] * len(prompt_ids) + input_ids[len(prompt_ids):]\n\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": label_ids,\n        \"is_too_big\": too_big\n    }","metadata":{"id":"iT8CKDlrzzVk","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:33:17.802291Z","iopub.execute_input":"2024-07-18T16:33:17.802599Z","iopub.status.idle":"2024-07-18T16:33:17.809755Z","shell.execute_reply.started":"2024-07-18T16:33:17.802574Z","shell.execute_reply":"2024-07-18T16:33:17.808744Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"/kaggle/working/fin-prediction-2023-09-01-2024-06-01-llama3\"\ndataset = datasets.load_from_disk(dataset_name)","metadata":{"id":"4RdmrMpVnWX8","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:33:19.045129Z","iopub.execute_input":"2024-07-18T16:33:19.045419Z","iopub.status.idle":"2024-07-18T16:33:19.081945Z","shell.execute_reply.started":"2024-07-18T16:33:19.045392Z","shell.execute_reply":"2024-07-18T16:33:19.081041Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(partial(tokenize, tokenizer))\nprint('original dataset length: ', len(dataset['train']))\ntokenized_dataset = tokenized_dataset.filter(lambda x: not x['is_too_big'])\nprint('filtered dataset length: ', len(dataset['train']))\ntokenized_dataset = tokenized_dataset.remove_columns(\n    ['prompt', 'answer', 'label', 'period', 'is_too_big']\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["5b5fe12a6dd242fbb1f678c24f8889d2","7c03165ba1e44f1fb6a0f5e9a1de7130","cc70d5494aa2428fb4535b2ce377ec2d","9ecd6cfe1f5e4dd38daeb66f80c3193b","0e25c3657c7a482d99ab14e24094700f","bd61c21d4cda47f283752d1f36928ef3","5a028a4a33044b339002e40457536735","9387d7e0e98b4534849529e008858964","0db68bea29e644bcab2a579fb87bf271","71927857a7e44dcdad2e0df79462ed6c","eec4724bdc904708aa87119b9c187861","ba61a21d0ef047b89400ebed07ab1f30","94bd9f1753be45fb91201bbce2b81567","047dcce93d5048b6b647f1cb3c8902e5","d7c51f161f5f4779b7d724eb1caf56c1","f203c7d51d0b4760a8df3d20b12159ff","9e6fbfcf4602470783234944fe00a80d","75dbd4b48d4b40a9aa73c389ca4b431c","b4219fd1c6c142ea8cbbe41c66a6fd7e","52317ad1f4fb4470b0b221bcdb5d1b84","ce76e0ba88844a9ab693d7daffae81b4","244a20287aec48af8a42757150c23504","5376f9587933402ba422859e999492ed","ed331e46cc1a463f828c2dfba96d9296","2e4b2e72ab3b4dcd83d5382c6c217c9b","3f409f0118d243b8a86f470c69f372e9","9a9593098dca4472b120719e5b80739c","a09ecb5428ff4c9894784d75fbd1ac4e","b223de2deb454a46ab183c8472db4f27","901c6fefb887434f9b9015de5fa8c0c3","a4d0e2f164044634b62f57b8cf25929d","6abd119862244705bd86594c5e438e1b","08854c2134364248a3233434b551c0ab","ac949691abbb4c9c9b79d1928ae15420","7cb91b31a79744d4937c374f0fb029fb","a43c8944390e47ffb28dad160ffed250","e76296a04b104dd0b724d72dd23b960f","c1dead594a0c4ee487f19d3f2879a266","bda0f0cca6f642668518e37b9b7c3977","2e8eaa8ba6334c11864dfc333cf35697","1ebb62bbbbe44f7c9be5fef39333be0d","31eab09e78384a40afd70b9d0296a4bc","4dfc0effb5d648d29e04ecd28e8c57d4","bcccba20051f4916ab98bd18f9219681","8f908931441f4b279484424b15aae9ab","03f9706a8a02498da8bd3c07850d26c5"]},"id":"B-3QnV5Ryk1Q","outputId":"e0b98822-9e65-4ad2-a0dd-a0b24581828d","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:33:19.083374Z","iopub.execute_input":"2024-07-18T16:33:19.083697Z","iopub.status.idle":"2024-07-18T16:33:27.479432Z","shell.execute_reply.started":"2024-07-18T16:33:19.083668Z","shell.execute_reply":"2024-07-18T16:33:27.478522Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f01d9f7d343f4d3a968313e9584774a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63265090357f4152b994e374497be052"}},"metadata":{}},{"name":"stdout","text":"original dataset length:  900\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0186cad275c42e38d1f3d329001be7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe7a8867354420a8967d3864c2a8975"}},"metadata":{}},{"name":"stdout","text":"filtered dataset length:  900\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_dataset['train'][0]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-17T18:45:28.570084Z","iopub.execute_input":"2024-07-17T18:45:28.570751Z","iopub.status.idle":"2024-07-17T18:45:28.614648Z","shell.execute_reply.started":"2024-07-17T18:45:28.570722Z","shell.execute_reply":"2024-07-17T18:45:28.613783Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [27,\n  91,\n  318,\n  5011,\n  91,\n  29,\n  9125,\n  198,\n  2675,\n  527,\n  264,\n  52614,\n  5708,\n  3157,\n  18738,\n  13,\n  4718,\n  3465,\n  374,\n  311,\n  1160,\n  279,\n  6928,\n  26006,\n  323,\n  4754,\n  10742,\n  369,\n  5220,\n  3196,\n  389,\n  9959,\n  3754,\n  323,\n  6913,\n  6020,\n  82,\n  505,\n  279,\n  3347,\n  5672,\n  11,\n  1243,\n  3493,\n  459,\n  6492,\n  323,\n  20212,\n  369,\n  279,\n  5220,\n  6,\n  5708,\n  3430,\n  7351,\n  369,\n  279,\n  14827,\n  2046,\n  13,\n  4718,\n  4320,\n  3645,\n  1288,\n  387,\n  439,\n  11263,\n  25,\n  4815,\n  58,\n  36590,\n  8000,\n  1392,\n  10556,\n  16,\n  13,\n  5585,\n  43447,\n  354,\n  2335,\n  52347,\n  82,\n  10556,\n  16,\n  13,\n  5585,\n  43447,\n  1171,\n  2538,\n  612,\n  18825,\n  10556,\n  89379,\n  25,\n  12515,\n  27671,\n  25,\n  12515,\n  27,\n  91,\n  318,\n  6345,\n  91,\n  397,\n  27,\n  91,\n  318,\n  5011,\n  91,\n  29,\n  882,\n  198,\n  58,\n  14831,\n  29438,\n  69662,\n  29518,\n  17855,\n  3623,\n  374,\n  264,\n  6522,\n  5502,\n  304,\n  279,\n  17961,\n  8471,\n  10706,\n  13,\n  67795,\n  323,\n  17880,\n  31207,\n  2533,\n  220,\n  4468,\n  22,\n  12,\n  2304,\n  12,\n  972,\n  11,\n  279,\n  2883,\n  706,\n  9749,\n  1202,\n  17444,\n  439,\n  832,\n  315,\n  279,\n  1401,\n  4311,\n  304,\n  279,\n  3157,\n  13,\n  4815,\n  29518,\n  17855,\n  3623,\n  27149,\n  15871,\n  304,\n  279,\n  2326,\n  11,\n  11380,\n  1234,\n  279,\n  48087,\n  362,\n  28475,\n  389,\n  279,\n  16560,\n  47404,\n  83751,\n  4154,\n  41973,\n  11,\n  18610,\n  497,\n  1666,\n  264,\n  25462,\n  5457,\n  304,\n  279,\n  17961,\n  8471,\n  3634,\n  11,\n  279,\n  2883,\n  9731,\n  311,\n  92064,\n  323,\n  6678,\n  5208,\n  2949,\n  279,\n  5064,\n  382,\n  3915,\n  220,\n  2366,\n  18,\n  12,\n  2545,\n  12,\n  2839,\n  311,\n  220,\n  2366,\n  18,\n  12,\n  2545,\n  12,\n  605,\n  11,\n  362,\n  28475,\n  596,\n  5708,\n  3430,\n  25983,\n  505,\n  220,\n  10895,\n  13,\n  3534,\n  311,\n  220,\n  9992,\n  13,\n  1490,\n  13,\n  5513,\n  2391,\n  420,\n  4261,\n  527,\n  10212,\n  3770,\n  1473,\n  58,\n  12626,\n  1074,\n  5787,\n  6250,\n  59800,\n  30,\n  220,\n  18,\n  17961,\n  80336,\n  311,\n  11544,\n  13538,\n  65863,\n  998,\n  544,\n  198,\n  58,\n  19791,\n  5787,\n  362,\n  6250,\n  19768,\n  1253,\n  539,\n  387,\n  304,\n  279,\n  7563,\n  369,\n  6020,\n  23301,\n  11,\n  439,\n  279,\n  5708,\n  3157,\n  374,\n  1022,\n  311,\n  264,\n  6996,\n  75,\n  5100,\n  1212,\n  2391,\n  420,\n  35901,\n  1633,\n  8009,\n  2305,\n  369,\n  3312,\n  1385,\n  13,\n  2057,\n  1304,\n  13146,\n  11201,\n  11,\n  9935,\n  6825,\n  374,\n  23268,\n  555,\n  8275,\n  12992,\n  304,\n  2802,\n  7969,\n  323,\n  5707,\n  7729,\n  430,\n  584,\n  4070,\n  3970,\n  779,\n  3117,\n  304,\n  6250,\n  13,\n  4452,\n  11,\n  358,\n  4510,\n  430,\n  555,\n  37250,\n  6020,\n  23301,\n  690,\n  36861,\n  10345,\n  998,\n  544,\n  13,\n  3011,\n  753,\n  1606,\n  358,\n  7655,\n  449,\n  40996,\n  17961,\n  320,\n  68445,\n  25,\n  30175,\n  8,\n  12432,\n  24785,\n  13000,\n  16233,\n  359,\n  889,\n  3309,\n  37653,\n  6007,\n  389,\n  5488,\n  13,\n  220,\n  22,\n  430,\n  578,\n  435,\n  271,\n  58,\n  12626,\n  1074,\n  5787,\n  26713,\n  86552,\n  753,\n  86621,\n  426,\n  1441,\n  25,\n  578,\n  220,\n  22,\n  80336,\n  23286,\n  1113,\n  5414,\n  47292,\n  198,\n  58,\n  19791,\n  5787,\n  8876,\n  4737,\n  927,\n  279,\n  90518,\n  315,\n  91375,\n  91668,\n  14075,\n  320,\n  68445,\n  25,\n  13396,\n  42,\n  6830,\n  11,\n  12551,\n  937,\n  25,\n  13396,\n  42,\n  7826,\n  8,\n  439,\n  12432,\n  304,\n  220,\n  5162,\n  20,\n  11,\n  26713,\n  86552,\n  706,\n  20270,\n  268,\n  88424,\n  20192,\n  315,\n  220,\n  508,\n  4,\n  264,\n  1060,\n  13,\n  3011,\n  753,\n  810,\n  1109,\n  2033,\n  279,\n  4780,\n  315,\n  279,\n  328,\n  43945,\n  220,\n  2636,\n  13,\n  2876,\n  1475,\n  1060,\n  574,\n  264,\n  13946,\n  13,\n  2468,\n  12387,\n  3585,\n  927,\n  279,\n  3347,\n  220,\n  2970,\n  1667,\n  11,\n  86552,\n  5675,\n  311,\n  279,\n  5526,\n  29531,\n  1963,\n  13,\n  18156,\n  555,\n  264,\n  7029,\n  4850,\n  13,\n  2030,\n  86552,\n  753,\n  8446,\n  315,\n  12096,\n  9250,\n  5220,\n  520,\n  6762,\n  7729,\n  323,\n  1243,\n  10168,\n  1124,\n  1317,\n  9860,\n  9731,\n  311,\n  2343,\n  1022,\n  13,\n  1226,\n  3207,\n  7556,\n  922,\n  459,\n  26263,\n  64,\n  271,\n  58,\n  12626,\n  1074,\n  5787,\n  3778,\n  17855,\n  320,\n  3027,\n  47,\n  8,\n  423,\n  3153,\n  4497,\n  34776,\n  6031,\n  1013,\n  47910,\n  25,\n  3639,\n  1472,\n  12540,\n  14521,\n  198,\n  58,\n  19791,\n  5787,\n  3778,\n  17855,\n  320,\n  3027,\n  47,\n  8,\n  8036,\n  279,\n  1455,\n  3293,\n  11380,\n  1938,\n  520,\n  400,\n  10132,\n  13,\n  2495,\n  11,\n  7366,\n  482,\n  15,\n  13,\n  2813,\n  4,\n  505,\n  279,\n  3766,\n  11380,\n  3882,\n  382,\n  58,\n  12626,\n  1074,\n  5787,\n  3778,\n  17855,\n  8351,\n  320,\n  3027,\n  47,\n  8,\n  2209,\n  264,\n  31753,\n  287,\n  12937,\n  25,\n  46083,\n  311,\n  14521,\n  13538,\n  85085,\n  389,\n  1102,\n  198,\n  58,\n  19791,\n  5787,\n  3778,\n  17855,\n  320,\n  3027,\n  47,\n  8,\n  706,\n  4036,\n  5115,\n  264,\n  2766,\n  315,\n  6666,\n  505,\n  1901,\n  7977,\n  916,\n  3932,\n  31445,\n  13,\n  15636,\n  11,\n  433,\n  374,\n  24219,\n  311,\n  387,\n  8010,\n  315,\n  279,\n  13363,\n  430,\n  649,\n  5536,\n  279,\n  5708,\n  596,\n  27949,\n  382,\n  58,\n  12626,\n  1074,\n  5787,\n  549,\n  815,\n  13,\n  33845,\n  5364,\n  78,\n  266,\n  80336,\n  1952,\n  13618,\n  482,\n  578,\n  6250,\n  220,\n  2366,\n  18,\n  27162,\n  5135,\n  198,\n  58,\n  19791,\n  5787,\n  5751,\n  220,\n  18,\n  30308,\n  1920,\n  24400,\n  389,\n  7029,\n  1474,\n  78,\n  266,\n  23301,\n  320,\n  300,\n  824,\n  29084,\n  12134,\n  9011,\n  75809,\n  82,\n  10959,\n  570,\n  7531,\n  704,\n  279,\n  8798,\n  2472,\n  315,\n  279,\n  1455,\n  2793,\n  481,\n  11426,\n  382,\n  58,\n  16323,\n  17961,\n  82,\n  69662,\n  2822,\n  6913,\n  6020,\n  5068,\n  382,\n  29815,\n  389,\n  682,\n  279,\n  2038,\n  1603,\n  220,\n  2366,\n  18,\n  12,\n  2545,\n  12,\n  605,\n  11,\n  1095,\n  596,\n  1176,\n  24564,\n  279,\n  6928,\n  26006,\n  323,\n  4754,\n  10742,\n  369,\n  362,\n  28475,\n  13,\n  15936,\n  709,\n  449,\n  220,\n  17,\n  12,\n  19,\n  1455,\n  3062,\n  9547,\n  15947,\n  323,\n  2567,\n  1124,\n  64694,\n  13,\n  7648,\n  9547,\n  1288,\n  387,\n  68695,\n  505,\n  2883,\n  5552,\n  3754,\n  13,\n  5112,\n  1304,\n  701,\n  20212,\n  315,\n  279,\n  362,\n  28475,\n  5708,\n  3430,\n  7351,\n  369,\n  1828,\n  2046,\n  320,\n  2366,\n  18,\n  12,\n  2545,\n  12,\n  605,\n  311,\n  220,\n  2366,\n  18,\n  12,\n  2545,\n  12,\n  1114,\n  570,\n  40665,\n  264,\n  12399,\n  6492,\n  311,\n  1862,\n  701,\n  20212,\n  16134,\n  91,\n  318,\n  6345,\n  91,\n  397,\n  27,\n  91,\n  318,\n  5011,\n  91,\n  29,\n  78191,\n  58,\n  36590,\n  8000,\n  1392,\n  10556,\n  16,\n  13,\n  3778,\n  17855,\n  320,\n  3027,\n  47,\n  8,\n  374,\n  9932,\n  439,\n  832,\n  315,\n  279,\n  6020,\n  23301,\n  430,\n  1436,\n  13893,\n  3217,\n  264,\n  6250,\n  19768,\n  11,\n  439,\n  824,\n  264,\n  3293,\n  4652,\n  627,\n  17,\n  13,\n  26713,\n  86552,\n  596,\n  9341,\n  304,\n  362,\n  28475,\n  374,\n  27463,\n  11,\n  19392,\n  279,\n  2883,\n  596,\n  4754,\n  369,\n  1317,\n  9860,\n  6650,\n  323,\n  20334,\n  627,\n  18,\n  13,\n  362,\n  28475,\n  596,\n  3293,\n  11380,\n  3882,\n  5602,\n  264,\n  8275,\n  18979,\n  304,\n  5708,\n  3430,\n  11,\n  902,\n  1436,\n  387,\n  3970,\n  439,\n  264,\n  12096,\n  6776,\n  369,\n  15167,\n  627,\n  19,\n  13,\n  578,\n  2883,\n  596,\n  7029,\n  1474,\n  78,\n  266,\n  5708,\n  2704,\n  11,\n  439,\n  824,\n  29084,\n  12134,\n  596,\n  10959,\n  11,\n  13533,\n  1202,\n  4754,\n  369,\n  1317,\n  9860,\n  6650,\n  323,\n  20334,\n  382,\n  43447,\n  354,\n  2335,\n  52347,\n  82,\n  10556,\n  16,\n  13,\n  578,\n  3293,\n  18979,\n  304,\n  362,\n  28475,\n  596,\n  5708,\n  3430,\n  1436,\n  387,\n  264,\n  1879,\n  315,\n  3157,\n  27924,\n  323,\n  4754,\n  53838,\n  627,\n  17,\n  13,\n  578,\n  8275,\n  5376,\n  304,\n  2802,\n  7969,\n  323,\n  5707,\n  7729,\n  1436,\n  617,\n  264,\n  8389,\n  5536,\n  389,\n  279,\n  2883,\n  596,\n  6020,\n  5178,\n  627,\n  18,\n  13,\n  578,\n  6996,\n  75,\n  5100,\n  1212,\n  311,\n  279,\n  2305,\n  315,\n  6250,\n  369,\n  279,\n  5708,\n  3157,\n  1436,\n  ...],\n 'labels': [128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  128001,\n  58,\n  36590,\n  8000,\n  1392,\n  10556,\n  16,\n  13,\n  3778,\n  17855,\n  320,\n  3027,\n  47,\n  8,\n  374,\n  9932,\n  439,\n  832,\n  315,\n  279,\n  6020,\n  23301,\n  430,\n  1436,\n  13893,\n  3217,\n  264,\n  6250,\n  19768,\n  11,\n  439,\n  824,\n  264,\n  3293,\n  4652,\n  627,\n  17,\n  13,\n  26713,\n  86552,\n  596,\n  9341,\n  304,\n  362,\n  28475,\n  374,\n  27463,\n  11,\n  19392,\n  279,\n  2883,\n  596,\n  4754,\n  369,\n  1317,\n  9860,\n  6650,\n  323,\n  20334,\n  627,\n  18,\n  13,\n  362,\n  28475,\n  596,\n  3293,\n  11380,\n  3882,\n  5602,\n  264,\n  8275,\n  18979,\n  304,\n  5708,\n  3430,\n  11,\n  902,\n  1436,\n  387,\n  3970,\n  439,\n  264,\n  12096,\n  6776,\n  369,\n  15167,\n  627,\n  19,\n  13,\n  578,\n  2883,\n  596,\n  7029,\n  1474,\n  78,\n  266,\n  5708,\n  2704,\n  11,\n  439,\n  824,\n  29084,\n  12134,\n  596,\n  10959,\n  11,\n  13533,\n  1202,\n  4754,\n  369,\n  1317,\n  9860,\n  6650,\n  323,\n  20334,\n  382,\n  43447,\n  354,\n  2335,\n  52347,\n  82,\n  10556,\n  16,\n  13,\n  578,\n  3293,\n  18979,\n  304,\n  362,\n  28475,\n  596,\n  5708,\n  3430,\n  1436,\n  387,\n  264,\n  1879,\n  315,\n  3157,\n  27924,\n  323,\n  4754,\n  53838,\n  627,\n  17,\n  13,\n  578,\n  8275,\n  5376,\n  304,\n  2802,\n  7969,\n  323,\n  5707,\n  7729,\n  1436,\n  617,\n  264,\n  8389,\n  5536,\n  389,\n  279,\n  2883,\n  596,\n  6020,\n  5178,\n  627,\n  18,\n  13,\n  578,\n  6996,\n  75,\n  5100,\n  1212,\n  311,\n  279,\n  2305,\n  315,\n  6250,\n  369,\n  279,\n  5708,\n  3157,\n  1436,\n  ...]}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Params","metadata":{"id":"rTvWHUu1kkPz"}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()\nmodel.is_parallelizable = True\nmodel.model_parallel = True\nmodel.model.config.use_cache = False\n\npeft_model = get_peft_model(model, lora_config)","metadata":{"id":"7H-_DeEpklSG","scrolled":true,"execution":{"iopub.status.busy":"2024-07-18T16:33:27.480720Z","iopub.execute_input":"2024-07-18T16:33:27.481091Z","iopub.status.idle":"2024-07-18T16:33:28.067447Z","shell.execute_reply.started":"2024-07-18T16:33:27.481049Z","shell.execute_reply":"2024-07-18T16:33:28.066644Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"current_time = datetime.now().strftime('%Y%m%d-%H-%M')\n\noptimizer = AdamW(\n    peft_model.parameters(),\n    lr=6e-5,\n    betas=(0.9, 0.97),\n    eps=1e-8,\n    weight_decay=0.005\n)\n\ntraining_args = TrainingArguments(\n    output_dir=f\"./results_{current_time}\",\n    num_train_epochs=4,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    log_level='info',\n    gradient_accumulation_steps=32,\n    eval_strategy='steps',\n    save_strategy=\"steps\",\n    fp16=True,\n    logging_steps=1,\n    save_total_limit=3,\n    save_steps=10,\n    eval_steps=10,\n    remove_unused_columns=False,\n    report_to='wandb',\n    run_name=\"llama3_fin_pred_run\",\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['test'],\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForSeq2Seq(\n      tokenizer, padding=True,\n      return_tensors=\"pt\"\n    ),\n    optimizers=(optimizer, None),  # (optimizer, scheduler)\n)\n\ntrainer.is_model_parallel = True\n\npeft_model.gradient_checkpointing_enable()\npeft_model.enable_input_require_grads()","metadata":{"id":"D6xuWZ7emFDy","scrolled":true,"outputId":"aafba994-8392-4ef8-f320-5cfdc7addfe8","execution":{"iopub.status.busy":"2024-07-18T16:33:28.068623Z","iopub.execute_input":"2024-07-18T16:33:28.068910Z","iopub.status.idle":"2024-07-18T16:33:28.137430Z","shell.execute_reply.started":"2024-07-18T16:33:28.068885Z","shell.execute_reply":"2024-07-18T16:33:28.136602Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\nUsing auto half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"compiled_model = torch.compile(peft_model)\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T02:46:46.185263Z","iopub.execute_input":"2024-07-11T02:46:46.185559Z","iopub.status.idle":"2024-07-11T02:46:46.893507Z","shell.execute_reply.started":"2024-07-11T02:46:46.185532Z","shell.execute_reply":"2024-07-11T02:46:46.892430Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train","metadata":{"id":"2h7gViVvbMcr"}},{"cell_type":"code","source":"trainer.train()\n\ntrainer.save_model(f\"{training_args.output_dir}/trainer_model\")\nmodel.save_pretrained(f\"{training_args.output_dir}/pretrained\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"_9vZEAQ4dEBi","outputId":"ae6e5dd1-a141-47f1-ca3d-21dd80cabba1","execution":{"iopub.status.busy":"2024-07-18T16:35:38.365097Z","iopub.execute_input":"2024-07-18T16:35:38.365477Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Loading model from /kaggle/working/results-20240717-19-04/checkpoint-80.\n***** Running training *****\n  Num examples = 900\n  Num Epochs = 4\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 32\n  Total optimization steps = 112\n  Number of trainable parameters = 20,971,520\n  Continuing training from checkpoint, will skip to saved global_step\n  Continuing training from epoch 2\n  Continuing training from global step 80\n  Will skip the first 2 epochs then the first 768 batches in the first epoch.\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maskador\u001b[0m (\u001b[33maskador-Kharkiv National University of Radio Electronics\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240718_163542-c4y242xj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/c4y242xj' target=\"_blank\">llama3_fin_pred_run</a></strong> to <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred' target=\"_blank\">https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/c4y242xj' target=\"_blank\">https://wandb.ai/askador-Kharkiv%20National%20University%20of%20Radio%20Electronics/llama3-fin-pred/runs/c4y242xj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='111' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [111/112 1:53:46 < 03:55, 0.00 it/s, Epoch 3.92/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>0.089700</td>\n      <td>0.095168</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.081400</td>\n      <td>0.093552</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='226' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [226/240 07:44 < 00:28, 0.48 it/s]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"\n***** Running Evaluation *****\n  Num examples = 240\n  Batch size = 1\nSaving model checkpoint to ./results_20240717-19-04/checkpoint-90\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/98ef99a87af7941e4895081219bf045db9601713/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\ntokenizer config file saved in ./results_20240717-19-04/checkpoint-90/tokenizer_config.json\nSpecial tokens file saved in ./results_20240717-19-04/checkpoint-90/special_tokens_map.json\n\n***** Running Evaluation *****\n  Num examples = 240\n  Batch size = 1\nSaving model checkpoint to ./results_20240717-19-04/checkpoint-100\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--instruction-pretrain--finance-Llama3-8B/snapshots/98ef99a87af7941e4895081219bf045db9601713/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\ntokenizer config file saved in ./results_20240717-19-04/checkpoint-100/tokenizer_config.json\nSpecial tokens file saved in ./results_20240717-19-04/checkpoint-100/special_tokens_map.json\n\n***** Running Evaluation *****\n  Num examples = 240\n  Batch size = 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"_sz4zAEHveGB"}},{"cell_type":"code","source":"dataset_name = \"./fin-prediction-2023-09-01-2024-06-01-llama3\"\ndataset = datasets.load_from_disk(dataset_name)\neval_dataset = dataset['test'].shuffle(seed=333).select(range(20))","metadata":{"id":"7M6bFouWv3Q-","execution":{"iopub.status.busy":"2024-07-20T03:27:36.653982Z","iopub.execute_input":"2024-07-20T03:27:36.654286Z","iopub.status.idle":"2024-07-20T03:27:36.691395Z","shell.execute_reply.started":"2024-07-20T03:27:36.654261Z","shell.execute_reply":"2024-07-20T03:27:36.690551Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T16:48:55.407251Z","iopub.execute_input":"2024-07-19T16:48:55.407660Z","iopub.status.idle":"2024-07-19T16:48:55.414853Z","shell.execute_reply.started":"2024-07-19T16:48:55.407624Z","shell.execute_reply":"2024-07-19T16:48:55.413782Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"finance_llama3_8b = \"instruction-pretrain/finance-Llama3-8B\"\nfinance_peft_adapter_path = \"/kaggle/input/fin-prediction-llama3/transformers/peft-adapter/2\"\nbase_llama3_8b = \"meta-llama/Meta-Llama-3-8B-Instruct\"","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:14:27.570036Z","iopub.execute_input":"2024-07-19T14:14:27.570500Z","iopub.status.idle":"2024-07-19T14:14:27.576808Z","shell.execute_reply.started":"2024-07-19T14:14:27.570467Z","shell.execute_reply":"2024-07-19T14:14:27.575869Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(base_llama3_8b, quantization_config=bnb_config, device_map='auto')","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:14:27.580834Z","iopub.execute_input":"2024-07-19T14:14:27.581278Z","iopub.status.idle":"2024-07-19T14:17:06.558743Z","shell.execute_reply.started":"2024-07-19T14:14:27.581245Z","shell.execute_reply":"2024-07-19T14:17:06.557780Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a51125b088904dfb999c049d99e99e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552abc4baaa14fcb828081de2e4cda57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa3a7fbe34b64ef1866bb605f105162a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"237aa9493a2f4284ae70f7eb9a810794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36911a1b42e461dae133722e02fd7fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b342c2e098ab425b8553665c6ace2b9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2509e1350b8d4d27a2e4104c18017830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6035ed634c8343e7a8818cabade8a9c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74a9fde065f48cb80dabcb8e37f6498"}},"metadata":{}}]},{"cell_type":"code","source":"finance_llama3_8b_model = AutoModelForCausalLM.from_pretrained(finance_llama3_8b, quantization_config=bnb_config, device_map='auto', low_cpu_mem_usage=True)\nfinance_llama3_8b_model = finance_llama3_8b_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:17:06.559988Z","iopub.execute_input":"2024-07-19T14:17:06.560284Z","iopub.status.idle":"2024-07-19T14:21:56.393442Z","shell.execute_reply.started":"2024-07-19T14:17:06.560258Z","shell.execute_reply":"2024-07-19T14:21:56.392448Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3ad841f4b834d208d49bfba4b616300"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6377c99b384973b747a56f1732260d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36266760ccef4391b57668a0503d0f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da57e22836c413fb8907e441844816d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f75971a360e49e7b95a19fee529d0c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd566a173e8342deadc7aed3a2fff826"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca1fe7c5a2344639975012a5c0d8c710"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6119dec222ed4b9e9daa7f86e14f7fdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f6b508fb4f4675adb3cda2ccadffdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b8637e733544a9c85366166ed9eba8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a49dc857caa49dd8da8ba1784a41c7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73321374ff164929a5956406b2ee4f64"}},"metadata":{}}]},{"cell_type":"code","source":"finance_finetuned_model = PeftModel.from_pretrained(finance_llama3_8b_model, finance_peft_adapter_path)\nfinance_finetuned_model = finance_finetuned_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:21:56.394771Z","iopub.execute_input":"2024-07-19T14:21:56.395055Z","iopub.status.idle":"2024-07-19T14:21:58.116575Z","shell.execute_reply.started":"2024-07-19T14:21:56.395031Z","shell.execute_reply":"2024-07-19T14:21:58.115782Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"finance_tokenizer = AutoTokenizer.from_pretrained(finance_llama3_8b)\nbase_tokenizer = AutoTokenizer.from_pretrained(base_llama3_8b)\nfinance_finetuned_tokenizer = AutoTokenizer.from_pretrained(finance_peft_adapter_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:21:58.117668Z","iopub.execute_input":"2024-07-19T14:21:58.117957Z","iopub.status.idle":"2024-07-19T14:22:00.764890Z","shell.execute_reply.started":"2024-07-19T14:21:58.117932Z","shell.execute_reply":"2024-07-19T14:22:00.763825Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"053e798deeca4044a7cfd3eb108910c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeeb926d546942fabae494c38a0e6e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bce9af61474ea485f1eb4661c64752"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c077cb2861e48c7932bdd84fee70009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"844324b7aa034c79a2e62297c0c744f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a3fee98d7644d5d9cdd907ca1d5ebc9"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"finance_finetuned_model","metadata":{"execution":{"iopub.status.busy":"2024-07-18T22:59:08.437984Z","iopub.execute_input":"2024-07-18T22:59:08.438352Z","iopub.status.idle":"2024-07-18T22:59:08.462845Z","shell.execute_reply.started":"2024-07-18T22:59:08.438297Z","shell.execute_reply":"2024-07-18T22:59:08.461946Z"},"scrolled":true,"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm()\n            (post_attention_layernorm): LlamaRMSNorm()\n          )\n        )\n        (norm): LlamaRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"generation_config = GenerationConfig.from_pretrained(finance_peft_adapter_path)\ngeneration_config.temperature = 0.001\n\nfinetuned_pipeline = pipeline(\n    \"text-generation\",\n    model=finance_llama3_8b_model,\n    tokenizer=finance_finetuned_tokenizer,\n    generation_config=generation_config,\n)\nfinetuned_pipeline.model = finance_finetuned_model","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:22:00.766293Z","iopub.execute_input":"2024-07-19T14:22:00.766670Z","iopub.status.idle":"2024-07-19T14:22:00.777782Z","shell.execute_reply.started":"2024-07-19T14:22:00.766633Z","shell.execute_reply":"2024-07-19T14:22:00.776887Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"generation_config = GenerationConfig.from_pretrained(base_llama3_8b)\ngeneration_config.temperature = 0.001\n\nbase_model_pipeline = pipeline(\n    \"text-generation\",\n    model=base_model,\n    tokenizer=base_tokenizer,\n    generation_config=generation_config,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:22:00.778924Z","iopub.execute_input":"2024-07-19T14:22:00.779214Z","iopub.status.idle":"2024-07-19T14:22:00.840092Z","shell.execute_reply.started":"2024-07-19T14:22:00.779188Z","shell.execute_reply":"2024-07-19T14:22:00.839427Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_assistant_response(output):\n    gen_text = output[0]['generated_text']\n    assistant_text = gen_text.rsplit('<|im_start|>assistant\\n', 1)[1]\n    return assistant_text","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:28:16.742745Z","iopub.execute_input":"2024-07-20T03:28:16.743330Z","iopub.status.idle":"2024-07-20T03:28:16.748010Z","shell.execute_reply.started":"2024-07-20T03:28:16.743300Z","shell.execute_reply":"2024-07-20T03:28:16.747017Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def change_prompt_instruct_to_prcnt(feature):\n    prompt = feature['prompt']\n    feature['prompt'] = prompt.replace(\"Prediction: ...\", \"Prediction: Up|Down by X-Y%\")\n    return feature","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:28:17.619780Z","iopub.execute_input":"2024-07-20T03:28:17.620154Z","iopub.status.idle":"2024-07-20T03:28:17.625057Z","shell.execute_reply.started":"2024-07-20T03:28:17.620105Z","shell.execute_reply":"2024-07-20T03:28:17.624175Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"better_prompt_dataset = eval_dataset.map(change_prompt_instruct_to_prcnt)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:28:17.904310Z","iopub.execute_input":"2024-07-20T03:28:17.904607Z","iopub.status.idle":"2024-07-20T03:28:17.913207Z","shell.execute_reply.started":"2024-07-20T03:28:17.904582Z","shell.execute_reply":"2024-07-20T03:28:17.912338Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ncompletions = {'base': [], 'finetuned': []}\n\nfor i, row in tqdm(enumerate(better_prompt_dataset)):\n    base_model_output = base_model_pipeline(row['prompt'])\n    completions['base'].append(base_model_output)\n    \n    finetuned_model_output = finetuned_pipeline(row['prompt'])\n    completions['finetuned'].append(finetuned_model_output)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T14:22:00.870902Z","iopub.execute_input":"2024-07-19T14:22:00.871195Z","iopub.status.idle":"2024-07-19T15:24:54.626405Z","shell.execute_reply.started":"2024-07-19T14:22:00.871161Z","shell.execute_reply":"2024-07-19T15:24:54.625417Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af58f895a60d4b96becc5b3009819887"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"completions['finetuned'] = [get_assistant_response(c) for c in completions['finetuned']]\ncompletions['base'] = [get_assistant_response(c) for c in completions['base']]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:29:38.510318Z","iopub.execute_input":"2024-07-20T03:29:38.510722Z","iopub.status.idle":"2024-07-20T03:29:38.516870Z","shell.execute_reply.started":"2024-07-20T03:29:38.510693Z","shell.execute_reply":"2024-07-20T03:29:38.515511Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"answers = []\nfor row in better_prompt_dataset:\n    answers.append(row['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:28:22.625848Z","iopub.execute_input":"2024-07-20T03:28:22.626258Z","iopub.status.idle":"2024-07-20T03:28:22.638101Z","shell.execute_reply.started":"2024-07-20T03:28:22.626227Z","shell.execute_reply":"2024-07-20T03:28:22.636708Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\ndef parse_answer(answer):\n    \n    match_res = re.match(r\"^\\s*(?:\\[|\\*\\*)Positive Developments(?:\\]|\\*\\*):\\s*(.*)\\s*(?:\\[|\\*\\*)Potential Concerns(?:\\]|\\*\\*):\\s*(.*)\\s*(?:\\[|\\*\\*)Prediction (&|and) Analysis(?:\\]|\\*\\*):\\s*(.*)\\s*$\", answer, flags=re.DOTALL)\n    if not match_res:\n        return None\n    \n    positive, concerns, predict = match_res.group(1), match_res.group(2), match_res.group(4)\n        \n    match_res = re.match(r'^Prediction:\\s*(.*)\\s*Analysis:\\s*(.*)\\s*$', predict, flags=re.DOTALL)\n    if not match_res:\n        return None\n        \n    prediction, analalysis = match_res.group(1), match_res.group(2)\n        \n    if re.search(r'up|increase', prediction.lower()):\n        prediction_bin = 1\n    elif re.search(r'down|decrease|decline', prediction.lower()):\n        prediction_bin = -1\n    else:\n        prediction_bin = 0\n            \n    match_res = re.search(r'(\\d)-(\\d)%', prediction)\n    if not match_res:\n        match_res = re.search(r'(?:more than )?(\\d)+?%', prediction)    \n        \n    prediction_margin = prediction_bin * (int(match_res.group(1)) + 0.5) if match_res else 0.\n        \n    return {\n        \"positive_developments\": positive,\n        \"potential_concerns\": concerns,\n        \"prediction\": prediction_margin,\n        \"prediction_binary\": prediction_bin,\n        \"analysis\": analalysis\n    }\n\ndef evaluate(completions, answers):\n    completions_dict = defaultdict(list)\n    answers_dict = defaultdict(list)\n    \n    for completion, answer in zip(completions, answers):\n        completion_dict = parse_answer(completion)\n        answer_dict = parse_answer(answer)\n        \n        if completion_dict and answer_dict:\n            print(f\"Completion:\\t{completion_dict['prediction']}\\t| Answer:\\t{answer_dict['prediction']}\")\n            for k in completion_dict.keys():\n                completions_dict[k].append(completion_dict[k])\n                answers_dict[k].append(answer_dict[k])\n                \n    if not completions_dict['prediction']:\n        return {}\n    \n    bin_acc = accuracy_score(completions_dict['prediction_binary'], answers_dict['prediction_binary'])\n    mse = mean_squared_error(completions_dict['prediction'], answers_dict['prediction'])\n    return {\n        \"valid_count\": len(completions_dict['prediction']),\n        \"bin_acc\": bin_acc,\n        \"mse\": mse\n    }","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:29:49.749479Z","iopub.execute_input":"2024-07-20T03:29:49.750443Z","iopub.status.idle":"2024-07-20T03:29:49.767412Z","shell.execute_reply.started":"2024-07-20T03:29:49.750402Z","shell.execute_reply":"2024-07-20T03:29:49.766353Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"basemodel_result = evaluate(completions['base'], answers)\nprint(\"Base model evaluation\", basemodel_result)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T17:44:08.557665Z","iopub.execute_input":"2024-07-19T17:44:08.558455Z","iopub.status.idle":"2024-07-19T17:44:08.577920Z","shell.execute_reply.started":"2024-07-19T17:44:08.558418Z","shell.execute_reply":"2024-07-19T17:44:08.576678Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Completion:\t-5.5\t| Answer:\t-5.5\nCompletion:\t2.5\t| Answer:\t1.5\nCompletion:\t-5.5\t| Answer:\t-0.5\nCompletion:\t2.5\t| Answer:\t-1.5\nCompletion:\t1.5\t| Answer:\t-0.5\nCompletion:\t5.5\t| Answer:\t1.5\nCompletion:\t2.5\t| Answer:\t4.5\nCompletion:\t-5.5\t| Answer:\t3.5\nCompletion:\t1.5\t| Answer:\t-3.5\nCompletion:\t1.5\t| Answer:\t0.5\nCompletion:\t2.5\t| Answer:\t-5.5\nCompletion:\t2.5\t| Answer:\t-0.5\nCompletion:\t2.5\t| Answer:\t-4.5\nBase model evaluation {'valid_count': 13, 'bin_acc': 0.46153846153846156, 'mse': 22.692307692307693}\n","output_type":"stream"}]},{"cell_type":"code","source":"finetuned_result = evaluate(completions['finetuned'], answers)\nprint(\"Finetuned model evaluation\", finetuned_result)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T17:44:17.210916Z","iopub.execute_input":"2024-07-19T17:44:17.211407Z","iopub.status.idle":"2024-07-19T17:44:17.236388Z","shell.execute_reply.started":"2024-07-19T17:44:17.211376Z","shell.execute_reply":"2024-07-19T17:44:17.234920Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Completion:\t-5.5\t| Answer:\t-5.5\nCompletion:\t0.5\t| Answer:\t1.5\nCompletion:\t3.5\t| Answer:\t-0.5\nCompletion:\t0.5\t| Answer:\t-0.5\nCompletion:\t0.5\t| Answer:\t-1.5\nCompletion:\t0.5\t| Answer:\t-0.5\nCompletion:\t1.5\t| Answer:\t-3.5\nCompletion:\t-2.5\t| Answer:\t1.5\nCompletion:\t2.5\t| Answer:\t1.5\nCompletion:\t1.5\t| Answer:\t1.5\nCompletion:\t-2.5\t| Answer:\t-5.5\nCompletion:\t-2.5\t| Answer:\t3.5\nCompletion:\t0.5\t| Answer:\t-3.5\nCompletion:\t0.5\t| Answer:\t0.5\nCompletion:\t0.5\t| Answer:\t0.5\nCompletion:\t1.5\t| Answer:\t-5.5\nCompletion:\t1.5\t| Answer:\t-0.5\nCompletion:\t-2.5\t| Answer:\t-4.5\nCompletion:\t2.5\t| Answer:\t-0.5\nFinetuned model evaluation {'valid_count': 19, 'bin_acc': 0.42105263157894735, 'mse': 10.105263157894736}\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/aaaaaa/base_finetuned_completions.json\", 'r') as f:\n    completions = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:28:26.407378Z","iopub.execute_input":"2024-07-20T03:28:26.407745Z","iopub.status.idle":"2024-07-20T03:28:26.415609Z","shell.execute_reply.started":"2024-07-20T03:28:26.407718Z","shell.execute_reply":"2024-07-20T03:28:26.414678Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"completions_base_parsed = [parse_answer(c) for c in completions['base']]\ncompletions_finetuned_parsed = [parse_answer(c) for c in completions['finetuned']]\nanswers_parsed = [parse_answer(c) for c in answers]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:30:40.275817Z","iopub.execute_input":"2024-07-20T03:30:40.276185Z","iopub.status.idle":"2024-07-20T03:30:40.295095Z","shell.execute_reply.started":"2024-07-20T03:30:40.276154Z","shell.execute_reply":"2024-07-20T03:30:40.294151Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for base, answer in zip(completions_base_parsed, answers_parsed):\n    if not base:\n        print(\"No Base\")\n        continue\n    space_base = \" \" if base['prediction'] > 0 else \"\"\n    space_answer = \" \" if answer['prediction'] > 0 else \"\"\n    is_eq = answer['prediction'] == base['prediction']\n    print(f\"Predictions: {space_base}{base['prediction']} {space_answer}{answer['prediction']} | Base == Answer {is_eq}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:30:47.673467Z","iopub.execute_input":"2024-07-20T03:30:47.674432Z","iopub.status.idle":"2024-07-20T03:30:47.682402Z","shell.execute_reply.started":"2024-07-20T03:30:47.674391Z","shell.execute_reply":"2024-07-20T03:30:47.681291Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Predictions: -5.5 -5.5 | Base == Answer True\nPredictions:  2.5  1.5 | Base == Answer False\nNo Base\nPredictions: -5.5 -0.5 | Base == Answer False\nPredictions:  2.5 -1.5 | Base == Answer False\nPredictions:  1.5 -0.5 | Base == Answer False\nNo Base\nPredictions:  5.5  1.5 | Base == Answer False\nNo Base\nNo Base\nNo Base\nPredictions:  2.5  4.5 | Base == Answer False\nPredictions: -5.5  3.5 | Base == Answer False\nPredictions:  1.5 -3.5 | Base == Answer False\nPredictions:  1.5  0.5 | Base == Answer False\nNo Base\nPredictions:  2.5 -5.5 | Base == Answer False\nPredictions:  2.5 -0.5 | Base == Answer False\nPredictions:  2.5 -4.5 | Base == Answer False\nNo Base\n","output_type":"stream"}]},{"cell_type":"code","source":"for finetuned, answer in zip(completions_finetuned_parsed, answers_parsed):\n    if not finetuned:\n        print(\"No Finetuned\")\n        continue\n    space_answer = \" \" if answer['prediction'] > 0 else \"\"\n    space_finetuned = \" \" if finetuned['prediction'] > 0 else \"\"\n    is_eq = finetuned['prediction'] == answer['prediction']\n    print(f\"Predictions: {space_answer}{answer['prediction']} {space_finetuned}{finetuned['prediction']} | Finetuned == Answer {is_eq}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T03:46:03.247673Z","iopub.execute_input":"2024-07-20T03:46:03.248047Z","iopub.status.idle":"2024-07-20T03:46:03.254633Z","shell.execute_reply.started":"2024-07-20T03:46:03.248020Z","shell.execute_reply":"2024-07-20T03:46:03.253454Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Predictions: -5.5 -5.5 | Finetuned == Answer True\nPredictions:  1.5  0.5 | Finetuned == Answer False\nPredictions: -0.5  3.5 | Finetuned == Answer False\nPredictions: -0.5  0.5 | Finetuned == Answer False\nPredictions: -1.5  0.5 | Finetuned == Answer False\nPredictions: -0.5  0.5 | Finetuned == Answer False\nPredictions: -3.5  1.5 | Finetuned == Answer False\nPredictions:  1.5 -2.5 | Finetuned == Answer False\nPredictions:  1.5  2.5 | Finetuned == Answer False\nPredictions:  1.5  1.5 | Finetuned == Answer True\nPredictions: -5.5 -2.5 | Finetuned == Answer False\nNo Finetuned\nPredictions:  3.5 -2.5 | Finetuned == Answer False\nPredictions: -3.5  0.5 | Finetuned == Answer False\nPredictions:  0.5  0.5 | Finetuned == Answer True\nPredictions:  0.5  0.5 | Finetuned == Answer True\nPredictions: -5.5  1.5 | Finetuned == Answer False\nPredictions: -0.5  1.5 | Finetuned == Answer False\nPredictions: -4.5 -2.5 | Finetuned == Answer False\nPredictions: -0.5  2.5 | Finetuned == Answer False\n","output_type":"stream"}]},{"cell_type":"code","source":"for base, finetuned in zip(completions_base_parsed, completions_finetuned_parsed):\n    if not base:\n        print(\"No Base\")\n        continue\n    if not finetuned:\n        print(\"No Finetuned\")\n        continue\n    space_base = \" \" if base['prediction'] > 0 else \"\"\n    space_finetuned = \" \" if finetuned['prediction'] > 0 else \"\"\n    is_eq = finetuned['prediction'] == base['prediction']\n    print(f\"Predictions: {space_base}{base['prediction']} {space_finetuned}{finetuned['prediction']} | Base == Finetuned {is_eq}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T19:10:00.063280Z","iopub.execute_input":"2024-07-19T19:10:00.064017Z","iopub.status.idle":"2024-07-19T19:10:00.071074Z","shell.execute_reply.started":"2024-07-19T19:10:00.063982Z","shell.execute_reply":"2024-07-19T19:10:00.070095Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Predictions: -5.5 -5.5 | Base == Finetuned True\nPredictions:  2.5  0.5 | Base == Finetuned False\nNo Base\nPredictions: -5.5  0.5 | Base == Finetuned False\nPredictions:  2.5  0.5 | Base == Finetuned False\nPredictions:  1.5  0.5 | Base == Finetuned False\nNo Base\nPredictions:  5.5 -2.5 | Base == Finetuned False\nNo Base\nNo Base\nNo Base\nNo Finetuned\nPredictions: -5.5 -2.5 | Base == Finetuned False\nPredictions:  1.5  0.5 | Base == Finetuned False\nPredictions:  1.5  0.5 | Base == Finetuned False\nNo Base\nPredictions:  2.5  1.5 | Base == Finetuned False\nPredictions:  2.5  1.5 | Base == Finetuned False\nPredictions:  2.5 -2.5 | Base == Finetuned False\nNo Base\n","output_type":"stream"}]}]}